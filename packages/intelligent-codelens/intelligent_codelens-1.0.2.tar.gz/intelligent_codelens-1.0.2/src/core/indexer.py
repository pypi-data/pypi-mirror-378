#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä»£ç ç´¢å¼•æ¨¡å—
ç”¨äºæ‰¹é‡è§£æä»£ç æ–‡ä»¶å¹¶å»ºç«‹ç´¢å¼•
"""

import os
import time
from pathlib import Path
from typing import List, Dict, Any, Generator
import yaml

try:
    from .tree_parser import TreeSitterParser
    from .database import CodeDatabase
except ImportError:
    from tree_parser import TreeSitterParser
    from database import CodeDatabase


class CodeIndexer:
    """ä»£ç ç´¢å¼•å™¨"""
    
    def __init__(self, config_path: str = "config.yaml"):
        """
        åˆå§‹åŒ–ç´¢å¼•å™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config = self._load_config(config_path)
        self.parser = TreeSitterParser(config_path)
        self.db = CodeDatabase(self.config['db_file'])
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_files': 0,
            'processed_files': 0,
            'failed_files': 0,
            'total_functions': 0,
            'total_classes': 0,
            'start_time': None,
            'end_time': None
        }
    
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """
        åŠ è½½é…ç½®æ–‡ä»¶
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            
        Returns:
            é…ç½®å­—å…¸
        """
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    
    def index_repository(self, repo_path: str = None) -> Dict[str, Any]:
        """
        ç´¢å¼•æ•´ä¸ªä»£ç ä»“åº“
        
        Args:
            repo_path: ä»“åº“è·¯å¾„ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è·¯å¾„
            
        Returns:
            ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯
        """
        if repo_path is None:
            repo_path = self.config['repo_path']
        
        print(f"ğŸš€ å¼€å§‹ç´¢å¼•ä»£ç ä»“åº“: {repo_path}")
        self.stats['start_time'] = time.time()
        
        # æ¸…ç©ºç°æœ‰ç´¢å¼•
        self.db.clear_index()
        
        # è·å–æ‰€æœ‰éœ€è¦å¤„ç†çš„æ–‡ä»¶
        files = list(self._get_source_files(repo_path))
        self.stats['total_files'] = len(files)
        
        print(f"ğŸ“ æ‰¾åˆ° {len(files)} ä¸ªæºä»£ç æ–‡ä»¶")
        
        # æ‰¹é‡å¤„ç†æ–‡ä»¶
        batch_size = self.config.get('batch_size', 100)
        for i in range(0, len(files), batch_size):
            batch = files[i:i + batch_size]
            self._process_batch(batch)
            
            # æ˜¾ç¤ºè¿›åº¦
            progress = (i + len(batch)) / len(files) * 100
            print(f"ğŸ“Š è¿›åº¦: {progress:.1f}% ({i + len(batch)}/{len(files)})")
        
        self.stats['end_time'] = time.time()
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        self._print_stats()
        
        # è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯å¹¶åˆå¹¶åˆ°è¿”å›ç»“æœä¸­
        db_stats = self.db.get_stats()
        self.stats.update(db_stats)
        
        return self.stats
    
    def _get_source_files(self, repo_path: str) -> Generator[str, None, None]:
        """
        è·å–ä»“åº“ä¸­çš„æ‰€æœ‰æºä»£ç æ–‡ä»¶
        
        Args:
            repo_path: ä»“åº“è·¯å¾„
            
        Yields:
            æºä»£ç æ–‡ä»¶è·¯å¾„
        """
        repo_path = Path(repo_path)
        exclude_dirs = set(self.config.get('exclude_dirs', []))
        file_extensions = []
        
        # æ”¶é›†æ‰€æœ‰æ”¯æŒçš„æ–‡ä»¶æ‰©å±•å
        for lang, exts in self.config['file_extensions'].items():
            file_extensions.extend(exts)
        
        for root, dirs, files in os.walk(repo_path):
            # è¿‡æ»¤æ’é™¤çš„ç›®å½•
            dirs[:] = [d for d in dirs if d not in exclude_dirs]
            
            for file in files:
                file_path = Path(root) / file
                
                # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
                if file_path.suffix.lower() in file_extensions:
                    # æ£€æŸ¥æ–‡ä»¶å¤§å°
                    try:
                        if file_path.stat().st_size <= self.config.get('max_file_size', 1048576):
                            yield str(file_path)
                    except OSError:
                        continue
    
    def _process_batch(self, files: List[str]):
        """
        æ‰¹é‡å¤„ç†æ–‡ä»¶
        
        Args:
            files: æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        for file_path in files:
            try:
                # è§£ææ–‡ä»¶
                result = self.parser.parse_file(file_path)
                if result:
                    # å­˜å‚¨åˆ°æ•°æ®åº“
                    self.db.store_file_data(result)
                    
                    # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                    self.stats['processed_files'] += 1
                    self.stats['total_functions'] += len(result['functions'])
                    self.stats['total_classes'] += len(result['classes'])
                else:
                    self.stats['failed_files'] += 1
                    
            except Exception as e:
                print(f"âŒ å¤„ç†æ–‡ä»¶ {file_path} å¤±è´¥: {e}")
                self.stats['failed_files'] += 1
    
    def _print_stats(self):
        """æ‰“å°ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯"""
        duration = self.stats['end_time'] - self.stats['start_time']
        
        print("\n" + "="*50)
        print("ğŸ“ˆ ç´¢å¼•å®Œæˆç»Ÿè®¡")
        print("="*50)
        print(f"â±ï¸  æ€»è€—æ—¶: {duration:.2f} ç§’")
        print(f"ğŸ“ æ€»æ–‡ä»¶æ•°: {self.stats['total_files']}")
        print(f"âœ… æˆåŠŸå¤„ç†: {self.stats['processed_files']}")
        print(f"âŒ å¤„ç†å¤±è´¥: {self.stats['failed_files']}")
        print(f"ğŸ”§ æ€»å‡½æ•°æ•°: {self.stats['total_functions']}")
        print(f"ğŸ—ï¸  æ€»ç±»æ•°: {self.stats['total_classes']}")
        
        if self.stats['processed_files'] > 0:
            avg_time = duration / self.stats['processed_files']
            print(f"âš¡ å¹³å‡å¤„ç†é€Ÿåº¦: {avg_time:.3f} ç§’/æ–‡ä»¶")
        
        # æ•°æ®åº“ç»Ÿè®¡
        db_stats = self.db.get_stats()
        print(f"ğŸ’¾ æ•°æ®åº“å¤§å°: {db_stats['db_size_mb']:.2f} MB")
        print(f"ğŸ“Š ç´¢å¼•è®°å½•æ•°: {db_stats['files'] + db_stats['functions'] + db_stats['classes']}")
        print("="*50)
    
    def update_file(self, file_path: str) -> bool:
        """
        æ›´æ–°å•ä¸ªæ–‡ä»¶çš„ç´¢å¼•
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        try:
            # è§£ææ–‡ä»¶
            result = self.parser.parse_file(file_path)
            if result:
                # åˆ é™¤æ—§ç´¢å¼•
                self.db.delete_file_data(file_path)
                
                # å­˜å‚¨æ–°ç´¢å¼•
                self.db.store_file_data(result)
                
                print(f"âœ… å·²æ›´æ–°æ–‡ä»¶ç´¢å¼•: {file_path}")
                return True
            else:
                print(f"âŒ è§£ææ–‡ä»¶å¤±è´¥: {file_path}")
                return False
                
        except Exception as e:
            print(f"âŒ æ›´æ–°æ–‡ä»¶ç´¢å¼•å¤±è´¥ {file_path}: {e}")
            return False
    
    def remove_file(self, file_path: str) -> bool:
        """
        ä»ç´¢å¼•ä¸­ç§»é™¤æ–‡ä»¶
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦ç§»é™¤æˆåŠŸ
        """
        try:
            self.db.delete_file_data(file_path)
            print(f"âœ… å·²ä»ç´¢å¼•ä¸­ç§»é™¤æ–‡ä»¶: {file_path}")
            return True
        except Exception as e:
            print(f"âŒ ç§»é™¤æ–‡ä»¶ç´¢å¼•å¤±è´¥ {file_path}: {e}")
            return False


def main():
    """ä¸»å‡½æ•°ï¼Œç”¨äºå‘½ä»¤è¡Œè°ƒç”¨"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ä»£ç ç´¢å¼•å·¥å…·")
    parser.add_argument("--config", default="config.yaml", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--repo", help="è¦ç´¢å¼•çš„ä»“åº“è·¯å¾„")
    parser.add_argument("--update", help="æ›´æ–°å•ä¸ªæ–‡ä»¶çš„ç´¢å¼•")
    parser.add_argument("--remove", help="ä»ç´¢å¼•ä¸­ç§»é™¤æ–‡ä»¶")
    
    args = parser.parse_args()
    
    indexer = CodeIndexer(args.config)
    
    if args.update:
        indexer.update_file(args.update)
    elif args.remove:
        indexer.remove_file(args.remove)
    else:
        indexer.index_repository(args.repo)


if __name__ == "__main__":
    main()