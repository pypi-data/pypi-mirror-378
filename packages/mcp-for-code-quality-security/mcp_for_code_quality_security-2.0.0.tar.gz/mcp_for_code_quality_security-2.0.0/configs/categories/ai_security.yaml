# AI Security Category Configuration
name: ai_security
display_name: "AI/LLM Security"
description: "Security scanners for AI/ML applications and LLM systems"
icon: "ðŸ¤–"
priority: 2

# Category metadata
metadata:
  focus_areas:
    - "Prompt Injection"
    - "Model Extraction"
    - "Training Data Poisoning"
    - "Plugin Security"
    - "Model Storage Security"

  frameworks_supported:
    - OpenAI
    - Anthropic
    - LangChain
    - Transformers
    - PyTorch
    - TensorFlow

# Tools in this category
tools:
  ai_security:
    display_name: "AI/LLM Security Scanner"
    difficulty: "advanced"
    primary_purpose: "security"
    owasp_llm_focus: ["LLM01", "LLM03", "LLM07", "LLM10"]

  model_security:  # future
    display_name: "Model Security Analyzer"
    difficulty: "expert"
    primary_purpose: "security"

# Learning path (for educational integration)
learning_path:
  - ai_security
  - model_security      # future
  - llm_monitoring      # future

# Compliance mapping
compliance_frameworks:
  owasp_llm_top10:
    covered_categories:
      - "LLM01: Prompt Injection"
      - "LLM02: Insecure Output Handling"
      - "LLM03: Training Data Poisoning"
      - "LLM04: Model Denial of Service"
      - "LLM05: Supply Chain Vulnerabilities"
      - "LLM06: Sensitive Information Disclosure"
      - "LLM07: Insecure Plugin Design"
      - "LLM08: Excessive Agency"
      - "LLM09: Overreliance"
      - "LLM10: Model Theft"

  nist_ai_rmf:  # future
    covered_categories:
      - "GOVERN: AI Risk Management"
      - "MAP: AI Risk Assessment"
      - "MEASURE: AI System Monitoring"

# Integration templates
templates:
  ci_cd:
    github_actions: "ai_security_workflow.yml"
    docker: "ai_security_container.yml"

  monitoring:
    prometheus: "ai_metrics.yml"
    grafana: "ai_security_dashboard.json"

  deployment:
    kubernetes: "ai_security_deployment.yml"