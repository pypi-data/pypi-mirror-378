"""
Report generation module for code quality scan results.

This module provides different report formats (text, markdown, JSON, HTML)
for presenting scan results in a clear and actionable format.
"""

import json
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional

from .scanner import ScanReport, ScanResult


class ReportGenerator:
    """Generate various report formats from scan results."""
    
    def generate_text(self, report: ScanReport, include_details: bool = True) -> str:
        """Generate a plain text report."""
        lines = []
        
        # Header
        lines.append("=" * 60)
        lines.append("         PYTHON CODE QUALITY SCAN REPORT")
        lines.append("=" * 60)
        lines.append(f"Project: {report.project_path}")
        lines.append(f"Scan Time: {report.timestamp}")
        lines.append(f"Configuration: {report.scan_config}")
        lines.append("")
        
        # Executive Summary
        lines.append("EXECUTIVE SUMMARY")
        lines.append("-" * 20)
        lines.append(f"Total Issues Found: {report.total_issues}")
        lines.append(f"Critical Issues: {report.critical_issues}")
        lines.append(f"Tools Executed: {report.summary.get('tools_run', 0)}")
        lines.append(f"Successful Scans: {report.summary.get('successful_tools', 0)}")
        lines.append(f"Failed Scans: {report.summary.get('failed_tools', 0)}")
        lines.append(f"Total Execution Time: {report.summary.get('execution_time', 0):.2f}s")
        lines.append("")
        
        # Issues by Severity
        if 'issues_by_severity' in report.summary:
            lines.append("ISSUES BY SEVERITY")
            lines.append("-" * 20)
            for severity, count in report.summary['issues_by_severity'].items():
                lines.append(f"{severity.title()}: {count}")
            lines.append("")
        
        # Issues by Tool
        if 'issues_by_tool' in report.summary:
            lines.append("ISSUES BY TOOL")
            lines.append("-" * 15)
            for tool, count in report.summary['issues_by_tool'].items():
                lines.append(f"{tool}: {count}")
            lines.append("")
        
        # Detailed Results
        if include_details:
            lines.append("DETAILED RESULTS")
            lines.append("-" * 20)
            
            for result in report.results:
                lines.append(f"\n{result.tool.upper()}")
                lines.append("~" * len(result.tool))
                lines.append(f"Status: {'✓ Success' if result.success else '✗ Failed'}")
                lines.append(f"Execution Time: {result.execution_time:.2f}s")
                lines.append(f"Issues Found: {len(result.issues)}")
                
                if result.errors:
                    lines.append("Errors:")
                    for error in result.errors:
                        lines.append(f"  • {error}")
                
                if result.issues:
                    lines.append("Issues:")
                    for issue in result.issues[:10]:  # Limit to first 10 issues
                        severity = issue.get('severity', 'info').upper()
                        file_path = issue.get('file', 'unknown')
                        line_no = issue.get('line', 0)
                        message = issue.get('message', 'No message')
                        rule = issue.get('rule', '')
                        
                        lines.append(f"  [{severity}] {file_path}:{line_no}")
                        lines.append(f"    {message}")
                        if rule:
                            lines.append(f"    Rule: {rule}")
                        lines.append("")
                    
                    if len(result.issues) > 10:
                        lines.append(f"  ... and {len(result.issues) - 10} more issues")
                
                lines.append("")
        
        # Fix Suggestions
        if report.fix_suggestions:
            lines.append("RECOMMENDED ACTIONS")
            lines.append("-" * 20)
            for i, suggestion in enumerate(report.fix_suggestions, 1):
                lines.append(f"{i}. {suggestion}")
            lines.append("")
        
        # Footer
        lines.append("=" * 60)
        lines.append("Report generated by MCP Code Scanner")
        lines.append(f"Generated at: {datetime.now().isoformat()}")
        lines.append("=" * 60)
        
        return "\n".join(lines)
    
    def generate_markdown(self, report: ScanReport) -> str:
        """Generate a Markdown report."""
        lines = []
        
        # Header
        lines.append("# Python Code Quality Scan Report")
        lines.append("")
        lines.append(f"**Project:** `{report.project_path}`  ")
        lines.append(f"**Scan Time:** {report.timestamp}  ")
        lines.append(f"**Configuration:** {report.scan_config}  ")
        lines.append("")
        
        # Executive Summary
        lines.append("## 📊 Executive Summary")
        lines.append("")
        lines.append("| Metric | Value |")
        lines.append("|--------|-------|")
        lines.append(f"| Total Issues | {report.total_issues} |")
        lines.append(f"| Critical Issues | {report.critical_issues} |")
        lines.append(f"| Tools Executed | {report.summary.get('tools_run', 0)} |")
        lines.append(f"| Successful Scans | {report.summary.get('successful_tools', 0)} |")
        lines.append(f"| Failed Scans | {report.summary.get('failed_tools', 0)} |")
        lines.append(f"| Execution Time | {report.summary.get('execution_time', 0):.2f}s |")
        lines.append("")
        
        # Issues by Severity
        if 'issues_by_severity' in report.summary and report.summary['issues_by_severity']:
            lines.append("## ⚠️ Issues by Severity")
            lines.append("")
            severity_icons = {
                'critical': '🔴',
                'error': '🟠',
                'warning': '🟡',
                'info': '🔵'
            }
            
            for severity, count in report.summary['issues_by_severity'].items():
                icon = severity_icons.get(severity, '⚪')
                lines.append(f"- {icon} **{severity.title()}:** {count}")
            lines.append("")
        
        # Tool Results
        lines.append("## 🔧 Tool Results")
        lines.append("")
        
        for result in report.results:
            status_icon = "✅" if result.success else "❌"
            lines.append(f"### {status_icon} {result.tool.title()}")
            lines.append("")
            lines.append(f"- **Status:** {'Success' if result.success else 'Failed'}")
            lines.append(f"- **Execution Time:** {result.execution_time:.2f}s")
            lines.append(f"- **Issues Found:** {len(result.issues)}")
            lines.append("")
            
            if result.errors:
                lines.append("**Errors:**")
                for error in result.errors:
                    lines.append(f"- ❌ {error}")
                lines.append("")
            
            if result.issues:
                lines.append("**Issues:**")
                lines.append("")
                
                # Group issues by severity
                issues_by_severity = {}
                for issue in result.issues:
                    severity = issue.get('severity', 'info')
                    if severity not in issues_by_severity:
                        issues_by_severity[severity] = []
                    issues_by_severity[severity].append(issue)
                
                for severity in ['critical', 'error', 'warning', 'info']:
                    if severity in issues_by_severity:
                        issues = issues_by_severity[severity]
                        icon = severity_icons.get(severity, '⚪')
                        lines.append(f"**{icon} {severity.title()} ({len(issues)})**")
                        lines.append("")
                        
                        for issue in issues[:5]:  # Show first 5 per severity
                            file_path = issue.get('file', 'unknown')
                            line_no = issue.get('line', 0)
                            message = issue.get('message', 'No message')
                            rule = issue.get('rule', '')
                            
                            lines.append(f"- `{file_path}:{line_no}` - {message}")
                            if rule:
                                lines.append(f"  - Rule: `{rule}`")
                        
                        if len(issues) > 5:
                            lines.append(f"- ... and {len(issues) - 5} more {severity} issues")
                        lines.append("")
        
        # Critical Issues Summary
        critical_issues = []
        for result in report.results:
            for issue in result.issues:
                if issue.get('severity') == 'critical':
                    critical_issues.append((result.tool, issue))
        
        if critical_issues:
            lines.append("## 🚨 Critical Issues Summary")
            lines.append("")
            lines.append("These issues require immediate attention:")
            lines.append("")
            
            for tool, issue in critical_issues[:10]:  # Show first 10 critical
                file_path = issue.get('file', 'unknown')
                line_no = issue.get('line', 0)
                message = issue.get('message', 'No message')
                lines.append(f"1. **{tool}** - `{file_path}:{line_no}`")
                lines.append(f"   {message}")
                lines.append("")
        
        # Fix Suggestions
        if report.fix_suggestions:
            lines.append("## 💡 Recommended Actions")
            lines.append("")
            for suggestion in report.fix_suggestions:
                lines.append(f"- {suggestion}")
            lines.append("")
        
        # Quality Gate
        lines.append("## 🎯 Quality Gate")
        lines.append("")
        
        if report.critical_issues == 0:
            lines.append("✅ **PASSED** - No critical issues found")
        else:
            lines.append(f"❌ **FAILED** - {report.critical_issues} critical issues found")
        
        lines.append("")
        
        # Footer
        lines.append("---")
        lines.append(f"*Report generated by MCP Code Scanner at {datetime.now().isoformat()}*")
        
        return "\n".join(lines)
    
    def generate_html(self, report: ScanReport) -> str:
        """Generate an HTML report."""
        # This is a basic HTML template - can be enhanced with CSS and JavaScript
        html_template = f"""
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Code Quality Report - {Path(report.project_path).name}</title>
    <style>
        body {{ font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; margin: 40px; }}
        .header {{ background: #f8f9fa; padding: 20px; border-radius: 8px; margin-bottom: 30px; }}
        .summary {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 20px; margin-bottom: 30px; }}
        .metric {{ background: white; padding: 20px; border-radius: 8px; border: 1px solid #e1e5e9; text-align: center; }}
        .metric h3 {{ margin: 0 0 10px 0; color: #586069; font-size: 14px; }}
        .metric .value {{ font-size: 24px; font-weight: bold; }}
        .critical {{ color: #d73a49; }}
        .warning {{ color: #f66a0a; }}
        .info {{ color: #0366d6; }}
        .success {{ color: #28a745; }}
        .tool-result {{ background: white; border: 1px solid #e1e5e9; border-radius: 8px; margin-bottom: 20px; }}
        .tool-header {{ background: #f6f8fa; padding: 15px; border-bottom: 1px solid #e1e5e9; }}
        .tool-content {{ padding: 15px; }}
        .issue {{ margin-bottom: 15px; padding: 10px; border-left: 4px solid #e1e5e9; }}
        .issue.critical {{ border-left-color: #d73a49; }}
        .issue.error {{ border-left-color: #d73a49; }}
        .issue.warning {{ border-left-color: #f66a0a; }}
        .issue.info {{ border-left-color: #0366d6; }}
        .fix-suggestions {{ background: #f1f8ff; border: 1px solid #c8e1ff; border-radius: 8px; padding: 20px; }}
    </style>
</head>
<body>
    <div class="header">
        <h1>Python Code Quality Report</h1>
        <p><strong>Project:</strong> {report.project_path}</p>
        <p><strong>Scan Time:</strong> {report.timestamp}</p>
        <p><strong>Configuration:</strong> {report.scan_config}</p>
    </div>
    
    <div class="summary">
        <div class="metric">
            <h3>Total Issues</h3>
            <div class="value {'critical' if report.total_issues > 0 else 'success'}">{report.total_issues}</div>
        </div>
        <div class="metric">
            <h3>Critical Issues</h3>
            <div class="value {'critical' if report.critical_issues > 0 else 'success'}">{report.critical_issues}</div>
        </div>
        <div class="metric">
            <h3>Tools Run</h3>
            <div class="value info">{report.summary.get('tools_run', 0)}</div>
        </div>
        <div class="metric">
            <h3>Execution Time</h3>
            <div class="value info">{report.summary.get('execution_time', 0):.2f}s</div>
        </div>
    </div>
    
    <h2>Detailed Results</h2>
    {self._generate_html_tool_results(report.results)}
    
    {self._generate_html_fix_suggestions(report.fix_suggestions)}
    
    <div style="margin-top: 40px; padding-top: 20px; border-top: 1px solid #e1e5e9; color: #586069; font-size: 12px;">
        Report generated by MCP Code Scanner at {datetime.now().isoformat()}
    </div>
</body>
</html>
"""
        return html_template
    
    def _generate_html_tool_results(self, results: List[ScanResult]) -> str:
        """Generate HTML for tool results."""
        html_parts = []
        
        for result in results:
            status_class = "success" if result.success else "critical"
            status_text = "✅ Success" if result.success else "❌ Failed"
            
            html_parts.append(f"""
    <div class="tool-result">
        <div class="tool-header">
            <h3>{result.tool.title()} - <span class="{status_class}">{status_text}</span></h3>
            <p>Execution Time: {result.execution_time:.2f}s | Issues: {len(result.issues)}</p>
        </div>
        <div class="tool-content">
""")
            
            if result.errors:
                html_parts.append("<h4>Errors:</h4><ul>")
                for error in result.errors:
                    html_parts.append(f"<li>{error}</li>")
                html_parts.append("</ul>")
            
            if result.issues:
                html_parts.append("<h4>Issues:</h4>")
                for issue in result.issues[:10]:  # Limit to 10 issues
                    severity = issue.get('severity', 'info')
                    file_path = issue.get('file', 'unknown')
                    line_no = issue.get('line', 0)
                    message = issue.get('message', 'No message')
                    rule = issue.get('rule', '')
                    
                    html_parts.append(f"""
            <div class="issue {severity}">
                <strong>{file_path}:{line_no}</strong><br>
                {message}
                {f'<br><small>Rule: {rule}</small>' if rule else ''}
            </div>
""")
                
                if len(result.issues) > 10:
                    html_parts.append(f"<p><em>... and {len(result.issues) - 10} more issues</em></p>")
            
            html_parts.append("        </div>\n    </div>")
        
        return "\n".join(html_parts)
    
    def _generate_html_fix_suggestions(self, suggestions: List[str]) -> str:
        """Generate HTML for fix suggestions."""
        if not suggestions:
            return ""
        
        html = ['    <div class="fix-suggestions">', '        <h2>💡 Recommended Actions</h2>', '        <ul>']
        
        for suggestion in suggestions:
            html.append(f"            <li>{suggestion}</li>")
        
        html.extend(['        </ul>', '    </div>'])
        
        return "\n".join(html)
    
    def generate_json(self, report: ScanReport, pretty: bool = True) -> str:
        """Generate a JSON report."""
        if pretty:
            return report.model_dump_json(indent=2)
        else:
            return report.model_dump_json()
    
    def generate_junit_xml(self, report: ScanReport) -> str:
        """Generate JUnit XML format for CI/CD integration."""
        # Count failures and errors
        failures = 0
        errors = 0
        
        for result in report.results:
            if not result.success:
                errors += 1
            else:
                failures += len([i for i in result.issues if i.get('severity') in ['critical', 'error']])
        
        total_tests = len(report.results)
        
        xml_parts = [
            '<?xml version="1.0" encoding="UTF-8"?>',
            f'<testsuite name="code-quality" tests="{total_tests}" failures="{failures}" errors="{errors}" time="{report.summary.get("execution_time", 0):.2f}">',
        ]
        
        for result in report.results:
            test_name = f"code-quality.{result.tool}"
            
            if result.success and not result.issues:
                # Passed test
                xml_parts.append(f'    <testcase name="{test_name}" time="{result.execution_time:.2f}"/>')
            else:
                # Failed test
                xml_parts.append(f'    <testcase name="{test_name}" time="{result.execution_time:.2f}">')
                
                if not result.success:
                    # Tool execution error
                    error_msg = "; ".join(result.errors) if result.errors else "Tool execution failed"
                    xml_parts.append(f'        <error message="{error_msg}"/>')
                else:
                    # Issues found
                    critical_issues = [i for i in result.issues if i.get('severity') in ['critical', 'error']]
                    if critical_issues:
                        issue_summary = f"{len(critical_issues)} critical/error issues found"
                        issue_details = "\n".join([
                            f"{i.get('file', 'unknown')}:{i.get('line', 0)} - {i.get('message', 'No message')}"
                            for i in critical_issues[:5]  # First 5 issues
                        ])
                        xml_parts.append(f'        <failure message="{issue_summary}">{issue_details}</failure>')
                
                xml_parts.append('    </testcase>')
        
        xml_parts.append('</testsuite>')
        
        return "\n".join(xml_parts)
    
    def save_report(
        self, 
        report: ScanReport, 
        output_path: Path, 
        format_type: str = 'markdown'
    ) -> bool:
        """
        Save a report to a file.
        
        Args:
            report: The scan report to save
            output_path: Where to save the report
            format_type: Format to use ('text', 'markdown', 'html', 'json', 'junit')
        
        Returns:
            True if saved successfully
        """
        try:
            if format_type == 'text':
                content = self.generate_text(report)
            elif format_type == 'markdown':
                content = self.generate_markdown(report)
            elif format_type == 'html':
                content = self.generate_html(report)
            elif format_type == 'json':
                content = self.generate_json(report)
            elif format_type == 'junit':
                content = self.generate_junit_xml(report)
            else:
                raise ValueError(f"Unsupported format: {format_type}")
            
            output_path.write_text(content, encoding='utf-8')
            return True
        
        except Exception:
            return False