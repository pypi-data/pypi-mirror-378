# ğŸš€ Mimo Language Model

Mimo est un modÃ¨le de langage AI pour exceller Ã  la fois en **gÃ©nÃ©ration de code** et en **conversations naturelles**.  
Il est issu d'un mÃ©lange de datasets puissants.


![Mimo](https://raw.githubusercontent.com/eurocybersecurite/Mimo-llm/main/assets/mimo.png)

---

## âœ¨ Points forts de Mimo

- ğŸ”§ **OptimisÃ© pour le code** : gÃ©nÃ©ration fiable de scripts Python, JS, etc.  
- ğŸ’¬ **Excellente conversation** : rÃ©ponses naturelles et contextualisÃ©es.  
- âš¡ **CompatibilitÃ© multiplateforme** : fonctionne sur Mac, PC et VSCode.  
- ğŸ“¦ **PrÃªt pour la quantification** (GGUF) â†’ utilisable avec LM Studio ou Ollama.  

---

## ğŸ“¦ Installation

Clonez le dÃ©pÃ´t et installez les dÃ©pendances :

```bash
git clone https://github.com/votre-utilisateur/mimo-llm.git
cd mimo-llm
pip install -r requirements.txt
```

âš ï¸ Assurez-vous dâ€™avoir `git-lfs` installÃ© pour gÃ©rer les poids du modÃ¨le.

---

## ğŸ”‘ Configuration

Avant toute utilisation, configurez votre **Hugging Face Token** :

```bash
export HF_TOKEN="votre_token_hugging_face"
```

---

## ğŸ‹ï¸ Fine-tuning

Lancez le fine-tuning avec :

```bash
python fine_tune_mimo.py
```

**IMPORTANT :** Remplacez `example.jsonl` par votre propre fichier de dataset avant d'exÃ©cuter ce script. Le fichier `example.jsonl` contient quelques exemples fictifs Ã  des fins de dÃ©monstration.

- Utilise vos donnÃ©es perso (`example.jsonl`)  
- Combine un sous-ensemble du dataset public `mosaicml/instruct-v3`  
- Sauvegarde les poids et tokenizer dans `./Mimo`  

âš ï¸ **Note de sÃ©curitÃ©** : ne publiez jamais vos donnÃ©es privÃ©es ou sensibles dans le dÃ©pÃ´t public.

---

## ğŸ§‘â€ğŸ’» Exemples dâ€™utilisation

### GÃ©nÃ©ration de code

```python
prompt = "Ã‰cris une fonction Python pour trier une liste."
inputs = mimo_tokenizer(prompt, return_tensors="pt")
outputs = mimo_model.generate(**inputs, max_new_tokens=100)
print(mimo_tokenizer.decode(outputs[0], skip_special_tokens=True))
```

### Conversation

```python
prompt = "Quelle est la meilleure faÃ§on d'apprendre une nouvelle langue ?"
inputs = mimo_tokenizer(prompt, return_tensors="pt")
outputs = mimo_model.generate(**inputs, max_new_tokens=150)
print(mimo_tokenizer.decode(outputs[0], skip_special_tokens=True))
```

---

## ğŸ“Š Performances comparatives

| ModÃ¨le                          | Code (Python) | Conversation | MÃ©moire requise |
|---------------------------------|---------------|--------------|-----------------|
| GPT-Neo 1.3B                    | â­â­            | â­â­           | ~12 Go          |
| DeepSeek-Qwen-1.5B (base)       | â­â­â­           | â­â­â­          | ~10 Go          |
| **Mimo-1.5B (fine-tuned)**      | â­â­â­â­          | â­â­â­â­         | ~8 Go (quantisÃ©) |

â¡ï¸ **Mimo surpasse la version de base** sur les benchmarks internes (code + QA).

![Mimo Performance](assets/mimo_conv_code.png)
![Mimo Performance](https://raw.githubusercontent.com/eurocybersecurite/Mimo-llm/main/assets/mimo_conv_code.png)

---

## ğŸ“‚ Structure du dÃ©pÃ´t

```
Mimo/
â”œâ”€â”€ README.md
â”œâ”€â”€ assets/mimo.png
â”œâ”€â”€ assets/mimo_conv_code.png
â”œâ”€â”€ example.jsonl        # Jeu de donnÃ©es fictif
â”œâ”€â”€ fine_tune_mimo.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ LICENSE
```

---

## ğŸ› ï¸ IntÃ©gration dans VSCode

1. Clonez le dÃ©pÃ´t :  
   ```bash
   git clone https://github.com/votre-utilisateur/mimo-llm.git
   cd mimo-llm
   ```
2. Installez les dÃ©pendances :  
   ```bash
   pip install -r requirements.txt
   ```
3. ExÃ©cutez soit :  
   - `fine_tune_mimo.py` â†’ pour lâ€™entraÃ®nement  
   - un script dâ€™infÃ©rence personnalisÃ©  

âš¡ Vous pouvez aussi utiliser Mimo dans **LM Studio** en important la version quantisÃ©e GGUF ou autre format.

---

## ğŸ“œ Licence

Ce projet est sous licence **Apache 2.0**.  
Voir le fichier [LICENSE](LICENSE) pour les dÃ©tails.

âš ï¸ **Note importante** : le fichier `example.jsonl` est fourni uniquement comme exemple.  
Nâ€™incluez jamais vos donnÃ©es sensibles ou privÃ©es dans le dÃ©pÃ´t public.

---

## ğŸ“§ Auteur

- **Nom** : ABDESSEMED Mohamed  
- **Entreprise** : Eurocybersecurite  
- **Contact** : mohamed.abdessemed@eurocybersecurite.fr

