# ğŸ¬ Video Transcription Agent

[![Python Version](https://img.shields.io/badge/python-3.9%2B-blue.svg)](https://python.org)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![PyPI version](https://img.shields.io/pypi/v/ai-agent-video-transcription)](https://pypi.org/project/ai-agent-video-transcription/)
[![Downloads](https://img.shields.io/pypi/dm/ai-agent-video-transcription)](https://pypi.org/project/ai-agent-video-transcription/)

> **Multi-agent AI system for video transcription using OpenAI Whisper, ChromaDB, and AutoGen**

Transform your videos into accurate transcriptions with an intelligent multi-agent system that combines the power of OpenAI Whisper, persistent memory with ChromaDB, and advanced agent coordination.

## âœ¨ Key Features

### ğŸ¤– Multi-Agent Architecture
- **Intelligent Coordination**: Specialized agents work together seamlessly
- **Video Analysis**: Extract metadata, duration, and quality information
- **Audio Transcription**: High-accuracy speech-to-text using OpenAI Whisper
- **Text Processing**: Automatic punctuation, formatting, and error correction
- **Output Formatting**: Multiple formats (SRT, VTT, TXT, JSON, CSV, DOCX)
- **Quality Assurance**: Built-in validation and quality assessment

### ğŸ§  Persistent Memory with ChromaDB
- **Semantic Search**: Find content using natural language queries
- **Session History**: Keep track of all transcriptions across sessions
- **Metadata Storage**: Rich information about videos and processing
- **Trend Analysis**: Usage statistics and pattern recognition

### ğŸ’¬ Interactive CLI Experience
- **Intuitive Commands**: Simple, English-based command interface
- **Auto-completion**: Tab completion for commands and file paths
- **Progress Indicators**: Real-time progress bars and status updates
- **Rich Interface**: Beautiful colors and formatting with Rich library
- **Error Handling**: Graceful error management and recovery

### ğŸ¯ Advanced Capabilities
- **Multiple Video Formats**: MP4, AVI, MOV, MKV, FLV, WMV, WebM, M4V
- **Language Detection**: Automatic or manual language selection
- **Precise Timestamps**: Word-level timing accuracy
- **Batch Processing**: Handle multiple videos simultaneously
- **Quality Optimization**: Automatic recommendations for better results

## ğŸš€ Quick Start

### Installation

```bash
# Install from PyPI
pip install ai-agent-video-transcription

# Or install from source
git clone https://github.com/lopand-solutions/video-transcription-agent.git
cd video-transcription-agent
pip install -e .
```

### Prerequisites

- **Python 3.9+**
- **FFmpeg** (for audio/video processing)

```bash
# Install FFmpeg
# macOS
brew install ffmpeg

# Ubuntu/Debian
sudo apt update && sudo apt install ffmpeg

# Windows (using Chocolatey)
choco install ffmpeg
```

### Basic Usage

#### Interactive CLI (Recommended)

```bash
# Start the interactive CLI
vt-cli

# Or use the full command
video-transcription-agent
```

**Available Commands:**
```
ğŸš€ Main Commands:

  â€¢ discovery      - Find videos in current directory
  â€¢ select <ID>   - Select a video from discovery results
  â€¢ transcribe    - Transcribe video file (always in Spanish)
  â€¢ analyze       - Analyze video metadata
  â€¢ search        - Search in saved transcriptions
  â€¢ history       - Show transcription history
  â€¢ status        - Show system status
  â€¢ help          - Show all commands
  â€¢ exit          - Exit the program
```

#### Command Line Usage

```bash
# Transcribe a video file
vt-cli transcribe path/to/video.mp4

# Analyze video metadata
vt-cli analyze path/to/video.mp4

# Search in transcriptions
vt-cli search "artificial intelligence"

# Show system status
vt-cli status
```

#### Programmatic Usage

```python
import asyncio
from ai_agent_video_transcription import CoordinatorAgent

async def transcribe_video():
    # Configuration
    config = {
        'transcriber': {
            'model_size': 'base',  # tiny, base, small, medium, large
            'language': 'es'       # Force Spanish transcription
        },
        'formatter': {
            'output_directory': './output'
        },
        'output_formats': ['txt', 'srt']
    }
    
    # Create coordinator
    coordinator = CoordinatorAgent(config)
    
    # Execute transcription
    result = await coordinator.execute({
        'video_path': 'path/to/video.mp4',
        'output_name': 'my_transcription'
    })
    
    return result

# Run transcription
result = asyncio.run(transcribe_video())
print(f"Transcription completed: {result['final_outputs']}")
```

## ğŸ“– Documentation

### Configuration

#### Environment Variables

```bash
# Optional: Set OpenAI API key for advanced features
export OPENAI_API_KEY="your_api_key_here"

# Optional: Custom ChromaDB directory
export CHROMADB_PERSIST_DIRECTORY="./my_chroma_db"
```

#### Configuration File

Create a `config.yaml` file for advanced configuration:

```yaml
transcriber:
  model_size: "base"  # tiny, base, small, medium, large, large-v2, large-v3
  language: "es"      # Force Spanish, or null for auto-detection
  temperature: 0.0

formatter:
  output_directory: "./output"
  supported_formats: ["txt", "srt", "vtt", "json"]

memory:
  persist_sessions: true
  session_timeout_minutes: 60
```

### Supported Formats

#### Input Video Formats
- MP4, AVI, MOV, MKV, FLV, WMV, WebM, M4V

#### Output Formats
- **TXT**: Plain text transcription
- **SRT**: SubRip subtitle format
- **VTT**: WebVTT subtitle format
- **JSON**: Structured data with timestamps
- **CSV**: Comma-separated values
- **DOCX**: Microsoft Word document

### Whisper Models

| Model | Size | Speed | Accuracy | Use Case |
|-------|------|-------|----------|----------|
| tiny | 39M | Fastest | Basic | Quick testing |
| base | 74M | Fast | Good | **Recommended** |
| small | 244M | Medium | Better | Balanced |
| medium | 769M | Slow | High | Quality focus |
| large | 1550M | Slowest | Highest | Best quality |

## ğŸ—ï¸ Architecture

```
Video Transcription Agent
â”œâ”€â”€ ğŸ¤– Multi-Agent System
â”‚   â”œâ”€â”€ Coordinator Agent (orchestrates workflow)
â”‚   â”œâ”€â”€ Analyzer Agent (video metadata extraction)
â”‚   â”œâ”€â”€ Transcriber Agent (Whisper-based transcription)
â”‚   â”œâ”€â”€ Processor Agent (text enhancement)
â”‚   â””â”€â”€ Formatter Agent (output generation)
â”œâ”€â”€ ğŸ§  Memory System (ChromaDB)
â”‚   â”œâ”€â”€ Persistent storage
â”‚   â”œâ”€â”€ Semantic search
â”‚   â””â”€â”€ Session management
â””â”€â”€ ğŸ’¬ CLI Interface
    â”œâ”€â”€ Interactive commands
    â”œâ”€â”€ Progress indicators
    â””â”€â”€ Error handling
```

## ğŸ”§ Advanced Usage

### Batch Processing

```python
# Process multiple videos
videos = ['video1.mp4', 'video2.mp4', 'video3.mp4']
results = await coordinator.execute_batch(videos, 'batch_output')
```

### Custom Memory Queries

```python
# Search in stored transcriptions
memory = MemoryManager()
results = memory.search_transcriptions("machine learning", limit=10)
```

### Quality Analysis

```python
# Analyze video quality before transcription
analyzer = AnalyzerAgent()
metadata = await analyzer.execute({'video_path': 'video.mp4'})
print(f"Quality Score: {metadata['quality_score']}")
```

## ğŸ› Troubleshooting

### Common Issues

**FFmpeg not found:**
```bash
# Verify installation
ffmpeg -version

# Install if missing
brew install ffmpeg  # macOS
sudo apt install ffmpeg  # Ubuntu
```

**Memory issues with large models:**
- Use smaller models: `tiny`, `base`, `small`
- Process videos in smaller segments
- Increase system RAM or use GPU acceleration

**Transcription in wrong language:**
- Set language explicitly: `language: "es"` in config
- Check audio quality and clarity
- Try different Whisper models

### Performance Optimization

- **GPU Acceleration**: Install CUDA-compatible PyTorch for faster processing
- **Model Caching**: Models are cached automatically after first use
- **Batch Processing**: Process multiple videos in sequence for efficiency

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **OpenAI Whisper** - Speech recognition models
- **ChromaDB** - Vector database for semantic search
- **AutoGen** - Multi-agent framework
- **Rich** - Beautiful terminal interfaces
- **FFmpeg** - Multimedia processing

## ğŸ“ Support

- ğŸ“§ **Email**: contact@lopandsolutions.com
- ğŸ› **Issues**: [GitHub Issues](https://github.com/lopand-solutions/video-transcription-agent/issues)
- ğŸ“– **Documentation**: [Project Wiki](https://github.com/lopand-solutions/video-transcription-agent/wiki)

---

**ğŸ¬ Transform your videos into accurate transcriptions with AI!** ğŸš€

Made with â¤ï¸ by [Lopand Solutions](https://lopandsolutions.com)