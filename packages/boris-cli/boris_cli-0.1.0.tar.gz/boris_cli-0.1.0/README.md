# ü§ñ Boris ‚Äî Chat With Your Codebase (Editor-agnostic, Local-first)

**Boris** is a **terminal AI assistant for developers**. It **scans your repo** into an in-memory tree, lets you **chat** about files and structure, and can **run safe shell** checks. It works with **OpenAI** and **Azure OpenAI** today, with a roadmap for **Anthropic Claude** and **Google Gemini**.

> Looking for a **Cursor / GitHub Copilot / Windsurf / Claude Code**-style assistant but **editor-agnostic** and **local-first**? Boris is a lightweight, repository-aware alternative you drive from the CLI‚Äîwith explicit config, repeatable runs, and safety rails.

---

## ‚ú® Highlights

* üõ† **Local-first** ‚Äî scans your repo into memory, never writes unless you ask.
* üîí **Safe** ‚Äî a **safe-mode shell** blocks risky commands.
* ‚ö° **Incremental** ‚Äî **snapshots** cache structure so subsequent runs are fast.
* üß≠ **Repo-aware chat** ‚Äî talk about files, folders, diffs, and apply patches.
* üîß **Configurable models** ‚Äî pick **chat / coding / reasoning / embedding** models per provider.
* üñ• **Editor-agnostic** ‚Äî use it alongside VS Code, Cursor, Windsurf, JetBrains‚Äîno lock-in.

---

## üß© How Boris compares (quick)

| Feature                | Boris                      | Cursor / Copilot / Windsurf / Claude Code |
| ---------------------- | -------------------------- | ----------------------------------------- |
| Editor dependency      | **None** (CLI)             | Tight editor integration                  |
| Repo scan & snapshots  | **Yes** (incremental)      | Varies                                    |
| Safe-mode shell        | **Yes**                    | No/limited                                |
| Explicit model routing | **Yes** (per role)         | Hidden/managed                            |
| Local-first apply      | **Yes** (dry-run friendly) | Editor buffer or FS                       |

---

## üì¶ Installation

> Not yet on PyPI.

```bash
git clone https://github.com/applebar17/boris.git
cd boris
pip install -e .
```

Python 3.10+ recommended.

---

## üöÄ Quick Start

```bash
# 1) Initialize config
boris ai init            # project-local .env
# or
boris ai init --global   # ~/.config/boris/.env

# 2) Choose a provider
boris ai use-openai --api-key sk-... --chat gpt-4o-mini --reasoning o3-mini
# or Azure OpenAI (use your deployment names)
boris ai use-azure --endpoint https://<resource>.openai.azure.com/ --api-key ... --chat my-gpt4o-mini

# 3) Verify
boris ai show
boris ai test

# 4) Chat in any repo
cd /path/to/your/repo
boris chat
```

When a chat starts, Boris **‚Äústudies‚Äù your project** and shows a concise scan summary. First time studying a project could be slow, but subsequent runs are faster thanks to snapshots.

---

## ‚öôÔ∏è Configuration

Boris reads from:

* **Project**: `./.env` (recommended)
* **Global**: `~/.config/boris/.env` (created via `boris ai init --global`)
* **Environment variables**: `BORIS_*`

### Required settings by provider

#### OpenAI (api.openai.com or compatible)

Configurable through:
```bash
boris ai use-openai --api-key sk-... --chat gpt-4o-mini --reasoning o3-mini
```

```bash
# required
BORIS_OAI_PROVIDER=openai
BORIS_OPENAI_API_KEY=sk-...

# optional: use this for compatible/self-hosted gateways
BORIS_OPENAI_BASE_URL=https://api.openai.com/v1
```

Model routing (pick what you like; CLI can set these):

```bash
BORIS_MODEL_CHAT=gpt-4o-mini
BORIS_MODEL_CODING=gpt-4o-mini
BORIS_MODEL_REASONING=o3-mini
BORIS_MODEL_EMBEDDING=text-embedding-3-small
```

#### Azure OpenAI

Azure uses **deployment names** (not raw model IDs) and typically requires an **API version**.
Boris includes a **fallback API version** if `BORIS_AZURE_OPENAI_API_VERSION` is not set, but pinning it is **recommended**.

Configurable through:
```bash
boris ai use-azure --endpoint https://<resource>.openai.azure.com/ --api-key ... --chat my-gpt4o-mini --api-version ... --reasoning my-o3-mini --coding my-gpt4o-mini
```

```bash
# required
BORIS_OAI_PROVIDER=azure
BORIS_AZURE_OPENAI_ENDPOINT=https://<your-resource>.openai.azure.com/
BORIS_AZURE_OPENAI_API_KEY=...

# recommended (explicit pin; Boris has a built-in fallback if omitted)
BORIS_AZURE_OPENAI_API_VERSION=2025-XX-XX # 2025 versions recommended

# your Azure deployment names
BORIS_MODEL_CHAT=my-gpt4o-mini
BORIS_MODEL_CODING=my-gpt4o-mini
BORIS_MODEL_REASONING=my-o3-mini
BORIS_MODEL_EMBEDDING=my-embeddings
```

> **Gotcha:** In Azure, `BORIS_MODEL_*` must be your **deployment names**, e.g., `my-gpt4o-mini`, not `gpt-4o-mini`.

### Useful toggles

```bash
# Skip enrichment on first huge import (e.g., monorepos)
BORIS_IMPORT_ENRICH=0

# Cap file size to read into memory (bytes; default 1 MiB)
BORIS_MAX_READ_BYTES=1048576

# Custom ignore file (merges with .cmignore/.gitignore) -> useful for studying process "files which Boris doesn't need to study for operating over the project itself
BORIS_CMIGNORE_PATH=/abs/path/to/custom.cmignore
```

---

## üíª CLI

```bash
boris [COMMAND]
```

**Core**

* `boris chat` ‚Äî interactive session. Inside chat:

  * `/help` ‚Äî show help
  * `/run <cmd>` ‚Äî run **safe-mode** shell command
  * `/exit` ‚Äî quit

**Utilities**

* `boris logs_path` ‚Äî show log file location
* `boris version` ‚Äî show installed version
* `boris ui` ‚Äî open project page

**AI configuration**

* `boris ai init [--global]` ‚Äî scaffold `.env`
* `boris ai use-openai ‚Ä¶` / `boris ai use-azure ‚Ä¶` ‚Äî set provider & creds (+models)
* `boris ai models ‚Ä¶` ‚Äî update model routing
* `boris ai show` ‚Äî show effective config (redacted secrets)
* `boris ai test` ‚Äî quick provider ping
* `boris ai guide` ‚Äî step-by-step setup

---

## üß† How it works (in one pass)

1. **Load config** (global + project + env).
2. **Init logging** (per-user logs dir; optional console tap).
3. **Engine select** (Local now; Remote placeholder).
4. **Bootstrap project tree**

   * Load prior **snapshot** (if any).
   * **Sync with disk** (read-only): add new/changed files, read code, ignore `.cmignore`/`.gitignore` rules (e.g., `.venv/`, `node_modules/`).
   * Save fresh **snapshot** for next run.
5. **Start chat**

   * Start asking Boris to perform actions over you project, he will work on you code for you!

---

## üõ°Ô∏è Safety & Logging

* **Safe-mode shell** blocks destructive patterns (e.g., `rm -rf`, redirections, chmod on wide paths).
* **No implicit writes** ‚Äî disk writes are **opt-in**; imports never modify your repo.
* **Logs**: rotating file under your per-user logs directory; console tap optional.

---

## üèéÔ∏è Performance tips

* Use/extend ignore rules:

  * Project `.cmignore` and `.gitignore` are merged automatically.
  * Heavy defaults like `.venv/`, `node_modules/`, `dist/`, `build/` are included out-of-the-box.
* Set `BORIS_IMPORT_ENRICH=0` for very large repos on first import -> boris may need additional instructions about where to operate.
* Adjust `BORIS_MAX_READ_BYTES` to avoid slurping giant artifacts.

---

## üîå Providers (today & tomorrow)

* **Today:** OpenAI, Azure OpenAI
* **Planned:** **Anthropic Claude** (Claude / Claude Code), **Google Gemini**
* Compatible backends via `BORIS_OPENAI_BASE_URL` are possible (OpenAI-compatible APIs)

---

## üß™ Roadmap

* Publish to PyPI
* Unit tests for config precedence, ignore/pruning, safe-mode policies, and tool loop
* Optional VS Code integration
* Remote engine (FastAPI) & project registry
* First-class Claude / Gemini adapters
* Expanded safe-mode & code-gen tooling

---

## üìù License

Boris is released under a **personal use license**:

* Free for personal, non-commercial use
* Commercial/corporate use requires a separate license
* Redistribution of modified builds is not allowed

See [LICENSE](./LICENSE) for details.

---

## ‚ùì Troubleshooting

**Azure: 401/404 or ‚Äúmodel not found‚Äù**

* You must use **deployment names** (`BORIS_MODEL_*`), not raw model IDs.
* Ensure `BORIS_AZURE_OPENAI_ENDPOINT` is correct and you set (or rely on the fallback) API version.
* Verify your deployment exists and is **enabled** in the Azure portal.

**Scan is slow on first run**

* Confirm your `.cmignore`/`.gitignore` ignore heavy dirs (`.venv`, `node_modules`, `dist`, `build`).
* Set `BORIS_IMPORT_ENRICH=0` and re-run; you can re-enable enrichment later.

**No output / tool calls look stuck**

* Run `boris ai test`.
* Check `boris logs_path` and open the log file for details.
* Open an **Issue**: as soon as possible the author will fix it.