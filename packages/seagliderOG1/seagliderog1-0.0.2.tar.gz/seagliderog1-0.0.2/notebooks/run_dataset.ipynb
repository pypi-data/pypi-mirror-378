{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert an entire seaglider mission\n",
    "\n",
    "Given an online location or folder on your computer, process a full mission of basestation netCDF files into a single seagliderOG1 mission file.  \n",
    "\n",
    "- Provide the input location (directory of `p*.nc` files) and output location (where the netCDF file and log file will be saved)\n",
    "- Optional: Provide details of contributing authors (e.g., who created the OG1 format file) to be appended to the output file's attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell imports for development work\n",
    "import pathlib\n",
    "import sys\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=Warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seagliderOG1 import readers, tools\n",
    "from seagliderOG1 import convertOG1\n",
    "import os\n",
    "import datetime\n",
    "import logging\n",
    "_log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify paths for inputs/outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = pathlib.Path().parent.absolute()\n",
    "parent_dir = script_dir.parents[0]\n",
    "sys.path.append(str(parent_dir))\n",
    "sys.path.append(str(parent_dir) + '/seagliderOG1')\n",
    "print(parent_dir)\n",
    "\n",
    "# Specify the path for writing datafiles\n",
    "data_path = os.path.join(parent_dir, 'data')\n",
    "\n",
    "\n",
    "# Provide a list of input locations\n",
    "input_locations = [\n",
    "    # Either Iceland, Faroes or RAPID/MOCHA\n",
    "    \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/005/20090829/\", # done\n",
    "    \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/005/20080606/\", # done\n",
    "    \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/005/20081106/\", # done\n",
    "    \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/012/20070831/\", # done\n",
    "    \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/014/20080214/\",  # done\n",
    "    \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/014/20080222/\", # done\n",
    "    \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/016/20061112/\",  # done\n",
    "    \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/016/20090605/\", # done\n",
    "    \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/016/20071113/\", # done\n",
    "    \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/016/20080607/\",  # done\n",
    "    \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/033/20100518/\",\n",
    "    \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/033/20100903/\",\n",
    "    \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/101/20081108/\",\n",
    "    \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/101/20061112/\",\n",
    "    \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/101/20070609/\",\n",
    "    \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/102/20061112/\",\n",
    "    # Labrador Sea\n",
    "    \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/015/20040924/\",\n",
    "    \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/014/20040924/\",\n",
    "    \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/008/20031002/\",\n",
    "    \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/004/20031002/\",\n",
    "    \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/016/20050406/\",\n",
    "    # RAPID/MOCHA\n",
    "    \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/033/20100729/\",\n",
    "    \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/034/20110128/\",\n",
    "    # RAPID/MOCHA\n",
    "    \"/Users/eddifying/Nextcloud/Shared/data-shared/data-whittard-seaglider/dg042_whittard_data\"\n",
    "\n",
    "]\n",
    "\n",
    "input_locations = [\n",
    "    \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/033/20100903/\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_loc in input_locations:\n",
    "    ds1_base = readers.load_first_basestation_file(input_loc)\n",
    "\n",
    "    # Create a log file based on the first data file\n",
    "    platform_id = ds1_base.attrs['platform_id']\n",
    "    dive_start = ds1_base.attrs['time_coverage_start']\n",
    "    start_time = datetime.datetime.strptime(dive_start, '%Y-%m-%dT%H:%M:%SZ').strftime('%Y%m%dT%H%M%S')\n",
    "\n",
    "    log_file = os.path.join(data_path, f\"{platform_id}_{start_time}.log\")\n",
    "    logf_with_path = os.path.join(data_path, log_file)\n",
    "\n",
    "    # Create the log file\n",
    "    # Note that the use of `force=True` generates a new log file each instance in the loop\n",
    "    logging.basicConfig(\n",
    "        filename=logf_with_path,\n",
    "        encoding='utf-8',\n",
    "        format=\"%(asctime)s %(levelname)-8s %(funcName)s %(message)s\",\n",
    "        filemode=\"w\", # 'w' to overwrite, 'a' to append\n",
    "        level=logging.INFO,\n",
    "        datefmt=\"%Y%m%dT%H%M%S\",\n",
    "        force=True,\n",
    "        )\n",
    "    _log.info('convertOG1.process_and_save_data')\n",
    "    _log.info('Processing data from: %s', input_loc)\n",
    "\n",
    "    # Process the data\n",
    "    ds_all = convertOG1.process_and_save_data(input_loc, output_dir=data_path, save=True,  run_quietly=True)\n",
    "\n",
    "    _log.info('Finished processing data from: %s', input_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = readers.load_sample_dataset()\n",
    "split_ds = tools.split_by_unique_dims(ds1)\n",
    "sg_cal, dc_log, dc_other = convertOG1.extract_variables(split_ds[()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_cal.mass.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = dc_log.log_GPS.values.tobytes().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmp[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_list = [key for key in split_ds.keys()]\n",
    "print(keys_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = readers.load_sample_dataset()\n",
    "divenum = ds1.attrs['dive_number']\n",
    "split_ds = tools.split_by_unique_dims(ds1)\n",
    "gps_info = split_ds[('gps_info',)]\n",
    "\n",
    "key_dims = list(split_ds.keys())\n",
    "key_dims.sort()\n",
    "assert key_dims == [(), ('gc_event',), ('gc_state',), ('gps_info',), ('sg_data_point',)]\n",
    "\n",
    "ds = split_ds[('sg_data_point',)]\n",
    "dsa = convertOG1.standardise_OG10(ds)\n",
    "\n",
    "varlist = list(dsa.data_vars)\n",
    "coordlist = list(dsa.coords)\n",
    "combined_list = varlist + coordlist\n",
    "combined_list.sort()\n",
    "og1_varlist = ['TIME',\n",
    "            'LATITUDE',\n",
    "            'LONGITUDE',\n",
    "            'LATITUDE_GPS',\n",
    "            'TEMP',\n",
    "            'DEPTH',\n",
    "            'TIME_GPS',\n",
    "            'LONGITUDE_GPS',\n",
    "            'TRAJECTORY',\n",
    "            'PLATFORM_MODEL',\n",
    "            'PLATFORM_SERIAL_NUMBER'\n",
    "]\n",
    "for var in og1_varlist:\n",
    "    if var in combined_list:\n",
    "        print(f\"{var} is in the list\")\n",
    "\n",
    "ds_new = convertOG1.add_gps_info_to_dataset(dsa, gps_info)\n",
    "\n",
    "if 'LATITUDE_GPS' in list(ds_new.variables):\n",
    "    print('LATITUDE_GPS is in the list')\n",
    "\n",
    "ds_new = tools.assign_profile_number(ds_new,ds1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
