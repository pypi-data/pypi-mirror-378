{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6a29764-f39c-431c-8e77-fbc6bfe20f01",
   "metadata": {},
   "source": [
    "# seagliderOG1 demo\n",
    "\n",
    "The purpose of this notebook is to demonstrate the functionality of `seagliderOG1` to convert from Seaglider basestation files to OG1 format.\n",
    "\n",
    "- OG1 format is a newly agreed format (since June 2024) for glider data sets from various platforms (e.g., Seaglider, Slocum, Seaexplorer).  It lives on github here: (https://github.com/OceanGlidersCommunity/OG-format-user-manual).\n",
    "- OG1 manual: https://oceangliderscommunity.github.io/OG-format-user-manual/OG_Format.html\n",
    "\n",
    "The test case is to convert sg015 data from the Labrador Sea in September 2004.\n",
    "\n",
    "The demo is organised to show\n",
    "\n",
    "- Conversion of a single dive cycle (single `p*.nc` file)\n",
    "\n",
    "- Conversion for a folder of local dive-cycle files (full mission of `p*.nc` files)\n",
    "\n",
    "- Download from remote server + conversion (directory with full mission of `p*.nc` files)\n",
    "\n",
    "Options are provided to only load e.g. 10 files, but note that OG1 format expects a full mission.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1920f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "\n",
    "script_dir = pathlib.Path().parent.absolute()\n",
    "parent_dir = script_dir.parents[0]\n",
    "sys.path.append(str(parent_dir))\n",
    "sys.path.append(str(parent_dir) + '/seagliderOG1')\n",
    "print(parent_dir)\n",
    "print(sys.path)\n",
    "### silence future warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import xarray as xr\n",
    "import os\n",
    "from seagliderOG1 import readers, writers, plotters\n",
    "from seagliderOG1 import convertOG1, vocabularies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e070d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path for writing datafiles\n",
    "data_path = os.path.join(parent_dir, 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803e373a",
   "metadata": {},
   "source": [
    "## Reading basestation files\n",
    "\n",
    "This has three ways to load a glider dataset.\n",
    "\n",
    "Load an example dataset using `seagliderOG1.fetchers.load_sample_dataset`\n",
    "\n",
    "Alternatively, use your own with e.g. `ds = xr.open_dataset('/path/to/yourfile.nc')`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c414b4",
   "metadata": {},
   "source": [
    "### Load single sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ca56cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = readers.load_sample_dataset()\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1416e5",
   "metadata": {},
   "source": [
    "### Load datasets from a local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bba8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the input directory on your local machine\n",
    "input_dir = data_path + '/demo_sg005' ### chose the input directory with your data\n",
    "\n",
    "# Load and concatenate all datasets in the input directory\n",
    "# Optionally, specify the range of profiles to load (start_profile, end_profile)\n",
    "list_datasets = readers.load_basestation_files(input_dir, start_profile=0, end_profile=5)\n",
    "\n",
    "# Where list_datasets is a list of xarray datasets.  A single dataset can be accessed as\n",
    "ds = list_datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926863fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = readers.load_sample_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4040443",
   "metadata": {},
   "source": [
    "### Load datasets from a remote directory (URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2913eb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the server where data are located\n",
    "server = \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/033/20100903/\"\n",
    "\n",
    "# Load and concatenate all datasets from the server, optionally specifying the range of profiles to load\n",
    "list_datasets = readers.load_basestation_files(server, start_profile=1, end_profile=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c4ebb6",
   "metadata": {},
   "source": [
    "## Convert to OG1 format\n",
    "\n",
    "Process:\n",
    "\n",
    "1. For one basestation dataset, split the dataset by dimension (`split_ds`)\n",
    "3. Transform into OG1 format: dataset with dims `sg_data_point`\n",
    "    - Change the dimension to `N_MEASUREMENTS`\n",
    "    - Rename variables according to `vocabularies.standard_names` \n",
    "    - Assign variable attributes according to `vocabularies.vocab_attrs`.  (Note: This *could* go wrong since it makes assumptions about the input variables. May need additional handling.)\n",
    "4. Add missing mandatory variables: \n",
    "    - From `split_ds[(gps_info,)]`, add the `LATITUDE_GPS`, `LONGITUDE_GPS` and `TIME_GPS` (Note: presently `TIME_GPS` is stripped before saving, but `TIME` values contain `TIME_GPS`)\n",
    "    - Create `PROFILE_NUMBER` and `PHASE`\n",
    "    - Calculate `DEPTH_Z` which is positive up\n",
    "5. Update attributes for the file. \n",
    "    - Combines `creator` and `contributor` from original attributes into `contributor`\n",
    "    - Adds `contributing_institutions` based on `institution`\n",
    "    - Reformats time in `time_coverage_*` and `start_time`--> `start_date`\n",
    "    - Adds `date_modified`\n",
    "    - Renames `comments`-->`history`, `site`-->`summary`\n",
    "    - Adds `title`, `platform`, `platform_vocabulary`, `featureType`, `Conventions`, `rtqc_method*` according to OceanGliders format\n",
    "    - Retains `naming_authority`, `institution`, `project`, `geospatial_*` as OG attributes\n",
    "    - Retains extra attributes: `license`, `keywords`, `keywords_vocabulary`, `file_version`, `acknowledgement`, `date_created`, `disclaimer`\n",
    "\n",
    "Future behaviour to be added:\n",
    "\n",
    "6. Retain the variables starting with `sg_cal` and check whether they vary over the mission (shouldn't)\n",
    "6. Add sensors, using information in the `split_ds` with no dimensions\n",
    "    - Need (from sg_cal_constants: `sg_cal` plus `volmax`, `vbd_cnts_per_cc`, `therm_expan`, `t_*`, `mass`, `hd_*`, `ctcor`, `cpcor`, `c_*`, `abs_compress`, `a`, `Tcor`, `Soc`, `Pcor`, `Foffset`)\n",
    "    - Maybe also `reviewed`, `magnetic_variation` (which will change with position), `log_D_FLARE`, `flight_avg_speed_north` and `flight_avg_speed_east` also with `_gsm`, `depth_avg_curr_north` and `depth_avg_curr_east` also with `_gsm`, \n",
    "    `wlbb2f` - means sensor\n",
    "    `sg_cal_mission_title`\n",
    "    `sg_cal_id_str`\n",
    "    `calibcomm_oxygen`\n",
    "    `calibcomm`\n",
    "    `sbe41` means ??\n",
    "    `hdm_qc`\n",
    "    `glider`\n",
    "    \n",
    "### Convert a single (sample) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd041858-c498-4654-a7c8-1731beb839fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads one dataset (p0150500_20050213.nc)\n",
    "ds = readers.load_sample_dataset()\n",
    "\n",
    "ds_OG1, var_list = convertOG1.convert_to_OG1(ds)\n",
    "\n",
    "# Check the results - uncomment the following lines to either generate a plot or show the variables.\n",
    "plotters.plot_profile_depth(ds_OG1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b0e357",
   "metadata": {},
   "outputs": [],
   "source": [
    "### print the list of inital variables of the dataset\n",
    "var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b697a2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print to screen a table of attributes\n",
    "plotters.show_contents(ds_OG1,'attrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c0c0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print to screen a table of the variables and variable attributes\n",
    "plotters.show_contents(ds_OG1,'variables')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0a27f3",
   "metadata": {},
   "source": [
    "### Convert mission from a local directory of basestation files\n",
    "\n",
    "- For local data in the directory `input_dir`\n",
    "- Creates a plot of ctd_depth against ctd_time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d202485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the input directory on your local machine\n",
    "input_dir = data_path + '/demo_sg005' ### chose the input directory with your data\n",
    "\n",
    "# Load and concatenate all datasets in the input directory\n",
    "# Optionally, specify the range of profiles to load (start_profile, end_profile)\n",
    "list_datasets = readers.load_basestation_files(input_dir, start_profile=1, end_profile=5)\n",
    "\n",
    "# Convert the list of datasets to OG1\n",
    "ds_OG1, var_list = convertOG1.convert_to_OG1(list_datasets)\n",
    "\n",
    "# Generate a simple plot\n",
    "plotters.plot_profile_depth(ds_OG1)\n",
    "plotters.show_contents(ds_OG1,'attrs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3f9e81",
   "metadata": {},
   "source": [
    "### Convert mission from the NCEI server (with p*nc files)\n",
    "\n",
    "- Data from the sg015 mission in the Labrador Sea (https://www.ncei.noaa.gov/access/metadata/landing-page/bin/iso?id=gov.noaa.nodc:0111844), dataset identifier gov.noaa.nodc:0111844.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac290a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the server where data are located\n",
    "server = \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/033/20100903/\"\n",
    "\n",
    "# Load and concatenate all datasets from the server, optionally specifying the range of profiles to load\n",
    "list_datasets = readers.load_basestation_files(server, start_profile=1, end_profile=19)\n",
    "\n",
    "# Convert the list of datasets to OG1\n",
    "ds_OG1, var_list = convertOG1.convert_to_OG1(list_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54baa613",
   "metadata": {},
   "source": [
    "## Saving data\n",
    "\n",
    "Due to problems with writing `xarray` datasets as netCDF when attributes are not of a specified type (`str`, `Number`, `np.ndarray`, `np.number`, `list`, `tuple`), a function was written `save_dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3540ad10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the file\n",
    "# This writer catches errors in data types (DType errors) when using xr.to_netcdf()\n",
    "# The solution is to convert them to strings, which may be undesired behaviour\n",
    "output_file = os.path.join(data_path, 'demo_test.nc')\n",
    "if os.path.exists(output_file):\n",
    "    os.remove(output_file)\n",
    "\n",
    "writers.save_dataset(ds_OG1, output_file);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57da6f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data saved\n",
    "ds1 = xr.open_dataset(output_file)\n",
    "\n",
    "# Generate a simple plot\n",
    "#plotters.show_contents(ds_all,'attrs')\n",
    "plotters.plot_depth_colored(ds1, color_by='PROFILE_NUMBER')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaed738",
   "metadata": {},
   "source": [
    "## Run multiple missions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f47f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add these to existing attributes - update to your details\n",
    "contrib_to_append = vocabularies.contrib_to_append\n",
    "print(contrib_to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6127a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a list of servers or local directories\n",
    "input_locations = [\n",
    "    # Either Iceland, Faroes or RAPID/MOCHA\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/005/20090829/\", # done\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/005/20080606/\", # done\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/005/20081106/\", # done\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/012/20070831/\", # done\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/014/20080214/\",  # done\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/014/20080222/\", # done\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/016/20061112/\",  # done\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/016/20090605/\", # done\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/016/20071113/\", # done\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/016/20080607/\",  # done\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/033/20100518/\", # done\n",
    "    \"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/033/20100903/\", # done\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/101/20081108/\",     # done\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/101/20061112/\",    # done\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/101/20070609/\",   # done\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/102/20061112/\",  # done\n",
    "    # Labrador Sea\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/015/20040924/\",\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/014/20040924/\",\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/008/20031002/\",\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/004/20031002/\",\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/016/20050406/\",\n",
    "    # RAPID/MOCHA\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/033/20100729/\",\n",
    "    #\"https://www.ncei.noaa.gov/data/oceans/glider/seaglider/uw/034/20110128/\",\n",
    "]\n",
    "\n",
    "for input_loc in input_locations:\n",
    "    # Example usage\n",
    "    ds_all = convertOG1.process_and_save_data(input_loc, output_dir=data_path, save=True,  run_quietly=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
