import pandas as pd

@staticmethod
def get_sites():
    """
    Retourne un DataFrame avec le mapping site/plage/gmaps_url.
    """
    data = [
        {"site": "PLAGE DE LA BAIE DES CITRONS", "plage": "Plage de la baie des Citrons", "gmaps_url": "https://maps.app.goo.gl/P2SP3oWuQbxd1sCH9"},
        {"site": "PLAGE DE L'ANSE VATA", "plage": "Plage de l'Anse-Vata", "gmaps_url": "https://maps.app.goo.gl/xAUdky47DqEjSF4R8"},
        {"site": "PLAGE DE LA POINTE MAGNIN", "plage": "Plage de la pointe Magnin", "gmaps_url": "https://maps.app.goo.gl/Wf69LoGgc894MtQy6"},
        {"site": "PLAGE DE LA PROMENADE PIERRE VERNIER", "plage": "Plage de la promenade Pierre-Vernier", "gmaps_url": "https://maps.app.goo.gl/bNocZKVVMYk3HFYs9"},
        {"site": "PLAGE DE MAGENTA", "plage": "Plage de Magenta", "gmaps_url": "https://maps.app.goo.gl/yFwgG2BCV1sEtPWP6"},
        {"site": "PLAGE DU KUENDU BEACH", "plage": "Plage du Kuendu Beach", "gmaps_url": "https://maps.app.goo.gl/oGY6Hy4KCXJWxqfL9"},
    ]
    return pd.DataFrame(data)
def get_pdf_url():
    """
    Alias public pour obtenir l'URL du dernier PDF d'analyses dÃ©taillÃ©es.
    """
    return get_latest_pdf_url()

import pandas as pd
import tabula
import requests
import io
from bs4 import BeautifulSoup

# URL de la page officielle contenant le lien vers le PDF
PAGE_URL = "https://www.noumea.nc/noumea-pratique/salubrite-publique/qualite-eaux-baignade"


def get_latest_pdf_url():
    """
    RÃ©cupÃ¨re dynamiquement l'URL du dernier PDF d'analyses dÃ©taillÃ©es depuis la page officielle.
    """
    print(f"ğŸ”— Recherche du lien PDF sur {PAGE_URL} ...")
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}
    try:
        resp = requests.get(PAGE_URL, headers=headers)
        resp.raise_for_status()
    except Exception as e:
        print(f"âŒ Impossible de rÃ©cupÃ©rer la page officielle : {e}")
        return None
    soup = BeautifulSoup(resp.text, "lxml")
    # Chercher le premier lien PDF dans la page
    link = soup.find("a", href=lambda h: h and h.endswith(".pdf"))
    if not link:
        print("âŒ Aucun lien PDF trouvÃ© sur la page.")
        return None
    pdf_url = link["href"]
    # Si le lien est relatif, le rendre absolu
    if pdf_url.startswith("/"):
        pdf_url = "https://www.noumea.nc" + pdf_url
    print(f"âœ… Lien PDF trouvÃ© : {pdf_url}")
    return pdf_url

def get_detailed_results():
    """
    TÃ©lÃ©charge dynamiquement le PDF des rÃ©sultats dÃ©taillÃ©s, en extrait le premier tableau
    et le retourne sous forme de DataFrame pandas.
    """
    pdf_url = get_latest_pdf_url()
    if not pdf_url:
        return None
    print(f"ğŸ“¥ TÃ©lÃ©chargement du PDF depuis {pdf_url} ...")
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}
        response = requests.get(pdf_url, headers=headers)
        response.raise_for_status()
        print("âœ… TÃ©lÃ©chargement terminÃ©.")
    except requests.exceptions.RequestException as e:
        print(f"âŒ Erreur lors du tÃ©lÃ©chargement du fichier PDF : {e}")
        return None

    pdf_file = io.BytesIO(response.content)

    try:
        print("ğŸ” Extraction des tableaux du PDF...")
        tables = tabula.read_pdf(pdf_file, pages='1', stream=True)
    except Exception as e:
        print(f"âŒ Une erreur est survenue lors de l'extraction des donnÃ©es du PDF.")
        print("â„¹ï¸  Cela peut Ãªtre dÃ» Ã  l'absence de Java sur votre systÃ¨me, qui est requis par la bibliothÃ¨que 'tabula-py'.")
        print(f"   Erreur originale : {e}")
        return None

    if not tables:
        print("âŒ Aucun tableau n'a Ã©tÃ© trouvÃ© dans le PDF.")
        return None

    print(f"âœ… {len(tables)} tableau(x) trouvÃ©(s). Affichage du premier.")
    df = tables[0]
    print("\n--- AperÃ§u du tableau extrait (toutes colonnes) ---")
    with pd.option_context('display.max_columns', None):
        print(df)
    print("\nColonnes:", list(df.columns))
    print("Shape:", df.shape)

    # SÃ©lection dynamique des colonnes bactÃ©ries par nom
    # Recherche des colonnes contenant les mots-clÃ©s
    e_coli_col = next((col for col in df.columns if "Escherichia" in str(col) or "coli" in str(col)), None)
    entero_col = next((col for col in df.columns if "EntÃ©rocoques" in str(col)), None)

    if e_coli_col is None or entero_col is None:
        print(f"âŒ Colonnes bactÃ©ries non trouvÃ©es dans le tableau extrait. Colonnes disponibles : {list(df.columns)}")
        return None

    # SÃ©lectionne les 4 premiÃ¨res colonnes + colonnes bactÃ©ries trouvÃ©es
    selected_cols = [df.columns[0], df.columns[1], df.columns[2], df.columns[4], e_coli_col, entero_col]
    cleaned_df = df.loc[:, selected_cols].copy()
    cleaned_df.columns = [
        "site",
        "point_de_prelevement",
        "date",
        "heure",
        "e_coli_npp_100ml",
        "enterocoques_npp_100ml"
    ]

    # Ajoute deux colonnes issues du split de 'point_de_prelevement'
    split_points = cleaned_df["point_de_prelevement"].str.split(",", n=1, expand=True)
    cleaned_df["id_point_prelevement"] = split_points[0].str.strip()
    cleaned_df["desc_point_prelevement"] = split_points[1].str.strip() if split_points.shape[1] > 1 else ""

    # S'assurer que la colonne 'heure' est bien prÃ©sente et de type string
    if "heure" in cleaned_df.columns:
        cleaned_df["heure"] = cleaned_df["heure"].astype(str)

    # Nettoyer et convertir les colonnes e_coli_npp_100ml et enterocoques_npp_100ml
    # Appliquer la mÃªme technique Ã  l'avant-derniÃ¨re colonne (e_coli_npp_100ml)
    if "e_coli_npp_100ml" in cleaned_df.columns:
        cleaned_df["e_coli_npp_100ml"] = cleaned_df["e_coli_npp_100ml"].astype(str).str.replace(r"<\s*10", "10", regex=True)
        cleaned_df["e_coli_npp_100ml"] = pd.to_numeric(cleaned_df["e_coli_npp_100ml"], errors="coerce").astype('Int64')

    # Appliquer la mÃªme technique Ã  la derniÃ¨re colonne (enterocoques_npp_100ml)
    if "enterocoques_npp_100ml" in cleaned_df.columns:
        cleaned_df["enterocoques_npp_100ml"] = cleaned_df["enterocoques_npp_100ml"].astype(str).str.replace(r"<\s*10", "10", regex=True)
        cleaned_df["enterocoques_npp_100ml"] = pd.to_numeric(cleaned_df["enterocoques_npp_100ml"], errors="coerce").astype('Int64')

    return cleaned_df

if __name__ == "__main__":
    # Obtenir le DataFrame des rÃ©sultats dÃ©taillÃ©s
    detailed_df = get_detailed_results()

    # Afficher seulement les colonnes demandÃ©es
    if detailed_df is not None:
        print("\nğŸ“‹ DÃ©tails synthÃ©tiques :")
        print(detailed_df[[
            "point_de_prelevement",
            "date",
            "e_coli_npp_100ml",
            "enterocoques_npp_100ml"
        ]])
