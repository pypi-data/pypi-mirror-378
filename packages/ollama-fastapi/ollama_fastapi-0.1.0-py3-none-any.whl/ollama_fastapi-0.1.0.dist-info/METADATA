Metadata-Version: 2.4
Name: ollama-fastapi
Version: 0.1.0
Summary: FastAPI wrapper for running Ollama locally
Author-email: Your Name <you@example.com>
License: MIT
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: fastapi
Requires-Dist: uvicorn
Dynamic: license-file

# Ollama FastAPI Wrapper

A simple FastAPI wrapper for [Ollama](https://ollama.ai) models.

## Installation
```bash
pip install ollama-fastapi
```

## Usage

### Run API server
```bash
ollama-fastapi
```

### Call API
```bash
curl -X POST http://127.0.0.1:8000/generate \
     -H "Content-Type: application/json" \
     -d '{"prompt": "Write a haiku about FastAPI"}'
```

### Use in Python
```python
from ollama_fastapi.client import OllamaClient

ollama = OllamaClient("llama3")
print(ollama.generate("Hello world"))
```
