Metadata-Version: 2.2
Name: gllm-inference-binary
Version: 0.5.26.post3
Summary: A library containing components related to model inferences in Gen AI applications.
Author-email: Henry Wicaksono <henry.wicaksono@gdplabs.id>, Resti Febrina <resti.febrina@gdplabs.id>
Description-Content-Type: text/markdown

# GLLM Inference

## Description

A library containing components related to model inferences in Gen AI applications.

## Installation

### Prerequisites
- Python 3.11+ - [Install here](https://www.python.org/downloads/)
- Pip (if using Pip) - [Install here](https://pip.pypa.io/en/stable/installation/)
- Poetry 1.8.1+ (if using Poetry) - [Install here](https://python-poetry.org/docs/#installation)
- Git (if using Git) - [Install here](https://git-scm.com/downloads)
- For git installation:
  - Access to the [GDP Labs SDK github repository](https://github.com/GDP-ADMIN/gen-ai-internal)

### 1. Installation from Artifact Registry
Choose one of the following methods to install the package:

#### Using pip
```bash
pip install gllm-inference-binary
```

#### Using Poetry
```bash
poetry add gllm-inference-binary
```

### 2. Development Installation (Git)
For development purposes, you can install directly from the Git repository:
```bash
poetry add "git+ssh://git@github.com/GDP-ADMIN/gen-ai-internal.git#subdirectory=libs/gllm-inference"
```

Available extras:
- `anthropic`: Install Anthropic models dependencies
- `google-genai`: Install Google Generative AI models dependencies
- `google-vertexai`: Install Google Vertex AI models dependencies
- `huggingface`: Install HuggingFace models dependencies
- `openai`: Install OpenAI models dependencies
- `twelvelabs`: Install TwelveLabs models dependencies

## Managing Dependencies
1. Go to root folder of `gllm-inference` module, e.g. `cd libs/gllm-inference`.
2. Run `poetry shell` to create a virtual environment.
3. Run `poetry lock` to create a lock file if you haven't done it yet.
4. Run `poetry install` to install the `gllm-inference` requirements for the first time.
5. Run `poetry update` if you update any dependency module version at `pyproject.toml`.

## Contributing
Please refer to this [Python Style Guide](https://docs.google.com/document/d/1uRggCrHnVfDPBnG641FyQBwUwLoFw0kTzNqRm92vUwM/edit?usp=sharing)
to get information about code style, documentation standard, and SCA that you need to use when contributing to this project

1. Activate `pre-commit` hooks using `pre-commit install`
2. Run `poetry shell` to create a virtual environment.
3. Run `poetry lock` to create a lock file if you haven't done it yet.
4. Run `poetry install` to install the `gllm-inference` requirements for the first time.
5. Run `which python` to get the path to be referenced at Visual Studio Code interpreter path (`Ctrl`+`Shift`+`P` or `Cmd`+`Shift`+`P`)
6. Try running the unit test to see if it's working:
```bash
poetry run pytest -s tests/unit_tests/
```

