#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FastBackup - ä¸€è¡Œå¯¼å…¥å¼å®éªŒå¤‡ä»½å·¥å…·
åªéœ€è¦åœ¨mainå‡½æ•°å¼€å¤´ import fastbackup å³å¯è‡ªåŠ¨å¤‡ä»½
"""

import os
import sys
import shutil
import datetime
import json
import hashlib
import inspect
from pathlib import Path
import atexit


class FastBackup:
    def __init__(self, project_path=None):
        # ä¿®å¤ï¼šä½¿ç”¨æ›´å¯é çš„æ–¹æ³•è·å–é¡¹ç›®è·¯å¾„
        if project_path:
            self.project_path = Path(project_path).resolve()
        else:
            self.project_path = self._find_user_script_path()

        if not self.project_path:
            print("âš ï¸  FastBackup: æ— æ³•ç¡®å®šé¡¹ç›®è·¯å¾„ï¼Œè·³è¿‡å¤‡ä»½")
            return

        # å¤‡ä»½ç›®å½•è®¾ç½®ä¸ºé¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ .fastbackup
        self.backup_root = self.project_path / '.fastbackup'
        self.backup_root.mkdir(exist_ok=True)

        # åˆ›å»º .gitignore æ–‡ä»¶å¿½ç•¥å¤‡ä»½ç›®å½•
        gitignore_path = self.project_path / '.gitignore'
        self._update_gitignore(gitignore_path)

        # æ‰§è¡Œå¤‡ä»½
        self.backup_dir = self._auto_backup()

        # æ³¨å†Œé€€å‡ºæ—¶çš„æ¸…ç†å‡½æ•°
        atexit.register(self._on_exit)

    def _find_user_script_path(self):
        """æ‰¾åˆ°çœŸæ­£çš„ç”¨æˆ·è„šæœ¬è·¯å¾„"""
        try:
            # æ–¹æ³•1: ä½¿ç”¨ sys.argv[0] (æœ€å¯é çš„ä¸»è„šæœ¬è·¯å¾„)
            if len(sys.argv) > 0 and sys.argv[0]:
                main_script_path = sys.argv[0]

                # å¤„ç†ç›¸å¯¹è·¯å¾„
                if not os.path.isabs(main_script_path):
                    main_script_path = os.path.join(os.getcwd(), main_script_path)

                main_script_path = Path(main_script_path).resolve()

                # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„Pythonæ–‡ä»¶
                if main_script_path.exists():
                    if main_script_path.is_file() and main_script_path.suffix in ['.py', '.pyw']:
                        print(f"ğŸ¯ FastBackup: æ£€æµ‹åˆ°ä¸»è„šæœ¬: {main_script_path}")
                        return main_script_path.parent
                    elif main_script_path.is_dir():
                        # å¦‚æœæ˜¯ç›®å½•ï¼ˆæ¯”å¦‚åœ¨Jupyterä¸­è¿è¡Œï¼‰ï¼Œä½¿ç”¨è¯¥ç›®å½•
                        print(f"ğŸ¯ FastBackup: æ£€æµ‹åˆ°é¡¹ç›®ç›®å½•: {main_script_path}")
                        return main_script_path

            # æ–¹æ³•2: æ£€æŸ¥è°ƒç”¨æ ˆä¸­çš„ç”¨æˆ·æ–‡ä»¶
            current_frame = inspect.currentframe()
            frame = current_frame
            user_files = []

            while frame:
                frame_file = frame.f_globals.get('__file__')
                if frame_file:
                    frame_path = Path(frame_file).resolve()
                    path_str = str(frame_path)

                    # æ’é™¤ç³»ç»Ÿæ–‡ä»¶å’ŒåŒ…æ–‡ä»¶
                    if (not any(exclude in path_str for exclude in [
                        'site-packages', 'lib/python', 'importlib',
                        'runpy.py', '<frozen', 'pkgutil.py'
                    ]) and frame_path.suffix == '.py' and frame_path.exists()):
                        user_files.append(frame_path)

                frame = frame.f_back

            # æ‰¾åˆ°æœ€åˆé€‚çš„ç”¨æˆ·æ–‡ä»¶
            if user_files:
                # ä¼˜å…ˆé€‰æ‹©ä¸åœ¨Pythonå®‰è£…ç›®å½•ä¸­çš„æ–‡ä»¶
                for user_file in user_files:
                    if not str(user_file).startswith(sys.prefix):
                        print(f"ğŸ¯ FastBackup: ä»è°ƒç”¨æ ˆæ£€æµ‹åˆ°ç”¨æˆ·è„šæœ¬: {user_file}")
                        return user_file.parent

                # å¦‚æœéƒ½åœ¨Pythonç›®å½•ä¸­ï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ª
                print(f"ğŸ¯ FastBackup: ä½¿ç”¨è°ƒç”¨æ ˆä¸­çš„è„šæœ¬: {user_files[0]}")
                return user_files[0].parent

            # æ–¹æ³•3: ä½¿ç”¨å½“å‰å·¥ä½œç›®å½•
            cwd = Path.cwd()
            print(f"ğŸ¯ FastBackup: ä½¿ç”¨å½“å‰å·¥ä½œç›®å½•: {cwd}")
            return cwd

        except Exception as e:
            print(f"âš ï¸  FastBackup: æ£€æµ‹é¡¹ç›®è·¯å¾„æ—¶å‡ºé”™: {e}")
            # æœ€åçš„å¤‡é€‰æ–¹æ¡ˆï¼šå½“å‰å·¥ä½œç›®å½•
            return Path.cwd()

    def _update_gitignore(self, gitignore_path):
        """æ›´æ–°.gitignoreæ–‡ä»¶ï¼Œå¿½ç•¥å¤‡ä»½ç›®å½•"""
        gitignore_entry = ".fastbackup/"

        if gitignore_path.exists():
            with open(gitignore_path, 'r', encoding='utf-8') as f:
                content = f.read()

            if gitignore_entry not in content:
                with open(gitignore_path, 'a', encoding='utf-8') as f:
                    if not content.endswith('\n'):
                        f.write('\n')
                    f.write(f"{gitignore_entry}\n")
        else:
            with open(gitignore_path, 'w', encoding='utf-8') as f:
                f.write(f"{gitignore_entry}\n")

    def _get_python_files(self):
        """è·å–é¡¹ç›®ä¸­æ‰€æœ‰Pythonæ–‡ä»¶"""
        python_files = []
        exclude_dirs = {'.git', '__pycache__', '.pytest_cache', 'venv', 'env',
                        '.venv', 'node_modules', '.fastbackup', '.idea', '.vscode'}

        for root, dirs, files in os.walk(self.project_path):
            # è¿‡æ»¤æ‰ä¸éœ€è¦çš„ç›®å½•
            dirs[:] = [d for d in dirs if d not in exclude_dirs and not d.startswith('.')]

            for file in files:
                if file.endswith('.py'):
                    file_path = Path(root) / file
                    python_files.append(file_path)
                elif file.endswith('.ipynb'):
                    file_path = Path(root) / file
                    python_files.append(file_path)
                elif file.endswith('.txt') or file.endswith('.md'):
                    file_path = Path(root) / file
                    python_files.append(file_path)
                elif file.endswith('.sh'):
                    file_path = Path(root) / file
                    python_files.append(file_path)
                elif file.endswith('.yaml') or file.endswith('.yml'):
                    file_path = Path(root) / file
                    python_files.append(file_path)
                elif file.endswith('.json'):
                    file_path = Path(root) / file
                    python_files.append(file_path)
                elif file.endswith('.cfg') or file.endswith('.ini'):
                    file_path = Path(root) / file
                    python_files.append(file_path)

        return python_files

    def _calculate_file_hash(self, file_path):
        """è®¡ç®—æ–‡ä»¶çš„MD5å“ˆå¸Œå€¼"""
        hash_md5 = hashlib.md5()
        try:
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
            return hash_md5.hexdigest()
        except:
            return None

    def _has_changes(self):
        """æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶å˜åŒ–"""
        latest_backup = self._get_latest_backup()
        if not latest_backup:
            return True

        info_file = latest_backup / "backup_info.json"
        if not info_file.exists():
            return True

        try:
            with open(info_file, 'r', encoding='utf-8') as f:
                last_info = json.load(f)
        except:
            return True

        # æ£€æŸ¥å½“å‰æ–‡ä»¶å“ˆå¸Œ
        current_files = self._get_python_files()
        current_hashes = {}

        for file_path in current_files:
            rel_path = str(file_path.relative_to(self.project_path))
            file_hash = self._calculate_file_hash(file_path)
            if file_hash:
                current_hashes[rel_path] = file_hash

        last_hashes = last_info.get('file_hashes', {})
        return current_hashes != last_hashes

    def _get_latest_backup(self):
        """è·å–æœ€æ–°çš„å¤‡ä»½ç›®å½•"""
        backup_dirs = [d for d in self.backup_root.iterdir() if d.is_dir()]
        if not backup_dirs:
            return None
        return max(backup_dirs, key=lambda x: x.name)

    def _auto_backup(self):
        """è‡ªåŠ¨æ‰§è¡Œå¤‡ä»½"""
        # æ£€æŸ¥æ˜¯å¦éœ€è¦å¤‡ä»½
        if not self._has_changes():
            latest_backup = self._get_latest_backup()
            if latest_backup:
                print(f"ğŸ”„ FastBackup: ä½¿ç”¨ç°æœ‰å¤‡ä»½ {latest_backup.name}")
            return latest_backup

        # åˆ›å»ºæ–°å¤‡ä»½
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_name = f"backup_{timestamp}"
        backup_dir = self.backup_root / backup_name
        backup_dir.mkdir(exist_ok=True)

        python_files = self._get_python_files()

        if not python_files:
            print("âš ï¸  FastBackup: æ²¡æœ‰æ‰¾åˆ°Pythonæ–‡ä»¶")
            return None

        print(f"ğŸ’¾ FastBackup: åˆ›å»ºå¤‡ä»½ {backup_name} ({len(python_files)} ä¸ªæ–‡ä»¶)")
        print(f"ğŸ“ é¡¹ç›®è·¯å¾„: {self.project_path}")

        # å¤‡ä»½ä¿¡æ¯
        backup_info = {
            "timestamp": timestamp,
            "project_path": str(self.project_path),
            "file_count": len(python_files),
            "file_hashes": {},
            "files": []
        }

        # å¤åˆ¶æ–‡ä»¶
        for file_path in python_files:
            try:
                rel_path = file_path.relative_to(self.project_path)
                target_path = backup_dir / rel_path
                target_path.parent.mkdir(parents=True, exist_ok=True)
                shutil.copy2(file_path, target_path)

                file_hash = self._calculate_file_hash(file_path)
                file_info = {
                    "path": str(rel_path),
                    "size": file_path.stat().st_size,
                    "modified": datetime.datetime.fromtimestamp(file_path.stat().st_mtime).isoformat(),
                    "hash": file_hash
                }

                backup_info["files"].append(file_info)
                if file_hash:
                    backup_info["file_hashes"][str(rel_path)] = file_hash

            except Exception as e:
                print(f"âš ï¸  FastBackup: å¤‡ä»½å¤±è´¥ {file_path}: {e}")

        # ä¿å­˜å¤‡ä»½ä¿¡æ¯
        with open(backup_dir / "backup_info.json", 'w', encoding='utf-8') as f:
            json.dump(backup_info, f, indent=2, ensure_ascii=False)

        return backup_dir

    def _on_exit(self):
        """ç¨‹åºé€€å‡ºæ—¶çš„å¤„ç†"""
        if hasattr(self, 'backup_dir') and self.backup_dir:
            # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ ä¸€äº›é€€å‡ºæ—¶çš„å¤„ç†é€»è¾‘
            pass

    @classmethod
    def list_backups(cls, project_path=None):
        """åˆ—å‡ºæ‰€æœ‰å¤‡ä»½ï¼ˆç±»æ–¹æ³•ï¼Œå¯ä»¥ç‹¬ç«‹è°ƒç”¨ï¼‰"""
        if project_path is None:
            # ä½¿ç”¨å½“å‰å·¥ä½œç›®å½•
            project_path = Path.cwd()
        else:
            project_path = Path(project_path).resolve()

        backup_root = project_path / '.fastbackup'

        if not backup_root.exists():
            print("ğŸ“ æ²¡æœ‰æ‰¾åˆ°å¤‡ä»½ç›®å½•")
            return

        backup_dirs = sorted([d for d in backup_root.iterdir() if d.is_dir()],
                             key=lambda x: x.name, reverse=True)

        if not backup_dirs:
            print("ğŸ“ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å¤‡ä»½")
            return

        print(f"ğŸ“‹ FastBackup å†å²è®°å½• ({len(backup_dirs)} ä¸ªå¤‡ä»½):")
        print("-" * 60)

        for i, backup_dir in enumerate(backup_dirs[:10]):  # åªæ˜¾ç¤ºæœ€è¿‘10ä¸ª
            info_file = backup_dir / "backup_info.json"

            if info_file.exists():
                try:
                    with open(info_file, 'r', encoding='utf-8') as f:
                        info = json.load(f)

                    timestamp = info.get('timestamp', '')
                    file_count = info.get('file_count', 0)

                    # æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º
                    try:
                        dt = datetime.datetime.strptime(timestamp, "%Y%m%d_%H%M%S")
                        time_str = dt.strftime("%Y-%m-%d %H:%M:%S")
                    except:
                        time_str = timestamp

                    print(f"{i + 1:2d}. {time_str} | {file_count} æ–‡ä»¶ | {backup_dir.name}")

                except Exception:
                    print(f"{i + 1:2d}. {backup_dir.name} (ä¿¡æ¯è¯»å–å¤±è´¥)")
            else:
                print(f"{i + 1:2d}. {backup_dir.name} (æ— ä¿¡æ¯æ–‡ä»¶)")

        if len(backup_dirs) > 10:
            print(f"... è¿˜æœ‰ {len(backup_dirs) - 10} ä¸ªæ›´æ—©çš„å¤‡ä»½")

    @classmethod
    def restore_backup(cls, backup_name, project_path=None):
        """æ¢å¤æŒ‡å®šçš„å¤‡ä»½"""
        if project_path is None:
            project_path = Path.cwd()
        else:
            project_path = Path(project_path).resolve()

        backup_root = project_path / '.fastbackup'
        backup_dir = backup_root / backup_name

        if not backup_dir.exists():
            print(f"âŒ å¤‡ä»½ä¸å­˜åœ¨: {backup_name}")
            return False

        print(f"ğŸ”„ æ¢å¤å¤‡ä»½: {backup_name}")

        # è¯»å–å¤‡ä»½ä¿¡æ¯
        info_file = backup_dir / "backup_info.json"
        if info_file.exists():
            with open(info_file, 'r', encoding='utf-8') as f:
                backup_info = json.load(f)

            restored_count = 0
            for file_info in backup_info.get('files', []):
                src_path = backup_dir / file_info['path']
                dst_path = project_path / file_info['path']

                if src_path.exists():
                    try:
                        dst_path.parent.mkdir(parents=True, exist_ok=True)
                        shutil.copy2(src_path, dst_path)
                        restored_count += 1
                        print(f"  âœ… {file_info['path']}")
                    except Exception as e:
                        print(f"  âŒ {file_info['path']}: {e}")

            print(f"âœ¨ æ¢å¤å®Œæˆ! å…±æ¢å¤ {restored_count} ä¸ªæ–‡ä»¶")
            return True
        else:
            print("âŒ æ‰¾ä¸åˆ°å¤‡ä»½ä¿¡æ¯æ–‡ä»¶")
            return False


# å…¨å±€å˜é‡ï¼Œé¿å…é‡å¤åˆå§‹åŒ–
_backup_instance = None


def _ensure_backup():
    """ç¡®ä¿å¤‡ä»½å®ä¾‹å·²åˆ›å»ºï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰"""
    global _backup_instance
    if _backup_instance is None:
        _backup_instance = FastBackup()
    return _backup_instance


# å¯¼å‡ºçš„ä¾¿æ·å‡½æ•°
def backup():
    """æ‰‹åŠ¨è§¦å‘å¤‡ä»½"""
    return _ensure_backup()


def list_backups():
    """åˆ—å‡ºæ‰€æœ‰å¤‡ä»½"""
    FastBackup.list_backups()


def restore(backup_name):
    """æ¢å¤æŒ‡å®šå¤‡ä»½"""
    return FastBackup.restore_backup(backup_name)


# è‡ªåŠ¨åˆå§‹åŒ–å‡½æ•° - åªæœ‰åœ¨çœŸæ­£å¯¼å…¥ä½¿ç”¨æ—¶æ‰æ‰§è¡Œ
def init(project_path=None):
    """æ‰‹åŠ¨åˆå§‹åŒ–FastBackup"""
    global _backup_instance
    _backup_instance = FastBackup(project_path)
    return _backup_instance


# åœ¨æ¨¡å—å¯¼å…¥æ—¶æ‰§è¡Œåˆå§‹åŒ–
init()

# å¦‚æœç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶ï¼Œæä¾›å‘½ä»¤è¡ŒåŠŸèƒ½
if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='FastBackup - å¿«é€Ÿå®éªŒå¤‡ä»½å·¥å…·')
    parser.add_argument('--list', '-l', action='store_true', help='åˆ—å‡ºæ‰€æœ‰å¤‡ä»½')
    parser.add_argument('--restore', '-r', help='æ¢å¤æŒ‡å®šå¤‡ä»½')
    parser.add_argument('--project', '-p', help='é¡¹ç›®è·¯å¾„ï¼ˆé»˜è®¤å½“å‰ç›®å½•ï¼‰')

    args = parser.parse_args()

    if args.list:
        FastBackup.list_backups(args.project or os.getcwd())
    elif args.restore:
        FastBackup.restore_backup(args.restore, args.project or os.getcwd())
    else:
        print("FastBackup - ä¸€è¡Œå¯¼å…¥å¼å®éªŒå¤‡ä»½å·¥å…·")
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  åœ¨ä½ çš„Pythonè„šæœ¬å¼€å¤´æ·»åŠ : import fastbackup")
        print("  å‘½ä»¤è¡ŒæŸ¥çœ‹å¤‡ä»½: python -m fastbackup --list")
        print("  æ¢å¤å¤‡ä»½: python -m fastbackup --restore backup_20240101_120000")