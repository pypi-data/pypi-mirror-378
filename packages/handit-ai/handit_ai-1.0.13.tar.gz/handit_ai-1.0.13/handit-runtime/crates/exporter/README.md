# Handit Exporter - Event Export Engine

üì§ **High-performance event buffering, compression, and export system**

This crate handles the collection, buffering, and export of trace events from the Handit core. It provides multiple export targets (files, HTTP endpoints), intelligent buffering strategies, and background processing to ensure minimal impact on application performance.

## üöÄ Key Features

- **Memory-Bounded Buffering** - Prevents unbounded memory growth with configurable limits
- **Multiple Export Targets** - Local files, HTTP endpoints, compression streams
- **Background Processing** - Non-blocking event export in dedicated threads
- **Intelligent Flushing** - Adaptive strategies based on time, count, and rate
- **Compression Support** - zstd and gzip compression for efficient storage
- **Graceful Degradation** - Continues operation even if export fails

## üèóÔ∏è Architecture

### Buffer Management
```rust
// In-memory event buffer with size limits
static EVENTS: Lazy<Mutex<Vec<String>>> = Lazy::new(|| Mutex::new(Vec::new()));
static BUFFER_BYTES: Lazy<Mutex<usize>> = Lazy::new(|| Mutex::new(0));

// Configuration limits
struct BufferConfig {
    max_events: usize,        // Hard limit on buffered events
    max_bytes: usize,         // Hard limit on buffered data
    flush_every_events: usize, // Flush threshold by count
    flush_every_ms: u64,      // Flush threshold by time
}
```

### Export Pipeline
```
Events ‚Üí Serialization ‚Üí Buffering ‚Üí Compression ‚Üí Export
   ‚Üì           ‚Üì            ‚Üì           ‚Üì          ‚Üì
Core API   JSON Lines   In-Memory    zstd/gzip   File/HTTP
```

## üìã Configuration

### Environment Variables
```bash
# Buffer limits
HANDIT_MAX_BUFFER_EVENTS="10000"     # Max events in buffer
HANDIT_MAX_BUFFER_BYTES="8388608"    # Max buffer size (8MB)

# Flush triggers
HANDIT_FLUSH_EVERY_EVENTS="200"      # Flush after N events
HANDIT_FLUSH_EVERY_MS="1000"         # Flush after N milliseconds

# Export targets
HANDIT_OUTPUT_FILE="./handit_events.jsonl"  # Local file path
HANDIT_ENDPOINT="https://api.handit.ai/events"  # HTTP endpoint
HANDIT_API_KEY="your-api-key"        # HTTP authentication

# Performance
HANDIT_SPOOL_DIR="./handit_spool"    # Temporary storage
```

### Programmatic Configuration
```rust
use handit_exporter::*;

// Configure export settings
set_http_config(
    Some("https://your-endpoint.com/events".to_string()),
    Some("your-api-key".to_string())
);

// Initialize collector with custom channel
let (tx, rx) = std::sync::mpsc::channel();
handit_core::init_global(tx);
spawn_collector_worker(rx);
```

## üì§ Export Targets

### File Export
Exports events as JSONL (JSON Lines) format with optional compression:

```rust
pub fn write_events_to_file(path: &str) {
    let events = drain_buffer();
    let compressed = compress_events(&events);
    
    std::fs::write(path, compressed)
        .unwrap_or_else(|e| eprintln!("Export failed: {}", e));
}
```

**Output format**:
```jsonl
{"type":"session_start","session_id":"sess_123","ts_ns":1703123456789000000}
{"type":"call","session_id":"sess_123","func":"compute","t0_ns":1703123456789100000}
{"type":"return","session_id":"sess_123","func":"compute","t1_ns":1703123456890000000}
```

### HTTP Export
Exports events to HTTP endpoints with retry logic and authentication:

```rust
#[cfg(feature = "http")]
pub fn flush_events_http() {
    let events = drain_buffer();
    let compressed = compress_events(&events);
    
    tokio::spawn(async move {
        let client = reqwest::Client::new();
        let response = client
            .post(&endpoint)
            .header("Authorization", format!("Bearer {}", api_key))
            .header("Content-Type", "application/x-ndjson")
            .header("Content-Encoding", "gzip")
            .body(compressed)
            .send()
            .await;
            
        match response {
            Ok(resp) if resp.status().is_success() => {
                // Success
            }
            _ => {
                // Retry logic or fallback to file
                fallback_to_file(&events);
            }
        }
    });
}
```

## ‚ö° Buffering Strategy

### Adaptive Flushing
The exporter uses multiple triggers to decide when to flush events:

```rust
fn should_flush(config: &ExportConfig, events: &[String], last_flush: Instant) -> bool {
    // Hard limits (always flush)
    if events.len() >= config.max_buffer_events {
        return true;
    }
    
    let buffer_bytes: usize = events.iter().map(|e| e.len()).sum();
    if buffer_bytes >= config.max_buffer_bytes {
        return true;
    }
    
    // Time-based flushing
    if last_flush.elapsed() >= Duration::from_millis(config.flush_every_ms) {
        return true;
    }
    
    // Count-based flushing
    if events.len() >= config.flush_every_events {
        return true;
    }
    
    // Rate-based prediction
    if should_flush_based_on_rate(events, config) {
        return true;
    }
    
    false
}
```

### Rate-Based Prediction
Predicts when buffer limits will be reached and flushes proactively:

```rust
fn should_flush_based_on_rate(events: &[String], config: &ExportConfig) -> bool {
    let events_per_second = calculate_event_rate();
    let remaining_capacity = config.max_buffer_events - events.len();
    let time_to_capacity = remaining_capacity as f64 / events_per_second;
    
    // Flush if we'll hit capacity before next scheduled flush
    time_to_capacity < (config.flush_every_ms as f64 / 1000.0)
}
```

## üóúÔ∏è Compression

### zstd Compression (Default)
High-performance compression optimized for JSON data:

```rust
use zstd::stream::encode_all;

fn compress_events_zstd(events: &[String]) -> Vec<u8> {
    let combined = events.join("");
    encode_all(combined.as_bytes(), 3)  // Compression level 3
        .unwrap_or_else(|_| combined.into_bytes())
}
```

### gzip Compression (HTTP)
Standard compression for HTTP transport:

```rust
use flate2::{write::GzEncoder, Compression};

fn compress_events_gzip(events: &[String]) -> Vec<u8> {
    let mut encoder = GzEncoder::new(Vec::new(), Compression::default());
    for event in events {
        encoder.write_all(event.as_bytes()).ok();
        encoder.write_all(b"\n").ok();
    }
    encoder.finish().unwrap_or_default()
}
```

## üîÑ Background Processing

### Worker Thread Architecture
```rust
pub fn spawn_collector_worker(rx: Receiver<Event>) {
    thread::spawn(move || {
        let mut last_flush = Instant::now();
        let mut rate_limiter = RateLimiter::new();
        
        loop {
            match rx.recv_timeout(Duration::from_millis(100)) {
                Ok(event) => {
                    process_event(event);
                    
                    if should_flush(&CONFIG, &get_buffer(), last_flush) {
                        flush_buffer();
                        last_flush = Instant::now();
                    }
                }
                Err(RecvTimeoutError::Timeout) => {
                    // Periodic flush even without events
                    if last_flush.elapsed() > Duration::from_secs(5) {
                        flush_buffer();
                        last_flush = Instant::now();
                    }
                }
                Err(RecvTimeoutError::Disconnected) => break,
            }
        }
        
        // Final flush on shutdown
        flush_buffer();
    });
}
```

### Event Processing Pipeline
```rust
fn process_event(event: Event) {
    // 1. Serialize to JSON
    let json_line = match serde_json::to_string(&event) {
        Ok(mut s) => { s.push('\n'); s }
        Err(_) => return, // Skip malformed events
    };
    
    // 2. Add to buffer
    let line_bytes = json_line.len();
    if let Ok(mut buffer) = EVENTS.lock() {
        buffer.push(json_line);
        
        // 3. Update byte counter
        if let Ok(mut bytes) = BUFFER_BYTES.lock() {
            *bytes += line_bytes;
        }
    }
    
    // 4. Check flush conditions
    check_and_flush_if_needed();
}
```

## üìä Performance Characteristics

### Throughput
- **Events/second**: 100K+ with compression
- **Memory usage**: Bounded by configuration
- **CPU overhead**: <1% for typical workloads
- **Disk I/O**: Batched writes minimize syscalls

### Compression Ratios
- **JSON events**: ~70-80% compression with zstd
- **HTTP transport**: ~60-70% with gzip
- **Large traces**: Better compression with more data

### Latency
- **Buffering**: ~10-50ns per event
- **Flushing**: Non-blocking (background thread)
- **Export**: Asynchronous HTTP, synchronous file

## üõ°Ô∏è Error Handling

### Export Failures
```rust
fn handle_export_error(error: ExportError, events: &[String]) {
    match error {
        ExportError::NetworkTimeout => {
            // Retry with exponential backoff
            schedule_retry(events, Duration::from_secs(1));
        }
        ExportError::AuthenticationFailed => {
            // Log error, don't retry
            eprintln!("Authentication failed, check API key");
            fallback_to_file(events);
        }
        ExportError::DiskFull => {
            // Try to export to different location
            try_alternative_paths(events);
        }
        _ => {
            // General fallback
            fallback_to_file(events);
        }
    }
}
```

### Graceful Degradation
- **Network failures**: Fall back to local file export
- **Disk full**: Compress more aggressively or drop old events
- **Serialization errors**: Skip malformed events, continue processing
- **Memory pressure**: Force early flushes to free buffers

## üîß Advanced Configuration

### Custom Export Handlers
```rust
pub trait EventExporter: Send + Sync {
    fn export(&self, events: &[String]) -> Result<(), ExportError>;
}

struct CustomExporter {
    // Custom implementation
}

impl EventExporter for CustomExporter {
    fn export(&self, events: &[String]) -> Result<(), ExportError> {
        // Custom export logic
        Ok(())
    }
}
```

### Batch Processing
```rust
pub struct BatchConfig {
    pub max_batch_size: usize,
    pub max_batch_age: Duration,
    pub compression_level: i32,
}

impl BatchProcessor {
    pub fn process_batch(&mut self, events: Vec<String>) -> Result<(), ExportError> {
        let batch = self.create_batch(events)?;
        let compressed = self.compress_batch(&batch)?;
        self.export_batch(compressed)
    }
}
```

## üß™ Testing

### Unit Tests
```bash
cd crates/exporter
cargo test
```

### Integration Tests
```bash
# Test file export
cargo test file_export_

# Test HTTP export (requires test server)
cargo test --features http http_export_

# Performance tests
cargo test --release perf_
```

### Load Testing
```rust
#[test]
fn test_high_volume_export() {
    let (tx, rx) = std::sync::mpsc::channel();
    spawn_collector_worker(rx);
    
    // Send 100K events
    for i in 0..100_000 {
        let event = create_test_event(i);
        tx.send(event).unwrap();
    }
    
    // Verify all events exported
    thread::sleep(Duration::from_secs(1));
    assert_exported_count(100_000);
}
```

## üìà Monitoring

### Built-in Metrics
```rust
pub struct ExportMetrics {
    pub events_buffered: AtomicUsize,
    pub events_exported: AtomicUsize,
    pub bytes_buffered: AtomicUsize,
    pub bytes_exported: AtomicUsize,
    pub export_failures: AtomicUsize,
    pub last_export_time: AtomicU64,
}

pub fn get_export_metrics() -> ExportMetrics {
    // Return current metrics
}
```

### Health Checks
```rust
pub fn export_health_check() -> HealthStatus {
    let metrics = get_export_metrics();
    
    if metrics.export_failures.load(Ordering::Relaxed) > 10 {
        HealthStatus::Degraded
    } else if metrics.events_buffered.load(Ordering::Relaxed) > 50_000 {
        HealthStatus::Warning
    } else {
        HealthStatus::Healthy
    }
}
```

## üîÆ Future Enhancements

### Planned Features
- **Schema registry** for event format evolution
- **Partitioned export** for large-scale deployments  
- **Real-time streaming** for live monitoring
- **Event deduplication** for exactly-once delivery

### Performance Improvements
- **Zero-copy networking** for HTTP export
- **Custom allocators** for buffer management
- **SIMD-optimized** compression
- **Async file I/O** for better concurrency

---

**The exporter crate ensures reliable, high-performance delivery of trace events to their destinations with minimal application impact.**
