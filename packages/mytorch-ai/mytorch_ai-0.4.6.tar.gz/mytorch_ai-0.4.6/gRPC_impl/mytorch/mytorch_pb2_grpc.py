# Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
"""Client and server classes corresponding to protobuf-defined services."""
import grpc
import warnings

from gRPC_impl.mytorch import mytorch_pb2 as mytorch_dot_mytorch__pb2
from gRPC_impl import shared_msg_types_pb2 as shared__msg__types__pb2

GRPC_GENERATED_VERSION = '1.70.0'
GRPC_VERSION = grpc.__version__
_version_not_supported = False

try:
    from grpc._utilities import first_version_is_lower
    _version_not_supported = first_version_is_lower(GRPC_VERSION, GRPC_GENERATED_VERSION)
except ImportError:
    _version_not_supported = True

if _version_not_supported:
    raise RuntimeError(
        f'The grpc package installed is at version {GRPC_VERSION},'
        + f' but the generated code in mytorch/mytorch_pb2_grpc.py depends on'
        + f' grpcio>={GRPC_GENERATED_VERSION}.'
        + f' Please upgrade your grpc module to grpcio>={GRPC_GENERATED_VERSION}'
        + f' or downgrade your generated code using grpcio-tools<={GRPC_VERSION}.'
    )


class MyTorchServiceStub(object):
    """/////////////////////////////////////////////
    The MyTorch API / service definition
    /////////////////////////////////////////////
    """

    def __init__(self, channel):
        """Constructor.

        Args:
            channel: A grpc.Channel.
        """
        self.randn = channel.unary_unary(
                '/mytorch.MyTorchService/randn',
                request_serializer=shared__msg__types__pb2.TensorShape.SerializeToString,
                response_deserializer=shared__msg__types__pb2.GrpcTensor.FromString,
                _registered_method=True)
        self.rand = channel.unary_unary(
                '/mytorch.MyTorchService/rand',
                request_serializer=shared__msg__types__pb2.TensorShape.SerializeToString,
                response_deserializer=shared__msg__types__pb2.GrpcTensor.FromString,
                _registered_method=True)
        self.from_numpy = channel.unary_unary(
                '/mytorch.MyTorchService/from_numpy',
                request_serializer=shared__msg__types__pb2.SerializedNumpyArray.SerializeToString,
                response_deserializer=shared__msg__types__pb2.GrpcTensor.FromString,
                _registered_method=True)
        self.arange = channel.unary_unary(
                '/mytorch.MyTorchService/arange',
                request_serializer=mytorch_dot_mytorch__pb2.ARangeRequest.SerializeToString,
                response_deserializer=shared__msg__types__pb2.GrpcTensor.FromString,
                _registered_method=True)
        self.reshape = channel.unary_unary(
                '/mytorch.MyTorchService/reshape',
                request_serializer=shared__msg__types__pb2.ReshapeRequest.SerializeToString,
                response_deserializer=shared__msg__types__pb2.GrpcTensor.FromString,
                _registered_method=True)
        self.cat = channel.unary_unary(
                '/mytorch.MyTorchService/cat',
                request_serializer=shared__msg__types__pb2.TensorIDsAndDim.SerializeToString,
                response_deserializer=shared__msg__types__pb2.GrpcTensor.FromString,
                _registered_method=True)
        self.argmax = channel.unary_unary(
                '/mytorch.MyTorchService/argmax',
                request_serializer=mytorch_dot_mytorch__pb2.ArgMaxRequest.SerializeToString,
                response_deserializer=shared__msg__types__pb2.GrpcTensor.FromString,
                _registered_method=True)
        self.matmul = channel.unary_unary(
                '/mytorch.MyTorchService/matmul',
                request_serializer=shared__msg__types__pb2.TwoTensorIDs.SerializeToString,
                response_deserializer=shared__msg__types__pb2.GrpcTensor.FromString,
                _registered_method=True)
        self.sendPytorchTensor = channel.unary_unary(
                '/mytorch.MyTorchService/sendPytorchTensor',
                request_serializer=shared__msg__types__pb2.SerializedTensorObject.SerializeToString,
                response_deserializer=shared__msg__types__pb2.GrpcTensor.FromString,
                _registered_method=True)
        self.unsqueeze = channel.unary_unary(
                '/mytorch.MyTorchService/unsqueeze',
                request_serializer=shared__msg__types__pb2.TensorIDAndDim.SerializeToString,
                response_deserializer=shared__msg__types__pb2.GrpcTensor.FromString,
                _registered_method=True)
        self.max = channel.unary_unary(
                '/mytorch.MyTorchService/max',
                request_serializer=shared__msg__types__pb2.TensorIDAndDim.SerializeToString,
                response_deserializer=shared__msg__types__pb2.TwoGrpcTensors.FromString,
                _registered_method=True)
        self.meshgrid = channel.unary_unary(
                '/mytorch.MyTorchService/meshgrid',
                request_serializer=shared__msg__types__pb2.TensorIDsAndDim.SerializeToString,
                response_deserializer=shared__msg__types__pb2.MultipleGrpcTensors.FromString,
                _registered_method=True)
        self.repeat_interleave = channel.unary_unary(
                '/mytorch.MyTorchService/repeat_interleave',
                request_serializer=mytorch_dot_mytorch__pb2.RepeatInterleaveRequest.SerializeToString,
                response_deserializer=shared__msg__types__pb2.GrpcTensor.FromString,
                _registered_method=True)
        self.allclose = channel.unary_unary(
                '/mytorch.MyTorchService/allclose',
                request_serializer=mytorch_dot_mytorch__pb2.AllCloseRequest.SerializeToString,
                response_deserializer=shared__msg__types__pb2.BooleanValue.FromString,
                _registered_method=True)
        self.mytorch_server_get_timing_statistics = channel.unary_unary(
                '/mytorch.MyTorchService/mytorch_server_get_timing_statistics',
                request_serializer=shared__msg__types__pb2.StringValue.SerializeToString,
                response_deserializer=shared__msg__types__pb2.StringValue.FromString,
                _registered_method=True)
        self.mytorch_server_initialize_timing_statistics = channel.unary_unary(
                '/mytorch.MyTorchService/mytorch_server_initialize_timing_statistics',
                request_serializer=shared__msg__types__pb2.StringValue.SerializeToString,
                response_deserializer=shared__msg__types__pb2.BooleanValue.FromString,
                _registered_method=True)
        self.save_model_stream = channel.unary_stream(
                '/mytorch.MyTorchService/save_model_stream',
                request_serializer=mytorch_dot_mytorch__pb2.SaveModelRequest.SerializeToString,
                response_deserializer=shared__msg__types__pb2.FileChunk.FromString,
                _registered_method=True)
        self.load_model_stream = channel.stream_unary(
                '/mytorch.MyTorchService/load_model_stream',
                request_serializer=shared__msg__types__pb2.FileChunk.SerializeToString,
                response_deserializer=mytorch_dot_mytorch__pb2.LoadModelResponse.FromString,
                _registered_method=True)
        self.generic_call = channel.unary_unary(
                '/mytorch.MyTorchService/generic_call',
                request_serializer=shared__msg__types__pb2.JsonRequest.SerializeToString,
                response_deserializer=shared__msg__types__pb2.JsonResponse.FromString,
                _registered_method=True)


class MyTorchServiceServicer(object):
    """/////////////////////////////////////////////
    The MyTorch API / service definition
    /////////////////////////////////////////////
    """

    def randn(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def rand(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def from_numpy(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def arange(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def reshape(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def cat(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def argmax(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def matmul(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def sendPytorchTensor(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def unsqueeze(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def max(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def meshgrid(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def repeat_interleave(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def allclose(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def mytorch_server_get_timing_statistics(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def mytorch_server_initialize_timing_statistics(self, request, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def save_model_stream(self, request, context):
        """DEPRECATED
        rpc save_model (SaveModelRequest) returns (SerializedModelFile);
        rpc load_model (SerializedModelFile) returns (LoadModelResponse);

        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def load_model_stream(self, request_iterator, context):
        """Missing associated documentation comment in .proto file."""
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def generic_call(self, request, context):
        """Generic JSON-based method invocation
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')


def add_MyTorchServiceServicer_to_server(servicer, server):
    rpc_method_handlers = {
            'randn': grpc.unary_unary_rpc_method_handler(
                    servicer.randn,
                    request_deserializer=shared__msg__types__pb2.TensorShape.FromString,
                    response_serializer=shared__msg__types__pb2.GrpcTensor.SerializeToString,
            ),
            'rand': grpc.unary_unary_rpc_method_handler(
                    servicer.rand,
                    request_deserializer=shared__msg__types__pb2.TensorShape.FromString,
                    response_serializer=shared__msg__types__pb2.GrpcTensor.SerializeToString,
            ),
            'from_numpy': grpc.unary_unary_rpc_method_handler(
                    servicer.from_numpy,
                    request_deserializer=shared__msg__types__pb2.SerializedNumpyArray.FromString,
                    response_serializer=shared__msg__types__pb2.GrpcTensor.SerializeToString,
            ),
            'arange': grpc.unary_unary_rpc_method_handler(
                    servicer.arange,
                    request_deserializer=mytorch_dot_mytorch__pb2.ARangeRequest.FromString,
                    response_serializer=shared__msg__types__pb2.GrpcTensor.SerializeToString,
            ),
            'reshape': grpc.unary_unary_rpc_method_handler(
                    servicer.reshape,
                    request_deserializer=shared__msg__types__pb2.ReshapeRequest.FromString,
                    response_serializer=shared__msg__types__pb2.GrpcTensor.SerializeToString,
            ),
            'cat': grpc.unary_unary_rpc_method_handler(
                    servicer.cat,
                    request_deserializer=shared__msg__types__pb2.TensorIDsAndDim.FromString,
                    response_serializer=shared__msg__types__pb2.GrpcTensor.SerializeToString,
            ),
            'argmax': grpc.unary_unary_rpc_method_handler(
                    servicer.argmax,
                    request_deserializer=mytorch_dot_mytorch__pb2.ArgMaxRequest.FromString,
                    response_serializer=shared__msg__types__pb2.GrpcTensor.SerializeToString,
            ),
            'matmul': grpc.unary_unary_rpc_method_handler(
                    servicer.matmul,
                    request_deserializer=shared__msg__types__pb2.TwoTensorIDs.FromString,
                    response_serializer=shared__msg__types__pb2.GrpcTensor.SerializeToString,
            ),
            'sendPytorchTensor': grpc.unary_unary_rpc_method_handler(
                    servicer.sendPytorchTensor,
                    request_deserializer=shared__msg__types__pb2.SerializedTensorObject.FromString,
                    response_serializer=shared__msg__types__pb2.GrpcTensor.SerializeToString,
            ),
            'unsqueeze': grpc.unary_unary_rpc_method_handler(
                    servicer.unsqueeze,
                    request_deserializer=shared__msg__types__pb2.TensorIDAndDim.FromString,
                    response_serializer=shared__msg__types__pb2.GrpcTensor.SerializeToString,
            ),
            'max': grpc.unary_unary_rpc_method_handler(
                    servicer.max,
                    request_deserializer=shared__msg__types__pb2.TensorIDAndDim.FromString,
                    response_serializer=shared__msg__types__pb2.TwoGrpcTensors.SerializeToString,
            ),
            'meshgrid': grpc.unary_unary_rpc_method_handler(
                    servicer.meshgrid,
                    request_deserializer=shared__msg__types__pb2.TensorIDsAndDim.FromString,
                    response_serializer=shared__msg__types__pb2.MultipleGrpcTensors.SerializeToString,
            ),
            'repeat_interleave': grpc.unary_unary_rpc_method_handler(
                    servicer.repeat_interleave,
                    request_deserializer=mytorch_dot_mytorch__pb2.RepeatInterleaveRequest.FromString,
                    response_serializer=shared__msg__types__pb2.GrpcTensor.SerializeToString,
            ),
            'allclose': grpc.unary_unary_rpc_method_handler(
                    servicer.allclose,
                    request_deserializer=mytorch_dot_mytorch__pb2.AllCloseRequest.FromString,
                    response_serializer=shared__msg__types__pb2.BooleanValue.SerializeToString,
            ),
            'mytorch_server_get_timing_statistics': grpc.unary_unary_rpc_method_handler(
                    servicer.mytorch_server_get_timing_statistics,
                    request_deserializer=shared__msg__types__pb2.StringValue.FromString,
                    response_serializer=shared__msg__types__pb2.StringValue.SerializeToString,
            ),
            'mytorch_server_initialize_timing_statistics': grpc.unary_unary_rpc_method_handler(
                    servicer.mytorch_server_initialize_timing_statistics,
                    request_deserializer=shared__msg__types__pb2.StringValue.FromString,
                    response_serializer=shared__msg__types__pb2.BooleanValue.SerializeToString,
            ),
            'save_model_stream': grpc.unary_stream_rpc_method_handler(
                    servicer.save_model_stream,
                    request_deserializer=mytorch_dot_mytorch__pb2.SaveModelRequest.FromString,
                    response_serializer=shared__msg__types__pb2.FileChunk.SerializeToString,
            ),
            'load_model_stream': grpc.stream_unary_rpc_method_handler(
                    servicer.load_model_stream,
                    request_deserializer=shared__msg__types__pb2.FileChunk.FromString,
                    response_serializer=mytorch_dot_mytorch__pb2.LoadModelResponse.SerializeToString,
            ),
            'generic_call': grpc.unary_unary_rpc_method_handler(
                    servicer.generic_call,
                    request_deserializer=shared__msg__types__pb2.JsonRequest.FromString,
                    response_serializer=shared__msg__types__pb2.JsonResponse.SerializeToString,
            ),
    }
    generic_handler = grpc.method_handlers_generic_handler(
            'mytorch.MyTorchService', rpc_method_handlers)
    server.add_generic_rpc_handlers((generic_handler,))
    server.add_registered_method_handlers('mytorch.MyTorchService', rpc_method_handlers)


 # This class is part of an EXPERIMENTAL API.
class MyTorchService(object):
    """/////////////////////////////////////////////
    The MyTorch API / service definition
    /////////////////////////////////////////////
    """

    @staticmethod
    def randn(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/mytorch.MyTorchService/randn',
            shared__msg__types__pb2.TensorShape.SerializeToString,
            shared__msg__types__pb2.GrpcTensor.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def rand(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/mytorch.MyTorchService/rand',
            shared__msg__types__pb2.TensorShape.SerializeToString,
            shared__msg__types__pb2.GrpcTensor.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def from_numpy(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/mytorch.MyTorchService/from_numpy',
            shared__msg__types__pb2.SerializedNumpyArray.SerializeToString,
            shared__msg__types__pb2.GrpcTensor.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def arange(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/mytorch.MyTorchService/arange',
            mytorch_dot_mytorch__pb2.ARangeRequest.SerializeToString,
            shared__msg__types__pb2.GrpcTensor.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def reshape(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/mytorch.MyTorchService/reshape',
            shared__msg__types__pb2.ReshapeRequest.SerializeToString,
            shared__msg__types__pb2.GrpcTensor.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def cat(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/mytorch.MyTorchService/cat',
            shared__msg__types__pb2.TensorIDsAndDim.SerializeToString,
            shared__msg__types__pb2.GrpcTensor.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def argmax(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/mytorch.MyTorchService/argmax',
            mytorch_dot_mytorch__pb2.ArgMaxRequest.SerializeToString,
            shared__msg__types__pb2.GrpcTensor.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def matmul(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/mytorch.MyTorchService/matmul',
            shared__msg__types__pb2.TwoTensorIDs.SerializeToString,
            shared__msg__types__pb2.GrpcTensor.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def sendPytorchTensor(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/mytorch.MyTorchService/sendPytorchTensor',
            shared__msg__types__pb2.SerializedTensorObject.SerializeToString,
            shared__msg__types__pb2.GrpcTensor.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def unsqueeze(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/mytorch.MyTorchService/unsqueeze',
            shared__msg__types__pb2.TensorIDAndDim.SerializeToString,
            shared__msg__types__pb2.GrpcTensor.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def max(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/mytorch.MyTorchService/max',
            shared__msg__types__pb2.TensorIDAndDim.SerializeToString,
            shared__msg__types__pb2.TwoGrpcTensors.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def meshgrid(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/mytorch.MyTorchService/meshgrid',
            shared__msg__types__pb2.TensorIDsAndDim.SerializeToString,
            shared__msg__types__pb2.MultipleGrpcTensors.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def repeat_interleave(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/mytorch.MyTorchService/repeat_interleave',
            mytorch_dot_mytorch__pb2.RepeatInterleaveRequest.SerializeToString,
            shared__msg__types__pb2.GrpcTensor.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def allclose(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/mytorch.MyTorchService/allclose',
            mytorch_dot_mytorch__pb2.AllCloseRequest.SerializeToString,
            shared__msg__types__pb2.BooleanValue.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def mytorch_server_get_timing_statistics(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/mytorch.MyTorchService/mytorch_server_get_timing_statistics',
            shared__msg__types__pb2.StringValue.SerializeToString,
            shared__msg__types__pb2.StringValue.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def mytorch_server_initialize_timing_statistics(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/mytorch.MyTorchService/mytorch_server_initialize_timing_statistics',
            shared__msg__types__pb2.StringValue.SerializeToString,
            shared__msg__types__pb2.BooleanValue.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def save_model_stream(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_stream(
            request,
            target,
            '/mytorch.MyTorchService/save_model_stream',
            mytorch_dot_mytorch__pb2.SaveModelRequest.SerializeToString,
            shared__msg__types__pb2.FileChunk.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def load_model_stream(request_iterator,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.stream_unary(
            request_iterator,
            target,
            '/mytorch.MyTorchService/load_model_stream',
            shared__msg__types__pb2.FileChunk.SerializeToString,
            mytorch_dot_mytorch__pb2.LoadModelResponse.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)

    @staticmethod
    def generic_call(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(
            request,
            target,
            '/mytorch.MyTorchService/generic_call',
            shared__msg__types__pb2.JsonRequest.SerializeToString,
            shared__msg__types__pb2.JsonResponse.FromString,
            options,
            channel_credentials,
            insecure,
            call_credentials,
            compression,
            wait_for_ready,
            timeout,
            metadata,
            _registered_method=True)
