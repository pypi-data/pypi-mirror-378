# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: mytorch/mytorch.proto
# Protobuf Python Version: 5.29.0
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import runtime_version as _runtime_version
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
_runtime_version.ValidateProtobufRuntimeVersion(
    _runtime_version.Domain.PUBLIC,
    5,
    29,
    0,
    '',
    'mytorch/mytorch.proto'
)
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from gRPC_impl import shared_msg_types_pb2 as shared__msg__types__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x15mytorch/mytorch.proto\x12\x07mytorch\x1a\x16shared_msg_types.proto\"9\n\rARangeRequest\x12\r\n\x05start\x18\x01 \x01(\x02\x12\x0b\n\x03\x65nd\x18\x02 \x01(\x02\x12\x0c\n\x04step\x18\x03 \x01(\x02\"B\n\rArgMaxRequest\x12\x13\n\x0btensor_uuid\x18\x01 \x01(\t\x12\x0b\n\x03\x64im\x18\x02 \x01(\x05\x12\x0f\n\x07keepdim\x18\x03 \x01(\x08\"l\n\x0f\x41llCloseRequest\x12\x14\n\x0ctensor1_uuid\x18\x01 \x01(\t\x12\x14\n\x0ctensor2_uuid\x18\x02 \x01(\t\x12\x0c\n\x04rtol\x18\x03 \x01(\x02\x12\x0c\n\x04\x61tol\x18\x04 \x01(\x02\x12\x11\n\tequal_nan\x18\x05 \x01(\x08\"L\n\x17RepeatInterleaveRequest\x12\x13\n\x0btensor_uuid\x18\x01 \x01(\t\x12\x0f\n\x07repeats\x18\x02 \x01(\x05\x12\x0b\n\x03\x64im\x18\x03 \x01(\x05\"\xaa\x01\n\x10SaveModelRequest\x12\x10\n\x08\x66ilename\x18\x01 \x01(\t\x12K\n\x12named_tensor_uuids\x18\x02 \x03(\x0b\x32/.mytorch.SaveModelRequest.NamedTensorUuidsEntry\x1a\x37\n\x15NamedTensorUuidsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\"\x91\x01\n\x11LoadModelResponse\x12\x38\n\x07tensors\x18\x01 \x03(\x0b\x32\'.mytorch.LoadModelResponse.TensorsEntry\x1a\x42\n\x0cTensorsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12!\n\x05value\x18\x02 \x01(\x0b\x32\x12.shared.GrpcTensor:\x02\x38\x01\x32\xb2\t\n\x0eMyTorchService\x12\x30\n\x05randn\x12\x13.shared.TensorShape\x1a\x12.shared.GrpcTensor\x12/\n\x04rand\x12\x13.shared.TensorShape\x1a\x12.shared.GrpcTensor\x12>\n\nfrom_numpy\x12\x1c.shared.SerializedNumpyArray\x1a\x12.shared.GrpcTensor\x12\x34\n\x06\x61range\x12\x16.mytorch.ARangeRequest\x1a\x12.shared.GrpcTensor\x12\x35\n\x07reshape\x12\x16.shared.ReshapeRequest\x1a\x12.shared.GrpcTensor\x12\x32\n\x03\x63\x61t\x12\x17.shared.TensorIDsAndDim\x1a\x12.shared.GrpcTensor\x12\x34\n\x06\x61rgmax\x12\x16.mytorch.ArgMaxRequest\x1a\x12.shared.GrpcTensor\x12\x32\n\x06matmul\x12\x14.shared.TwoTensorIDs\x1a\x12.shared.GrpcTensor\x12G\n\x11sendPytorchTensor\x12\x1e.shared.SerializedTensorObject\x1a\x12.shared.GrpcTensor\x12\x37\n\tunsqueeze\x12\x16.shared.TensorIDAndDim\x1a\x12.shared.GrpcTensor\x12\x35\n\x03max\x12\x16.shared.TensorIDAndDim\x1a\x16.shared.TwoGrpcTensors\x12@\n\x08meshgrid\x12\x17.shared.TensorIDsAndDim\x1a\x1b.shared.MultipleGrpcTensors\x12I\n\x11repeat_interleave\x12 .mytorch.RepeatInterleaveRequest\x1a\x12.shared.GrpcTensor\x12:\n\x08\x61llclose\x12\x18.mytorch.AllCloseRequest\x1a\x14.shared.BooleanValue\x12P\n$mytorch_server_get_timing_statistics\x12\x13.shared.StringValue\x1a\x13.shared.StringValue\x12X\n+mytorch_server_initialize_timing_statistics\x12\x13.shared.StringValue\x1a\x14.shared.BooleanValue\x12\x43\n\x11save_model_stream\x12\x19.mytorch.SaveModelRequest\x1a\x11.shared.FileChunk0\x01\x12\x44\n\x11load_model_stream\x12\x11.shared.FileChunk\x1a\x1a.mytorch.LoadModelResponse(\x01\x12\x39\n\x0cgeneric_call\x12\x13.shared.JsonRequest\x1a\x14.shared.JsonResponseb\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'mytorch.mytorch_pb2', _globals)
if not _descriptor._USE_C_DESCRIPTORS:
  DESCRIPTOR._loaded_options = None
  _globals['_SAVEMODELREQUEST_NAMEDTENSORUUIDSENTRY']._loaded_options = None
  _globals['_SAVEMODELREQUEST_NAMEDTENSORUUIDSENTRY']._serialized_options = b'8\001'
  _globals['_LOADMODELRESPONSE_TENSORSENTRY']._loaded_options = None
  _globals['_LOADMODELRESPONSE_TENSORSENTRY']._serialized_options = b'8\001'
  _globals['_ARANGEREQUEST']._serialized_start=58
  _globals['_ARANGEREQUEST']._serialized_end=115
  _globals['_ARGMAXREQUEST']._serialized_start=117
  _globals['_ARGMAXREQUEST']._serialized_end=183
  _globals['_ALLCLOSEREQUEST']._serialized_start=185
  _globals['_ALLCLOSEREQUEST']._serialized_end=293
  _globals['_REPEATINTERLEAVEREQUEST']._serialized_start=295
  _globals['_REPEATINTERLEAVEREQUEST']._serialized_end=371
  _globals['_SAVEMODELREQUEST']._serialized_start=374
  _globals['_SAVEMODELREQUEST']._serialized_end=544
  _globals['_SAVEMODELREQUEST_NAMEDTENSORUUIDSENTRY']._serialized_start=489
  _globals['_SAVEMODELREQUEST_NAMEDTENSORUUIDSENTRY']._serialized_end=544
  _globals['_LOADMODELRESPONSE']._serialized_start=547
  _globals['_LOADMODELRESPONSE']._serialized_end=692
  _globals['_LOADMODELRESPONSE_TENSORSENTRY']._serialized_start=626
  _globals['_LOADMODELRESPONSE_TENSORSENTRY']._serialized_end=692
  _globals['_MYTORCHSERVICE']._serialized_start=695
  _globals['_MYTORCHSERVICE']._serialized_end=1897
# @@protoc_insertion_point(module_scope)
