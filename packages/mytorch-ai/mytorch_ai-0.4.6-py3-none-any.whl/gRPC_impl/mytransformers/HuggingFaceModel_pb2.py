# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: mytransformers/HuggingFaceModel.proto
# Protobuf Python Version: 5.29.0
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import runtime_version as _runtime_version
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
_runtime_version.ValidateProtobufRuntimeVersion(
    _runtime_version.Domain.PUBLIC,
    5,
    29,
    0,
    '',
    'mytransformers/HuggingFaceModel.proto'
)
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from gRPC_impl import shared_msg_types_pb2 as shared__msg__types__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n%mytransformers/HuggingFaceModel.proto\x12\x0emytransformers\x1a\x16shared_msg_types.proto\"\xd5\x01\n\x16\x66romPretrained_request\x12%\n\x1dpretrained_model_name_or_path\x18\x01 \x01(\t\x12\x12\n\nmodel_args\x18\x02 \x03(\t\x12\x42\n\x06kwargs\x18\x03 \x03(\x0b\x32\x32.mytransformers.fromPretrained_request.KwargsEntry\x1a<\n\x0bKwargsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x1c\n\x05value\x18\x02 \x01(\x0b\x32\r.shared.Value:\x02\x38\x01\"-\n\x17\x66romPretrained_response\x12\x12\n\nmodel_uuid\x18\x01 \x01(\t\"L\n\x10generate_request\x12\x12\n\nmodel_uuid\x18\x01 \x01(\t\x12$\n\x06kwargs\x18\x02 \x03(\x0b\x32\x14.shared.keyValuePair\"(\n\x11generate_response\x12\x13\n\x0btensor_uuid\x18\x01 \x01(\t2\x9c\x07\n\x17HuggingFaceModelService\x12j\n\x17getAutoModelForCausalML\x12&.mytransformers.fromPretrained_request\x1a\'.mytransformers.fromPretrained_response\x12x\n%getAutoModelForSequenceClassification\x12&.mytransformers.fromPretrained_request\x1a\'.mytransformers.fromPretrained_response\x12x\n%getBertModelForSequenceClassification\x12&.mytransformers.fromPretrained_request\x1a\'.mytransformers.fromPretrained_response\x12{\n(getRobertaModelForSequenceClassification\x12&.mytransformers.fromPretrained_request\x1a\'.mytransformers.fromPretrained_response\x12p\n\x1dgetT5ForConditionalGeneration\x12&.mytransformers.fromPretrained_request\x1a\'.mytransformers.fromPretrained_response\x12k\n\x18getAutoModelForSeq2SeqLM\x12&.mytransformers.fromPretrained_request\x1a\'.mytransformers.fromPretrained_response\x12t\n!getXLNetForSequenceClassification\x12&.mytransformers.fromPretrained_request\x1a\'.mytransformers.fromPretrained_response\x12O\n\x08generate\x12 .mytransformers.generate_request\x1a!.mytransformers.generate_responseb\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'mytransformers.HuggingFaceModel_pb2', _globals)
if not _descriptor._USE_C_DESCRIPTORS:
  DESCRIPTOR._loaded_options = None
  _globals['_FROMPRETRAINED_REQUEST_KWARGSENTRY']._loaded_options = None
  _globals['_FROMPRETRAINED_REQUEST_KWARGSENTRY']._serialized_options = b'8\001'
  _globals['_FROMPRETRAINED_REQUEST']._serialized_start=82
  _globals['_FROMPRETRAINED_REQUEST']._serialized_end=295
  _globals['_FROMPRETRAINED_REQUEST_KWARGSENTRY']._serialized_start=235
  _globals['_FROMPRETRAINED_REQUEST_KWARGSENTRY']._serialized_end=295
  _globals['_FROMPRETRAINED_RESPONSE']._serialized_start=297
  _globals['_FROMPRETRAINED_RESPONSE']._serialized_end=342
  _globals['_GENERATE_REQUEST']._serialized_start=344
  _globals['_GENERATE_REQUEST']._serialized_end=420
  _globals['_GENERATE_RESPONSE']._serialized_start=422
  _globals['_GENERATE_RESPONSE']._serialized_end=462
  _globals['_HUGGINGFACEMODELSERVICE']._serialized_start=465
  _globals['_HUGGINGFACEMODELSERVICE']._serialized_end=1389
# @@protoc_insertion_point(module_scope)
