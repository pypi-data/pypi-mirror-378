# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: mytransformers/HuggingFaceTokenizer.proto
# Protobuf Python Version: 5.29.0
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import runtime_version as _runtime_version
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
_runtime_version.ValidateProtobufRuntimeVersion(
    _runtime_version.Domain.PUBLIC,
    5,
    29,
    0,
    '',
    'mytransformers/HuggingFaceTokenizer.proto'
)
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from gRPC_impl import shared_msg_types_pb2 as shared__msg__types__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n)mytransformers/HuggingFaceTokenizer.proto\x12\x0emytransformers\x1a\x16shared_msg_types.proto\"`\n\x12\x65ncodePlus_request\x12\x16\n\x0etokenizer_uuid\x18\x01 \x01(\t\x12\x0c\n\x04text\x18\x02 \x01(\t\x12$\n\x06kwargs\x18\x03 \x03(\x0b\x32\x14.shared.keyValuePair\";\n\x17tokenizer_key_uuid_pair\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x13\n\x0btensor_uuid\x18\x02 \x01(\t\"c\n\x13\x65ncodePlus_response\x12\x15\n\rencoding_uuid\x18\x01 \x01(\t\x12\x35\n\x04\x64\x61ta\x18\x02 \x03(\x0b\x32\'.mytransformers.tokenizer_key_uuid_pair\"@\n\x13setPadToken_request\x12\x16\n\x0etokenizer_uuid\x18\x01 \x01(\t\x12\x11\n\tpad_token\x18\x02 \x01(\t\"\x16\n\x14setPadToken_response\"i\n\x0e\x64\x65\x63ode_request\x12\x16\n\x0etokenizer_uuid\x18\x01 \x01(\t\x12\x19\n\x11input_tensor_uuid\x18\x02 \x01(\t\x12$\n\x06kwargs\x18\x03 \x03(\x0b\x32\x14.shared.keyValuePair\"\x1f\n\x0f\x64\x65\x63ode_response\x12\x0c\n\x04text\x18\x01 \x01(\t\"\xd4\x01\n\x1ftokenizerFromPretrained_request\x12%\n\x1dpretrained_model_name_or_path\x18\x01 \x01(\t\x12\x0e\n\x06inputs\x18\x02 \x03(\t\x12K\n\x06kwargs\x18\x03 \x03(\x0b\x32;.mytransformers.tokenizerFromPretrained_request.KwargsEntry\x1a-\n\x0bKwargsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\"\xcd\x01\n tokenizerFromPretrained_response\x12\x16\n\x0etokenizer_uuid\x18\x01 \x01(\t\x12[\n\x0especial_tokens\x18\x02 \x03(\x0b\x32\x43.mytransformers.tokenizerFromPretrained_response.SpecialTokensEntry\x1a\x34\n\x12SpecialTokensEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\x32\xf7\x06\n\x1bHuggingFaceTokenizerService\x12u\n\x10getAutoTokenizer\x12/.mytransformers.tokenizerFromPretrained_request\x1a\x30.mytransformers.tokenizerFromPretrained_response\x12u\n\x10getBertTokenizer\x12/.mytransformers.tokenizerFromPretrained_request\x1a\x30.mytransformers.tokenizerFromPretrained_response\x12x\n\x13getRobertaTokenizer\x12/.mytransformers.tokenizerFromPretrained_request\x1a\x30.mytransformers.tokenizerFromPretrained_response\x12s\n\x0egetT5Tokenizer\x12/.mytransformers.tokenizerFromPretrained_request\x1a\x30.mytransformers.tokenizerFromPretrained_response\x12v\n\x11getXLNetTokenizer\x12/.mytransformers.tokenizerFromPretrained_request\x1a\x30.mytransformers.tokenizerFromPretrained_response\x12X\n\x0b\x65ncode_plus\x12\".mytransformers.encodePlus_request\x1a#.mytransformers.encodePlus_response\"\x00\x12\\\n\rset_pad_token\x12#.mytransformers.setPadToken_request\x1a$.mytransformers.setPadToken_response\"\x00\x12K\n\x06\x64\x65\x63ode\x12\x1e.mytransformers.decode_request\x1a\x1f.mytransformers.decode_response\"\x00\x62\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'mytransformers.HuggingFaceTokenizer_pb2', _globals)
if not _descriptor._USE_C_DESCRIPTORS:
  DESCRIPTOR._loaded_options = None
  _globals['_TOKENIZERFROMPRETRAINED_REQUEST_KWARGSENTRY']._loaded_options = None
  _globals['_TOKENIZERFROMPRETRAINED_REQUEST_KWARGSENTRY']._serialized_options = b'8\001'
  _globals['_TOKENIZERFROMPRETRAINED_RESPONSE_SPECIALTOKENSENTRY']._loaded_options = None
  _globals['_TOKENIZERFROMPRETRAINED_RESPONSE_SPECIALTOKENSENTRY']._serialized_options = b'8\001'
  _globals['_ENCODEPLUS_REQUEST']._serialized_start=85
  _globals['_ENCODEPLUS_REQUEST']._serialized_end=181
  _globals['_TOKENIZER_KEY_UUID_PAIR']._serialized_start=183
  _globals['_TOKENIZER_KEY_UUID_PAIR']._serialized_end=242
  _globals['_ENCODEPLUS_RESPONSE']._serialized_start=244
  _globals['_ENCODEPLUS_RESPONSE']._serialized_end=343
  _globals['_SETPADTOKEN_REQUEST']._serialized_start=345
  _globals['_SETPADTOKEN_REQUEST']._serialized_end=409
  _globals['_SETPADTOKEN_RESPONSE']._serialized_start=411
  _globals['_SETPADTOKEN_RESPONSE']._serialized_end=433
  _globals['_DECODE_REQUEST']._serialized_start=435
  _globals['_DECODE_REQUEST']._serialized_end=540
  _globals['_DECODE_RESPONSE']._serialized_start=542
  _globals['_DECODE_RESPONSE']._serialized_end=573
  _globals['_TOKENIZERFROMPRETRAINED_REQUEST']._serialized_start=576
  _globals['_TOKENIZERFROMPRETRAINED_REQUEST']._serialized_end=788
  _globals['_TOKENIZERFROMPRETRAINED_REQUEST_KWARGSENTRY']._serialized_start=743
  _globals['_TOKENIZERFROMPRETRAINED_REQUEST_KWARGSENTRY']._serialized_end=788
  _globals['_TOKENIZERFROMPRETRAINED_RESPONSE']._serialized_start=791
  _globals['_TOKENIZERFROMPRETRAINED_RESPONSE']._serialized_end=996
  _globals['_TOKENIZERFROMPRETRAINED_RESPONSE_SPECIALTOKENSENTRY']._serialized_start=944
  _globals['_TOKENIZERFROMPRETRAINED_RESPONSE_SPECIALTOKENSENTRY']._serialized_end=996
  _globals['_HUGGINGFACETOKENIZERSERVICE']._serialized_start=999
  _globals['_HUGGINGFACETOKENIZERSERVICE']._serialized_end=1886
# @@protoc_insertion_point(module_scope)
