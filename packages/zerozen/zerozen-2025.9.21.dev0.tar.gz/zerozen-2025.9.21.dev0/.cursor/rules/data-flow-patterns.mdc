---
description: Analysis of data flow patterns between components including agent communication, memory integration, and external service interactions
---


# data-flow-patterns

## Core Data Flow Paths

### Agent Communication Flow (Importance: 85)
- Agent triage system in `src/zerozen/agenthub/main.py` routes requests between specialized agents:
  1. Main triage agent receives initial user request
  2. Request analyzed and routed to specialized agent (memory, Google, etc.)
  3. Specialized agent processes request and returns response
  4. Response flows back through triage to user

### Memory System Integration (Importance: 90)
- Bidirectional flow between agents and memory system:
  1. Memory agent (`src/zerozen/agenthub/memagent.py`) receives queries
  2. Queries converted to embeddings via `src/zerozen/memory/embedding.py`
  3. LanceDB performs semantic search on embeddings
  4. Relevant conversation history returned to agent
  5. New conversations stored back in memory system

### Google Service Integration (Importance: 80)
- Multi-stage OAuth flow and data access pattern:
  1. Credential management (`src/zerozen/integrations/google/creds.py`) handles auth flow
  2. Google agent (`src/zerozen/integrations/google/google_agent.py`) receives requests
  3. Requests routed to specific tools:
     - Gmail tool fetches email data
     - Calendar tool retrieves event information
  4. Data processed and returned with privacy constraints enforced

### Cross-Component Data Exchange (Importance: 75)
Data flows between major components follow structured paths:
- Agent Hub → Memory System: Conversation storage/retrieval
- Agent Hub → Google Integration: Service requests/responses
- Memory System → Embedding Service: Text vectorization
- Google Integration → Tools: API data access

Key file paths implementing these flows:
```
src/zerozen/agenthub/main.py
src/zerozen/memory/api.py
src/zerozen/integrations/google/main.py
src/zerozen/memory/embedding.py
```

$END$

 If you're using this file in context, clearly say in italics in one small line that "Context added by Giga data-flow-patterns" along with specifying exactly what information was used from this file in a human-friendly way, instead of using kebab-case use normal sentence case.