{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3974a398",
   "metadata": {},
   "source": [
    "# Lesson 10: Memory for Agents\n",
    "\n",
    "This lesson explores the concept of adding **long-term memory** to agents, so they can persist and retrieve information over time. \n",
    "\n",
    "We’ll implement semantic, episodic, and procedural memory using the open-source mem0 library with Google's Gemini text embedding model, and a vector store that runs locally in the notebook, using ChromaDB. \n",
    "\n",
    "\n",
    "Learning Objectives:\n",
    "\n",
    "1. Understand the different types of memory \n",
    "2. How to implement them, using the mem0 library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce8c3ae",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "First, we define some standard Magic Python commands to autoreload Python packages whenever they change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eca0f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854700aa",
   "metadata": {},
   "source": [
    "### Set Up Python Environment\n",
    "\n",
    "To set up your Python virtual environment using `uv` and use it in the Notebook, follow the step-by-step instructions from the [Course Admin](https://academy.towardsai.net/courses/take/agent-engineering/multimedia/67469688-lesson-1-part-2-course-admin) lesson from the beginning of the course.\n",
    "\n",
    "**TL/DR:** Be sure the correct kernel pointing to your `uv` virtual environment is selected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc69dfa",
   "metadata": {},
   "source": [
    "### Configure Gemini API\n",
    "\n",
    "To configure the Gemini API, follow the step-by-step instructions from the [Course Admin](https://academy.towardsai.net/courses/take/agent-engineering/multimedia/67469688-lesson-1-part-2-course-admin) lesson.\n",
    "\n",
    "But here is a quick check on what you need to run this Notebook:\n",
    "\n",
    "1.  Get your key from [Google AI Studio](https://aistudio.google.com/app/apikey).\n",
    "2.  From the root of your project, run: `cp .env.example .env` \n",
    "3.  Within the `.env` file, fill in the `GOOGLE_API_KEY` variable:\n",
    "\n",
    "Now, the code below will load the key from the `.env` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "334f7f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded from `/Users/fabio/Desktop/course-ai-agents/.env`\n",
      "Environment variables loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from utils import env\n",
    "\n",
    "env.load(required_env_vars=[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fd0942",
   "metadata": {},
   "source": [
    "### Import Key Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa9cb7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import Optional\n",
    "\n",
    "from google import genai\n",
    "from mem0 import Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5708a96",
   "metadata": {},
   "source": [
    "### Initialize the Gemini Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36d28218",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4388a20",
   "metadata": {},
   "source": [
    "### Define Constants\n",
    "\n",
    "We will use the `gemini-2.5-flash` model, which is fast and cost-effective:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4feb5354",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"gemini-2.5-pro\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc334dc7",
   "metadata": {},
   "source": [
    "### Configure mem0 (Gemini LLM + embeddings + local vector store)\n",
    "\n",
    "Here we instantiate mem0 with:\n",
    "\n",
    "- LLM: our existing Gemini model (`MODEL_ID = \"gemini-2.5-flash\"`) for the summarization/extraction of facts.\n",
    "- Embeddings: Gemini’s `text-embedding-004` (dimension 768).\n",
    "- Vector store:\n",
    "    - ChromaDB with `MEM_BACKEND=chromadb` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fb81ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Mem0 ready (Gemini embeddings + in-memory Chroma).\n"
     ]
    }
   ],
   "source": [
    "MEM0_CONFIG = {\n",
    "    # Use Google's text-embedding-004 (768-dim) for embeddings\n",
    "    \"embedder\": {\n",
    "        \"provider\": \"gemini\",\n",
    "        \"config\": {\n",
    "            \"model\": \"text-embedding-004\",\n",
    "            \"embedding_dims\": 768,\n",
    "            \"api_key\": os.getenv(\"GOOGLE_API_KEY\"),\n",
    "        },\n",
    "    },\n",
    "    # Use ChromaDB as a local, in-notebook vector store (ephemeral, in-memory)\n",
    "    \"vector_store\": {\n",
    "        \"provider\": \"chroma\",\n",
    "        \"config\": {\n",
    "            \"collection_name\": \"lesson9_memories\",\n",
    "        },\n",
    "    },\n",
    "    \"llm\": {\n",
    "        \"provider\": \"gemini\",\n",
    "        \"config\": {\n",
    "            \"model\": MODEL_ID,\n",
    "            \"api_key\": os.getenv(\"GOOGLE_API_KEY\"),\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "memory = Memory.from_config(MEM0_CONFIG)\n",
    "MEM_USER_ID = \"lesson9_notebook_student\"\n",
    "memory.delete_all(user_id=MEM_USER_ID)\n",
    "print(\"✅ Mem0 ready (Gemini embeddings + in-memory Chroma).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356970b6",
   "metadata": {},
   "source": [
    "### Helper functions: add/search for memories\n",
    "\n",
    "A small wrapper layer around mem0 to:\n",
    "\n",
    "- Save a string memory and tag it with a category (\"semantic\", \"episodic\", \"procedure\") plus any extra metadata.\n",
    "    - `mem_add_text` stores verbatim text with infer=False (no LLM fact extraction triggered by mem0). It also changes and all metadata values to primitives (str | int | float | bool | None) since mem0 requires primitive types.\n",
    "\n",
    "- Search memories and (optionally) filter by category client-side.\n",
    "    - `mem_search` calls memory.search(...) and then inspects each hit’s metadata to filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8de83b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mem_add_text(text: str, category: str = \"semantic\", **meta) -> str:\n",
    "    \"\"\"Add a single text memory. No LLM is used for extraction or summarization.\"\"\"\n",
    "    metadata = {\"category\": category}\n",
    "    for k, v in meta.items():\n",
    "        if isinstance(v, (str, int, float, bool)) or v is None:\n",
    "            metadata[k] = v\n",
    "        else:\n",
    "            metadata[k] = str(v)\n",
    "    memory.add(text, user_id=MEM_USER_ID, metadata=metadata, infer=False)\n",
    "    return f\"Saved {category} memory.\"\n",
    "\n",
    "\n",
    "def mem_search(query: str, limit: int = 5, category: Optional[str] = None) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Category-aware search wrapper.\n",
    "    Returns the full result dicts so we can inspect metadata.\n",
    "    \"\"\"\n",
    "    res = memory.search(query, user_id=MEM_USER_ID, limit=limit) or {}\n",
    "\n",
    "    items = res.get(\"results\", [])\n",
    "    if category is not None:\n",
    "        items = [r for r in items if (r.get(\"metadata\") or {}).get(\"category\") == category]\n",
    "    return items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b21d67e",
   "metadata": {},
   "source": [
    "## 2. Semantic memory example (facts as atomic strings)\n",
    "\n",
    "**Goal**: We show semantic memory as “facts & preferences” stored as short, individual strings.\n",
    "\n",
    "- We insert a few example facts (e.g., “User has a dog named George”).\n",
    "\n",
    "- Then we search with a natural query (e.g., “brother job”) and see the relevant fact returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d46ea78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved semantic memory.\n",
      "Saved semantic memory.\n",
      "Saved semantic memory.\n",
      "Saved semantic memory.\n",
      "Added 4 semantic memories.\n"
     ]
    }
   ],
   "source": [
    "facts: list[str] = [\n",
    "    \"User prefers vegetarian meals.\",\n",
    "    \"User has a dog named George.\",\n",
    "    \"User is allergic to gluten.\",\n",
    "    \"User's brother is named Mark and is a software engineer.\",\n",
    "]\n",
    "for f in facts:\n",
    "    print(mem_add_text(f, category=\"semantic\"))\n",
    "\n",
    "print(f\"Added {len(facts)} semantic memories.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d7d1313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User's brother is named Mark and is a software engineer.\n",
      "{'id': '68fa87b4-5cad-41c0-b06d-143e92ba7c66', 'memory': \"User's brother is named Mark and is a software engineer.\", 'hash': '9a01dbd8ea8b96f8ed9c84e9dcdb55a1', 'metadata': {'category': 'semantic'}, 'score': 0.9269160032272339, 'created_at': '2025-09-12T02:29:53.515480-07:00', 'updated_at': None, 'user_id': 'lesson9_notebook_student', 'role': 'user'}\n"
     ]
    }
   ],
   "source": [
    "# Search for a specific fact\n",
    "results = memory.search(\"brother job\", user_id=MEM_USER_ID, limit=1)\n",
    "# We print the memory string\n",
    "print(results[\"results\"][0][\"memory\"])\n",
    "# We print the whole dict that contains the memory\n",
    "print(results[\"results\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c54022",
   "metadata": {},
   "source": [
    "## 3. Episodic memory example (summarize 3–4 turns → one episode)\n",
    "\n",
    "**Goal**: Demonstrate episodic memory (experiences & history).\n",
    "\n",
    "- We create a short 3–4 turn exchange between user and assistant.\n",
    "\n",
    "- We ask the LLM to produce a concise episode summary (1–2 sentences) and save it under category=\"episodic\".\n",
    "\n",
    "- Finally, we run a semantic search (e.g., “deadline stress”) to retrieve that episode, we print the memory along with its creation timestamp.\n",
    "\n",
    "This example show how an agent can compress transient chat into a single durable “moment.”\n",
    "\n",
    "Since mem0 by default creates a created_at timestamp, we have the possibility to use it to sort and filter memories.\n",
    "It would then be possible to answer questions like \"What did we talk about last week?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fe99984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A user, stressed about a Friday project deadline because of testing and a preference for working at night, is advised to split the testing work into two manageable sessions.\n"
     ]
    }
   ],
   "source": [
    "# A short 4-turn exchange we want to compress into one \"episode\"\n",
    "dialogue = [\n",
    "    {\"role\": \"user\", \"content\": \"I'm stressed about my project deadline on Friday.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"I’m here to help—what’s the blocker?\"},\n",
    "    {\"role\": \"user\", \"content\": \"Mainly testing. I also prefer working at night.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Okay, we can split testing into two sessions.\"},\n",
    "]\n",
    "\n",
    "# Ask the LLM to write a clear episodic summary.\n",
    "episodic_prompt = f\"\"\"Summarize the following 3–4 turns as one concise 'episode' (1–2 sentences).\n",
    "Keep salient details and tone.\n",
    "\n",
    "{dialogue}\n",
    "\"\"\"\n",
    "episode_summary = client.models.generate_content(model=MODEL_ID, contents=episodic_prompt)\n",
    "episode = episode_summary.text.strip()\n",
    "print(episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59e2ee43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved episodic memory.\n",
      "\n",
      "Search --> 'deadline stress'\n",
      "\n",
      "A user, stressed about a Friday project deadline because of testing and a preference for working at night, is advised to split the testing work into two manageable sessions.\n",
      "\n",
      "{'id': '93ebb9eb-65b0-4975-9c0d-105497b43e5c', 'memory': 'A user, stressed about a Friday project deadline because of testing and a preference for working at night, is advised to split the testing work into two manageable sessions.', 'hash': '44f0bcd0965a1fb557c1d3b5a9f8ae6c', 'metadata': {'turns': 4, 'summarized': True, 'category': 'episodic'}, 'score': 0.9109697937965393, 'created_at': '2025-09-12T02:30:01.358468-07:00', 'updated_at': None, 'user_id': 'lesson9_notebook_student', 'role': 'user'}\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    mem_add_text(\n",
    "        episode,\n",
    "        category=\"episodic\",\n",
    "        summarized=True,\n",
    "        turns=4,\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"\\nSearch --> 'deadline stress'\\n\")\n",
    "hits = mem_search(\"deadline stress\", limit=1, category=\"episodic\")\n",
    "for h in hits:\n",
    "    print(f\"{h['memory']}\\n\")\n",
    "    print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d94159",
   "metadata": {},
   "source": [
    "## 4. Procedural memory example (learn & “run” a skill)\n",
    "\n",
    "**Goal**: Demonstrate procedural memory (skills & workflows).\n",
    "\n",
    "- We teach the agent a small procedure (e.g., monthly_report) by saving ordered steps in a single text block under category=\"procedure\".\n",
    "\n",
    "- We retrieve the procedure and parse the numbered steps to simulate “running” it.\n",
    "\n",
    "This example shows how agents can learn reusable playbooks and trigger them later by name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efb5caa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned procedure: monthly_report\n"
     ]
    }
   ],
   "source": [
    "procedure_name = \"monthly_report\"\n",
    "steps = [\n",
    "    \"Query sales DB for the last 30 days.\",\n",
    "    \"Summarize top 5 insights.\",\n",
    "    \"Ask user whether to email or display.\",\n",
    "]\n",
    "procedure_text = f\"Procedure: {procedure_name}\\nSteps:\\n\" + \"\\n\".join(f\"{i + 1}. {s}\" for i, s in enumerate(steps))\n",
    "\n",
    "mem_add_text(procedure_text, category=\"procedure\", procedure_name=procedure_name)\n",
    "\n",
    "print(f\"Learned procedure: {procedure_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2fcd684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procedure: monthly_report\n",
      "Steps:\n",
      "1. Query sales DB for the last 30 days.\n",
      "2. Summarize top 5 insights.\n",
      "3. Ask user whether to email or display.\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the procedure by name\n",
    "results = mem_search(\"how to create a monthly report\", category=\"procedure\", limit=1)\n",
    "if results:\n",
    "    print(results[0][\"memory\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
