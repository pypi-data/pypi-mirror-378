{
    "config": {
        "thread_id": "6bb72685-8ac9-48d4-8eeb-2e73d0098f6c",
        "article_id": "11_multimodal",
        "enable_human_review": null
    },
    "num_chars_article": 61573,
    "num_chars_conclusion": 812,
    "num_chars_introduction": 876,
    "num_sections": 6,
    "num_words_article": 6846,
    "num_words_conclusion": 128,
    "num_words_introduction": 127,
    "sections": {
        "Limitations of traditional document processing": {
            "num_chars": 3254,
            "num_words": 415
        },
        "Foundations of multimodal LLMs": {
            "num_chars": 8889,
            "num_words": 924
        },
        "Applying multimodal LLMs to images and PDFs": {
            "num_chars": 22147,
            "num_words": 2541
        },
        "Foundations of multimodal RAG": {
            "num_chars": 5853,
            "num_words": 691
        },
        "Implementing multimodal RAG for images, PDFs and text": {
            "num_chars": 9522,
            "num_words": 1042
        },
        "Building multimodal AI agents": {
            "num_chars": 5267,
            "num_words": 636
        }
    },
    "seo": {
        "title": "Multimodal AI: See, Hear, Feel",
        "description": "Unlock the power of Multimodal AI! Learn to build AI agents that see, hear, & feel beyond text. Explore LLMs, RAG, & MLOps for images, PDFs, & more. Master AI engineering now!"
    }
}