{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constelation optimization performance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ephemerista\n",
    "\n",
    "ephemerista.init(eop_path=\"../../tests/resources/finals2000A.all.csv\", spk_path=\"../../tests/resources/de440s.bsp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import deap.base\n",
    "import deap.creator\n",
    "import deap.tools\n",
    "import geojson_pydantic\n",
    "import numpy as np\n",
    "from deap import algorithms, tools\n",
    "\n",
    "from ephemerista.analysis.coverage import Coverage\n",
    "from ephemerista.constellation.design import Constellation, WalkerStar\n",
    "from ephemerista.scenarios import Scenario\n",
    "from ephemerista.time import Time, TimeDelta\n",
    "\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are lower values than the ones used in the optimization notebook, so\n",
    "# that the tests run faster.\n",
    "\n",
    "TIME = Time.from_iso(\"TDB\", \"2016-05-30T12:00:00\")\n",
    "START_TIME = Time.from_iso(\"TDB\", \"2016-05-30T12:00:00\")\n",
    "END_TIME = START_TIME + TimeDelta.from_hours(4)\n",
    "PENALTY = 1e3\n",
    "DISCRETIZATION_RESOLUTION = 15\n",
    "\n",
    "LOWER_BOUND_SATS = 5\n",
    "UPPER_BOUND_SATS = 15\n",
    "LOWER_BOUND_PLANES = 1\n",
    "UPPER_BOUND_PLANES = 15\n",
    "\n",
    "POPULATION_SIZE = 20\n",
    "GENERATIONS = 10\n",
    "\n",
    "HALL_OF_FAME_LEN = 20\n",
    "\n",
    "with open(\"../single_aoi.geojson\") as f:\n",
    "    AOI = geojson_pydantic.FeatureCollection.model_validate_json(f.read())\n",
    "\n",
    "global_hof_result: deap.tools.HallOfFame | list = []\n",
    "global_evaluate_constellation_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%prun\n",
    "\n",
    "\n",
    "def evaluate_constellation(\n",
    "    individual,\n",
    "    time: Time = TIME,\n",
    "    start_time: Time = START_TIME,\n",
    "    end_time: Time = END_TIME,\n",
    "    aoi: geojson_pydantic.FeatureCollection = AOI,\n",
    "    discretization_resolution: int = DISCRETIZATION_RESOLUTION,\n",
    "    penalty: float = PENALTY,\n",
    "    evaluate_constellation_cache: dict = global_evaluate_constellation_cache,\n",
    ") -> tuple:\n",
    "    print(f\"Evaluating individual: {individual}\")  # noqa: T201\n",
    "    nsats, nplanes = individual\n",
    "    if (nsats, nplanes) in evaluate_constellation_cache:\n",
    "        print(f\"Using cached result for {nsats} satellites and {nplanes} planes\")  # noqa: T201\n",
    "        individual.fitness.values = evaluate_constellation_cache[(nsats, nplanes)][0]\n",
    "        mean_cov = evaluate_constellation_cache[(nsats, nplanes)][1]\n",
    "        return nsats, mean_cov\n",
    "\n",
    "    constellation = Constellation(\n",
    "        model=WalkerStar(\n",
    "            time=time,\n",
    "            nsats=nsats,\n",
    "            nplanes=nplanes,\n",
    "            semi_major_axis=7000,\n",
    "            inclination=45,\n",
    "            eccentricity=0.0,\n",
    "            periapsis_argument=90,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    scenario = Scenario(\n",
    "        name=\"Coverage analysis with constellation\",\n",
    "        start_time=start_time,\n",
    "        end_time=end_time,\n",
    "        areas_of_interest=aoi,\n",
    "        time_step=600,\n",
    "        constellations=[constellation],\n",
    "        discretization_resolution=discretization_resolution,\n",
    "    )\n",
    "\n",
    "    cov = Coverage(scenario=scenario)\n",
    "    results = cov.analyze()\n",
    "    mean_cov = np.array(results.coverage_percent).mean()\n",
    "    individual.fitness.values = (-nsats * penalty, mean_cov)\n",
    "    print(f\"Evaluated individual: {individual} with fitness {individual.fitness}\")  # noqa: T201\n",
    "    evaluate_constellation_cache[(nsats, nplanes)] = (individual.fitness.values, mean_cov, results)\n",
    "    return nsats, mean_cov\n",
    "\n",
    "\n",
    "def optimize_constellation(\n",
    "    pop_size=20,\n",
    "    generations=50,\n",
    "    hall_of_fame_len=1,\n",
    "    time: Time = TIME,\n",
    "    start_time: Time = START_TIME,\n",
    "    end_time: Time = END_TIME,\n",
    "    aoi: geojson_pydantic.FeatureCollection = AOI,\n",
    "    penalty: float = PENALTY,\n",
    "    lower_bound_sats: int = LOWER_BOUND_SATS,\n",
    "    upper_bound_sats: int = UPPER_BOUND_SATS,\n",
    "    lower_bound_planes: int = LOWER_BOUND_PLANES,\n",
    "    upper_bound_planes: int = UPPER_BOUND_PLANES,\n",
    ") -> deap.tools.HallOfFame:\n",
    "    # We use this function and not define evaluate_constellation here so we can profile the function\n",
    "    def evaluate(individual) -> tuple:\n",
    "        return evaluate_constellation(individual, time, start_time, end_time, aoi, penalty)\n",
    "\n",
    "    # Minimize number of satellites while maximizing coverage while favoring the latter\n",
    "    deap.creator.create(\"FitnessMulti\", deap.base.Fitness, weights=(-0.5, 1.0))\n",
    "    deap.creator.create(\"Individual\", list, fitness=deap.creator.FitnessMulti)  # type: ignore\n",
    "\n",
    "    def init_individual():\n",
    "        \"\"\"Randomly generate an individual ensuring integer values.\"\"\"\n",
    "        num_sats = random.randint(lower_bound_sats, upper_bound_sats)  # noqa: S311\n",
    "        num_planes = random.randint(lower_bound_planes, upper_bound_sats)  # noqa: S311\n",
    "\n",
    "        num_sats = max(num_planes, (num_sats // num_planes) * num_planes)\n",
    "\n",
    "        indi = deap.creator.Individual([num_sats, num_planes])  # type: ignore\n",
    "        print(f\"Initialized individual: {indi} with fitness {indi.fitness.values}\")  # noqa: T201\n",
    "        return indi\n",
    "\n",
    "    def mutate(individual, mu=0, sigma=5, indpb=0.2):\n",
    "        print(f\"Mutating individual {individual} with fitness {individual.fitness.values}\")  # noqa: T201\n",
    "        num_sats, num_planes = individual\n",
    "\n",
    "        # Apply Gaussian mutation\n",
    "        if random.random() < indpb:  # noqa: S311\n",
    "            num_sats += int(random.gauss(mu, sigma))\n",
    "        if random.random() < indpb:  # noqa: S311\n",
    "            num_planes += int(random.gauss(mu, sigma))\n",
    "\n",
    "        # Enforce bounds and ensure integers\n",
    "        num_sats = max(lower_bound_sats, min(upper_bound_sats, round(num_sats)))\n",
    "        num_planes = max(lower_bound_planes, min(upper_bound_planes, round(num_planes)))\n",
    "\n",
    "        num_sats = max(num_planes, (num_sats // num_planes) * num_planes)\n",
    "\n",
    "        individual[:] = [num_sats, num_planes]\n",
    "        print(f\"Mutated individual: {individual} with fitness {individual.fitness.values}\")  # noqa: T201\n",
    "        return (individual,)\n",
    "\n",
    "    def crossover(ind1, ind2, indpb=0.5):\n",
    "        print(f\"Crossover between {ind1} with fitness {ind1.fitness} and {ind2} with fitness {ind2.fitness}\")  # noqa: T201\n",
    "        for i in range(len(ind1)):\n",
    "            if random.random() < indpb:  # Each gene has probability `indpb` of swapping  # noqa: S311\n",
    "                ind1[i], ind2[i] = ind2[i], ind1[i]  # Swap values\n",
    "\n",
    "        # Ensure num_sats remains divisible by num_planes\n",
    "        for ind in [ind1, ind2]:\n",
    "            num_sats, num_planes = ind\n",
    "            if num_planes > 0:\n",
    "                num_sats = max(num_planes, (num_sats // num_planes) * num_planes)\n",
    "            ind[:] = [num_sats, num_planes]  # Assign values back\n",
    "            del ind.fitness.values  # Invalidate fitness to force re-evaluation\n",
    "\n",
    "        print(  # noqa: T201\n",
    "            \"Resulting individuals after crossover: \"\n",
    "            f\"{ind1} with fitness {ind1.fitness} and {ind2} with fitness {ind2.fitness}\"\n",
    "        )\n",
    "        return ind1, ind2\n",
    "\n",
    "    toolbox = deap.base.Toolbox()\n",
    "\n",
    "    toolbox.register(\"individual\", init_individual)\n",
    "    toolbox.register(\"population\", deap.tools.initRepeat, list, toolbox.individual)  # type: ignore\n",
    "    toolbox.register(\"evaluate\", evaluate)\n",
    "    toolbox.register(\"mate\", crossover, indpb=0.5)  # Blend crossover\n",
    "    toolbox.register(\"mutate\", mutate, mu=0, sigma=5, indpb=0.2)  # Gaussian mutation\n",
    "    toolbox.register(\"select\", deap.tools.selTournament, tournsize=2)\n",
    "\n",
    "    stats = tools.Statistics(key=lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean, axis=0)\n",
    "    stats.register(\"std\", np.std, axis=0)\n",
    "    stats.register(\"min\", np.min, axis=0)\n",
    "    stats.register(\"max\", np.max, axis=0)\n",
    "\n",
    "    hof = deap.tools.HallOfFame(hall_of_fame_len)\n",
    "    pop = toolbox.population(n=pop_size)  # type: ignore\n",
    "    print(f\"Initial population {[(p, p.fitness.values) for p in pop]}\")  # noqa: T201\n",
    "\n",
    "    pop = algorithms.eaSimple(\n",
    "        pop, toolbox, cxpb=0.5, mutpb=0.1, ngen=generations, stats=stats, halloffame=hof, verbose=True\n",
    "    )\n",
    "    print(f\"Hall of Fame: {hof}\")  # noqa: T201\n",
    "\n",
    "    best_sats, best_planes = hof[0]\n",
    "    best_cost = evaluate_constellation(hof[0])[0]\n",
    "\n",
    "    print(f\"Optimal Constellation: {best_sats} satellites, {best_planes} planes, Cost: {best_cost}\")  # noqa: T201\n",
    "\n",
    "    # Store the global Hall of Fame result, so we can access it later even if profiling\n",
    "    global global_hof_result  # noqa\n",
    "    global_hof_result = hof\n",
    "\n",
    "    return hof\n",
    "\n",
    "\n",
    "optimize_constellation(pop_size=POPULATION_SIZE, generations=GENERATIONS, hall_of_fame_len=HALL_OF_FAME_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "functions_to_profile = \"-f optimize_constellation -f evaluate_constellation -f Coverage.analyze\"\n",
    "function_call = (\n",
    "    \"optimize_constellation(pop_size=POPULATION_SIZE, \",\n",
    "    \"generations=GENERATIONS, hall_of_fame_len=HALL_OF_FAME_LEN)\",\n",
    ")\n",
    "\n",
    "%lprun -u 1 {functions_to_profile} {function_call}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_coverage(\n",
    "    nsats,\n",
    "    nplanes,\n",
    "    time: Time = TIME,\n",
    "    start_time: Time = START_TIME,\n",
    "    end_time: Time = END_TIME,\n",
    "    discretization_resolution: int = DISCRETIZATION_RESOLUTION,\n",
    "    aoi: geojson_pydantic.FeatureCollection = AOI,\n",
    "):\n",
    "    constellation = Constellation(\n",
    "        model=WalkerStar(\n",
    "            time=time,\n",
    "            nsats=nsats,\n",
    "            nplanes=nplanes,\n",
    "            semi_major_axis=7000,\n",
    "            inclination=45,\n",
    "            eccentricity=0.0,\n",
    "            periapsis_argument=90,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    scenario = Scenario(\n",
    "        name=\"Coverage analysis with constellation\",\n",
    "        start_time=start_time,\n",
    "        end_time=end_time,\n",
    "        areas_of_interest=aoi,\n",
    "        discretization_resolution=discretization_resolution,\n",
    "        time_step=600,\n",
    "        constellations=[constellation],\n",
    "    )\n",
    "\n",
    "    cov = Coverage(scenario=scenario)\n",
    "    results = cov.analyze()\n",
    "    print(f\"Coverage results for {nsats} satellites and {nplanes} planes: {results.coverage_percent}\")  # noqa: T201\n",
    "    results.plot_mpl(legend=True, cmap=\"viridis\", plot_land=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for constellation in global_hof_result:\n",
    "    nsats, nplanes = constellation\n",
    "    print(f\"Plotting coverage for {nsats} satellites and {nplanes} planes\")  # noqa: T201\n",
    "    plot_coverage(nsats=nsats, nplanes=nplanes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ephemerista",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
