{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"7ab9b32b","cell_type":"markdown","source":"# Ariel data challenge submission\n\n## 1. Notebook set up","metadata":{}},{"id":"0ff23202-ae87-4f5c-8c0a-486570d42d58","cell_type":"code","source":"# Standard library imports\nimport random\n\n# Project imports\nfrom ariel_data_preprocessing.data_preprocessing import DataProcessor\n\n# Globals\nINPUT_DIRECTORY = '/kaggle/input/ariel-data-challenge-2025'\nWORKING_DIRECTORY = '/kaggle/working'\nMODE = 'train'\nDATA_FILE = 'train.h5'\nWAVELENGTHS = 283 # Number of wavelength indicies\nSAMPLE_SIZE = 883 # Number of captures per sample\nSAMPLES = 10      # Number of sample to draw per planet\nN_CPUS = 3\nN_PLANETS = 100","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T03:31:38.752326Z","iopub.execute_input":"2025-09-21T03:31:38.752880Z","iopub.status.idle":"2025-09-21T03:31:38.761520Z","shell.execute_reply.started":"2025-09-21T03:31:38.752835Z","shell.execute_reply":"2025-09-21T03:31:38.760078Z"}},"outputs":[],"execution_count":3},{"id":"a9ea7cf3-07c1-4455-9f5d-7edd0aba475c","cell_type":"markdown","source":"## 2. Data preparation\n\n### 2.1. Preprocess the raw data","metadata":{}},{"id":"9e3e8e70-6752-4ed1-85d7-9dab6171fc97","cell_type":"code","source":"data_processor = DataProcessor(\n    input_data_path=INPUT_DIRECTORY,\n    output_data_path=WORKING_DIRECTORY,\n    output_file=DATA_FILE,\n    n_cpus=N_CPUS,\n    downsample_fgs=True,\n    n_planets=N_PLANETS,\n    mode=MODE\n)\n\ndata_processor.run()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T03:05:51.250803Z","iopub.execute_input":"2025-09-21T03:05:51.251396Z","iopub.status.idle":"2025-09-21T03:26:58.694143Z","shell.execute_reply.started":"2025-09-21T03:05:51.251366Z","shell.execute_reply":"2025-09-21T03:26:58.688390Z"}},"outputs":[],"execution_count":2},{"id":"00475a7f-5a15-400d-a6ec-09cf0830e615","cell_type":"markdown","source":"## 2.2. Planet IDs","metadata":{}},{"id":"c9d0a8b2-4ef5-48bd-9f89-6ca3d64d26c0","cell_type":"code","source":"# Load corrected/extracted data for a sample planet\nwith h5py.File(f'{WORKING_DIRECTORY}/{DATA_FILE}', 'r') as hdf:\n    planet_ids = list(hdf.keys())\n\nprint(f'Found {len(planet_ids)} planets.')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"7ee82e54-516f-43d6-b773-c5f7b670a004","cell_type":"markdown","source":"## 2.2. Data generator","metadata":{}},{"id":"c889b6c0-4831-464f-8933-85a0e099bcfe","cell_type":"code","source":"def prediction_data_loader(planet_ids: list, data_file: str, sample_size: int = 100, n_samples: int = 10):\n    '''Generator that yields signal, spectrum pairs for training/validation/testing.\n\n    Args:\n        planet_ids (list): List of planet IDs to include in the generator.\n        data_file (str): Path to the HDF5 file containing the data.\n        sample_size (int, optional): Number of frames to draw from each planet. Defaults to 100.\n    '''\n\n    with h5py.File(data_file, 'r') as hdf:\n\n        while True:\n            \n            for planet_id in planet_ids:\n\n                signal = hdf[planet_id]['signal'][:]\n                samples = []\n\n                for _ in range(n_samples):\n\n                    indices = random.sample(range(signal.shape[0]), sample_size)\n                    samples.append(signal[sorted(indices), :])\n\n                yield np.array(spectra)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T03:31:45.011814Z","iopub.execute_input":"2025-09-21T03:31:45.012123Z","iopub.status.idle":"2025-09-21T03:31:45.023277Z","shell.execute_reply.started":"2025-09-21T03:31:45.012103Z","shell.execute_reply":"2025-09-21T03:31:45.021967Z"}},"outputs":[],"execution_count":4},{"id":"5c692816-c7ea-47d2-977c-2cf4ed801770","cell_type":"code","source":"prediction_data_generator = partial(\n    prediction_data_loader,\n    planet_ids=planet_ids,\n    data_file=f'{WORKING_DIRECTORY}/{DATA_FILE}',\n    sample_size=SAMPLE_SIZE,\n    n_samples=SAMPLES\n)\n\nprediction_dataset = tf.data.Dataset.from_generator(\n    prediction_data_generator,\n    output_signature=(\n        tf.TensorSpec(shape=(SAMPLES, SAMPLE_SIZE, WAVELENGTHS), dtype=tf.float64),\n    )\n)\n\ndata = prediction_dataset.take(planets)\nsignals = np.array([element[0].numpy() for element in data])\nprint(f'Signals shape: {signals.shape}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"738865de-fcb1-409a-9fd0-c485ade40ae1","cell_type":"markdown","source":"## 3. Predictions","metadata":{}},{"id":"d55ed0cc-9393-435e-9785-3712532cd835","cell_type":"code","source":"spectrum_predictions = []\n\nfor planet in signals:\n    spectrum_predictions.append(model.predict(planet, batch_size=SAMPLES, verbose=0))\n\nspectrum_predictions = np.array(spectrum_predictions)\nspectrum_predictions_avg = np.mean(spectrum_predictions, axis=1).flatten()\nspectrum_predictions_std = np.std(spectrum_predictions, axis=1).flatten()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}