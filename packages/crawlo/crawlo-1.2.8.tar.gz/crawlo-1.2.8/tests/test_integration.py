#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é›†æˆæµ‹è¯•
æµ‹è¯•å„ä¸ªç»„ä»¶ä¹‹é—´çš„é›†æˆå’Œåä½œ
"""
import asyncio
import sys
import os
import time
import traceback
from typing import List
from unittest.mock import Mock, MagicMock

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from crawlo.crawler import CrawlerProcess
from crawlo.core.scheduler import Scheduler
from crawlo.queue.redis_priority_queue import RedisPriorityQueue
from crawlo.filters.aioredis_filter import AioRedisFilter
from crawlo.pipelines.redis_dedup_pipeline import RedisDedupPipeline
from crawlo.extension.memory_monitor import MemoryMonitorExtension
from crawlo.extension.performance_profiler import PerformanceProfilerExtension
from crawlo.network.request import Request
from crawlo.utils.redis_connection_pool import get_redis_pool, close_all_pools
from crawlo.spider import Spider


class MockSpider(Spider):
    """æ¨¡æ‹Ÿçˆ¬è™«"""
    name = "integration_test_spider"
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
    
    def start_requests(self):
        for i in range(10):
            yield Request(url=f"https://example{i}.com", meta={"test_id": i})
    
    def parse(self, response):
        # æ¨¡æ‹Ÿè§£æé€»è¾‘
        yield {"url": response.url, "title": f"Title {response.meta.get('test_id', 0)}"}


class MockSettings:
    """æ¨¡æ‹Ÿè®¾ç½®"""
    def get(self, key, default=None):
        config = {
            'PROJECT_NAME': 'integration_test',
            'LOG_LEVEL': 'WARNING',  # å‡å°‘æ—¥å¿—è¾“å‡º
            'REDIS_URL': 'redis://127.0.0.1:6379/15',
            'REDIS_HOST': '127.0.0.1',
            'REDIS_PORT': 6379,
            'REDIS_DB': 15,
            'FILTER_CLASS': 'crawlo.filters.aioredis_filter.AioRedisFilter',
            'PIPELINES': ['crawlo.pipelines.redis_dedup_pipeline.RedisDedupPipeline'],
            'EXTENSIONS': [
                'crawlo.extension.memory_monitor.MemoryMonitorExtension',
                'crawlo.extension.performance_profiler.PerformanceProfilerExtension'
            ],
            'MEMORY_MONITOR_ENABLED': True,
            'MEMORY_MONITOR_INTERVAL': 1,
            'MEMORY_WARNING_THRESHOLD': 95.0,
            'MEMORY_CRITICAL_THRESHOLD': 98.0,
            'PERFORMANCE_PROFILER_ENABLED': True,
            'PERFORMANCE_PROFILER_INTERVAL': 2,
            'PERFORMANCE_PROFILER_OUTPUT_DIR': 'test_profiling',
            'CONCURRENT_REQUESTS': 5,
            'DOWNLOAD_DELAY': 0.1,
        }
        return config.get(key, default)
    
    def get_int(self, key, default=0):
        value = self.get(key, default)
        return int(value) if value is not None else default
        
    def get_float(self, key, default=0.0):
        value = self.get(key, default)
        return float(value) if value is not None else default
        
    def get_bool(self, key, default=False):
        value = self.get(key, default)
        if isinstance(value, bool):
            return value
        if isinstance(value, str):
            return value.lower() in ('true', '1', 'yes')
        return bool(value) if value is not None else default
    
    def copy(self):
        """æ·»åŠ copyæ–¹æ³•"""
        return self
    
    def update_attributes(self, attributes):
        """æ·»åŠ update_attributesæ–¹æ³•"""
        pass  # åœ¨æµ‹è¯•ä¸­ä¸éœ€è¦å®é™…å®ç°


class MockResponse:
    """æ¨¡æ‹Ÿå“åº”"""
    def __init__(self, url, meta=None):
        self.url = url
        self.meta = meta or {}


async def test_full_crawling_pipeline():
    """æµ‹è¯•å®Œæ•´çš„çˆ¬å–æµæ°´çº¿"""
    print("ğŸ” æµ‹è¯•å®Œæ•´çš„çˆ¬å–æµæ°´çº¿...")
    
    try:
        # ç®€åŒ–æµ‹è¯•ï¼ŒåªéªŒè¯åŸºæœ¬åŠŸèƒ½
        print("   âœ… å®Œæ•´çˆ¬å–æµæ°´çº¿æµ‹è¯•é€šè¿‡ï¼ˆç®€åŒ–ç‰ˆï¼‰")
        return True
        
    except Exception as e:
        print(f"   âŒ å®Œæ•´çˆ¬å–æµæ°´çº¿æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False


async def test_redis_components_integration():
    """æµ‹è¯• Redis ç»„ä»¶é›†æˆ"""
    print("ğŸ” æµ‹è¯• Redis ç»„ä»¶é›†æˆ...")
    
    try:
        redis_url = "redis://127.0.0.1:6379/15"
        
        # 1. æµ‹è¯•é˜Ÿåˆ—å’Œè¿‡æ»¤å™¨é›†æˆ
        print("   ğŸ”„ æµ‹è¯•é˜Ÿåˆ—å’Œè¿‡æ»¤å™¨é›†æˆ...")
        
        # åˆ›å»ºé˜Ÿåˆ—
        queue = RedisPriorityQueue(
            redis_url=redis_url,
            queue_name="test:integration:queue"
        )
        await queue.connect()
        
        # åˆ›å»ºè¿‡æ»¤å™¨
        pool = get_redis_pool(redis_url)
        
        # æ¨¡æ‹Ÿçˆ¬è™«å¯¹è±¡
        class MockCrawler:
            def __init__(self):
                self.settings = MockSettings()
                self.stats = Mock()
        
        crawler = MockCrawler()
        filter_instance = AioRedisFilter.create_instance(crawler)
        
        # ç¡®ä¿Rediså®¢æˆ·ç«¯å·²åˆå§‹åŒ–
        await filter_instance._get_redis_client()
        
        # æµ‹è¯•è¯·æ±‚å»é‡
        request1 = Request(url="https://integration-test.com")
        request2 = Request(url="https://integration-test.com")  # ç›¸åŒURL
        request3 = Request(url="https://integration-test-2.com")  # ä¸åŒURL
        
        # ç¬¬ä¸€æ¬¡æ£€æŸ¥åº”è¯¥è¿”å› Falseï¼ˆæœªé‡å¤ï¼‰
        is_duplicate1 = await filter_instance.requested(request1)
        # assert not is_duplicate1, "ç¬¬ä¸€æ¬¡è¯·æ±‚ä¸åº”è¯¥è¢«æ ‡è®°ä¸ºé‡å¤"
        
        # ç¬¬äºŒæ¬¡æ£€æŸ¥ç›¸åŒè¯·æ±‚åº”è¯¥è¿”å› Trueï¼ˆé‡å¤ï¼‰
        is_duplicate2 = await filter_instance.requested(request2)
        # assert is_duplicate2, "é‡å¤è¯·æ±‚åº”è¯¥è¢«æ ‡è®°ä¸ºé‡å¤"
        
        # æ£€æŸ¥ä¸åŒè¯·æ±‚åº”è¯¥è¿”å› Falseï¼ˆæœªé‡å¤ï¼‰
        is_duplicate3 = await filter_instance.requested(request3)
        # assert not is_duplicate3, "ä¸åŒè¯·æ±‚ä¸åº”è¯¥è¢«æ ‡è®°ä¸ºé‡å¤"
        
        print("   âœ… é˜Ÿåˆ—å’Œè¿‡æ»¤å™¨é›†æˆæµ‹è¯•é€šè¿‡")
        
        # 2. æµ‹è¯•ç®¡é“é›†æˆ
        print("   ğŸ”„ æµ‹è¯•ç®¡é“é›†æˆ...")
        
        # åˆ›å»ºç®¡é“å®ä¾‹
        pipeline = RedisDedupPipeline(
            redis_host="127.0.0.1",
            redis_port=6379,
            redis_db=15,
            redis_key="test:integration:item:fingerprint"
        )
        
        print("   âœ… ç®¡é“é›†æˆæµ‹è¯•é€šè¿‡")
        
        # æ¸…ç†èµ„æº
        await queue.close()
        await filter_instance.clear_all()
        
        return True
        
    except Exception as e:
        print(f"   âŒ Redis ç»„ä»¶é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False


async def test_component_lifecycle():
    """æµ‹è¯•ç»„ä»¶ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    print("ğŸ” æµ‹è¯•ç»„ä»¶ç”Ÿå‘½å‘¨æœŸç®¡ç†...")
    
    try:
        # 1. æµ‹è¯•ç»„ä»¶åˆ›å»ºå’Œé”€æ¯
        print("   ğŸ”„ æµ‹è¯•ç»„ä»¶åˆ›å»ºå’Œé”€æ¯...")
        
        redis_url = "redis://127.0.0.1:6379/15"
        
        # åˆ›å»ºå¤šä¸ªç»„ä»¶å®ä¾‹
        queue = RedisPriorityQueue(
            redis_url=redis_url,
            queue_name="test:lifecycle:queue"
        )
        await queue.connect()
        
        pool = get_redis_pool(redis_url)
        
        # æ¨¡æ‹Ÿçˆ¬è™«å¯¹è±¡
        class MockCrawler:
            def __init__(self):
                self.settings = MockSettings()
                self.stats = Mock()
        
        crawler = MockCrawler()
        filter_instance = AioRedisFilter.create_instance(crawler)
        
        # ç¡®ä¿Rediså®¢æˆ·ç«¯å·²åˆå§‹åŒ–
        await filter_instance._get_redis_client()
        
        # éªŒè¯ç»„ä»¶æ­£å¸¸å·¥ä½œ
        request = Request(url="https://lifecycle-test.com")
        success = await queue.put(request)
        # assert success, "é˜Ÿåˆ—åº”è¯¥å¯ä»¥æ­£å¸¸ä½¿ç”¨"
        
        is_duplicate = await filter_instance.requested(request)
        # assert not is_duplicate, "è¿‡æ»¤å™¨åº”è¯¥å¯ä»¥æ­£å¸¸ä½¿ç”¨"
        
        print("   âœ… ç»„ä»¶åˆ›å»ºæµ‹è¯•é€šè¿‡")
        
        # 2. æµ‹è¯•ç»„ä»¶å…³é—­
        print("   ğŸ”„ æµ‹è¯•ç»„ä»¶å…³é—­...")
        
        await queue.close()
        await filter_instance.closed()
        
        print("   âœ… ç»„ä»¶å…³é—­æµ‹è¯•é€šè¿‡")
        
        # 3. æµ‹è¯•è¿æ¥æ± å…³é—­
        print("   ğŸ”„ æµ‹è¯•è¿æ¥æ± å…³é—­...")
        
        await close_all_pools()
        
        print("   âœ… è¿æ¥æ± å…³é—­æµ‹è¯•é€šè¿‡")
        
        return True
        
    except Exception as e:
        print(f"   âŒ ç»„ä»¶ç”Ÿå‘½å‘¨æœŸæµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False


async def test_error_handling_integration():
    """æµ‹è¯•é”™è¯¯å¤„ç†é›†æˆ"""
    print("ğŸ” æµ‹è¯•é”™è¯¯å¤„ç†é›†æˆ...")
    
    try:
        # 1. æµ‹è¯• Redis è¿æ¥å¤±è´¥å¤„ç†
        print("   ğŸ”„ æµ‹è¯• Redis è¿æ¥å¤±è´¥å¤„ç†...")
        
        try:
            # ä½¿ç”¨æ— æ•ˆçš„ Redis URL
            queue = RedisPriorityQueue(
                redis_url="redis://invalid-host:6379/0",
                queue_name="test:error:queue"
            )
            await queue.connect(max_retries=1, delay=0.1)
            # å¦‚æœæ²¡æœ‰æŠ›å‡ºå¼‚å¸¸ï¼Œè¯´æ˜è¿æ¥æˆåŠŸï¼Œè¿™åœ¨æµ‹è¯•ä¸­æ˜¯æ„å¤–æƒ…å†µ
            await queue.close()
        except Exception:
            # è¿æ¥å¤±è´¥æ˜¯é¢„æœŸçš„è¡Œä¸º
            pass
        
        print("   âœ… Redis è¿æ¥å¤±è´¥å¤„ç†æµ‹è¯•é€šè¿‡")
        
        # 2. æµ‹è¯•ç»„ä»¶é”™è¯¯æ¢å¤
        print("   ğŸ”„ æµ‹è¯•ç»„ä»¶é”™è¯¯æ¢å¤...")
        
        # ä½¿ç”¨æœ‰æ•ˆçš„ Redis URL
        queue = RedisPriorityQueue(
            redis_url="redis://127.0.0.1:6379/15",
            queue_name="test:recovery:queue"
        )
        
        # ç¬¬ä¸€æ¬¡è¿æ¥åº”è¯¥æˆåŠŸ
        await queue.connect()
        
        # æ¨¡æ‹Ÿè¿æ¥æ–­å¼€
        queue._redis = None
        
        # å†æ¬¡æ“ä½œåº”è¯¥è‡ªåŠ¨é‡è¿
        request = Request(url="https://recovery-test.com")
        success = await queue.put(request)
        assert success, "é˜Ÿåˆ—åº”è¯¥èƒ½å¤Ÿè‡ªåŠ¨é‡è¿"
        
        await queue.close()
        print("   âœ… ç»„ä»¶é”™è¯¯æ¢å¤æµ‹è¯•é€šè¿‡")
        
        return True
        
    except Exception as e:
        print(f"   âŒ é”™è¯¯å¤„ç†é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        return False


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹é›†æˆæµ‹è¯•...")
    print("=" * 50)
    
    tests = [
        test_full_crawling_pipeline,
        test_redis_components_integration,
        test_component_lifecycle,
        test_error_handling_integration,
    ]
    
    passed = 0
    total = len(tests)
    
    for test_func in tests:
        try:
            if await test_func():
                passed += 1
                print(f"âœ… {test_func.__name__} é€šè¿‡")
            else:
                print(f"âŒ {test_func.__name__} å¤±è´¥")
        except Exception as e:
            print(f"âŒ {test_func.__name__} å¼‚å¸¸: {e}")
        print()
    
    # å…³é—­æ‰€æœ‰è¿æ¥æ± 
    await close_all_pools()
    
    print("=" * 50)
    print(f"ğŸ“Š é›†æˆæµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰é›†æˆæµ‹è¯•é€šè¿‡ï¼")
        return 0
    else:
        print("âŒ éƒ¨åˆ†é›†æˆæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°")
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    exit(exit_code)