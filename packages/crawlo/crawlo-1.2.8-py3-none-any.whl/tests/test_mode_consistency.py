#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•æ¨¡å¼ä¸€è‡´æ€§æç¤º
"""
import asyncio
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from crawlo.crawler import CrawlerProcess
from crawlo.spider import Spider
from crawlo import Request


class TestSpider(Spider):
    name = "test_mode_spider"
    
    def start_requests(self):
        yield Request("https://httpbin.org/get")
    
    def parse(self, response):
        yield {"url": response.url, "status": response.status}


async def test_mode_consistency():
    """æµ‹è¯•æ¨¡å¼ä¸€è‡´æ€§æç¤º"""
    print("ğŸ” æµ‹è¯•æ¨¡å¼ä¸€è‡´æ€§æç¤º...")
    
    try:
        # åˆ›å»ºçˆ¬è™«è¿›ç¨‹
        process = CrawlerProcess()
        
        # æ·»åŠ çˆ¬è™«
        await process.crawl(TestSpider)
        
        print("âœ… æ¨¡å¼ä¸€è‡´æ€§æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    import logging
    logging.basicConfig(level=logging.INFO)
    
    asyncio.run(test_mode_consistency())