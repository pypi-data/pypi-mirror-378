# -*- coding: UTF-8 -*-
"""
{{project_name}} é¡¹ç›®é…ç½®æ–‡ä»¶ï¼ˆåˆ†å¸ƒå¼ç‰ˆï¼‰
=============================
åŸºäº Crawlo æ¡†æ¶çš„åˆ†å¸ƒå¼çˆ¬è™«é¡¹ç›®é…ç½®ã€‚
é€‚åˆå¤§è§„æ¨¡æ•°æ®é‡‡é›†å’Œå¤šèŠ‚ç‚¹éƒ¨ç½²ã€‚
"""
import os
from crawlo.config import CrawloConfig

# ============================== é¡¹ç›®åŸºæœ¬ä¿¡æ¯ ==============================
PROJECT_NAME = '{{project_name}}'

# ============================== åˆ†å¸ƒå¼é…ç½®è¯´æ˜ ==============================
RUN_MODE = 'distributed'  
QUEUE_TYPE = 'redis'  
FILTER_CLASS = 'crawlo.filters.aioredis_filter.AioRedisFilter'  
DEFAULT_DEDUP_PIPELINE = 'crawlo.pipelines.redis_dedup_pipeline.RedisDedupPipeline'
# æœ¬æ¨¡æ¿ä¸“ä¸ºåˆ†å¸ƒå¼éƒ¨ç½²è®¾è®¡ï¼Œé€‚ç”¨äºä»¥ä¸‹åœºæ™¯ï¼š
# - å¤§è§„æ¨¡æ•°æ®é‡‡é›†ä»»åŠ¡
# - éœ€è¦å¤šèŠ‚ç‚¹ååŒå·¥ä½œçš„é¡¹ç›®
# - é«˜å¹¶å‘ã€é«˜ååé‡éœ€æ±‚
# 
# è¿è¡Œæ¨¡å¼ç‰¹ç‚¹ï¼š
# - RUN_MODE = 'distributed'ï¼ˆåˆ†å¸ƒå¼æ¨¡å¼ï¼‰
# - QUEUE_TYPE = 'redis'ï¼ˆä½¿ç”¨Redisé˜Ÿåˆ—å®ç°åˆ†å¸ƒå¼åè°ƒï¼‰
# - FILTER_CLASS = 'crawlo.filters.aioredis_filter.AioRedisFilter'ï¼ˆRedisè¿‡æ»¤å™¨ï¼‰
# - DEFAULT_DEDUP_PIPELINE = 'crawlo.pipelines.redis_dedup_pipeline.RedisDedupPipeline'ï¼ˆRediså»é‡ï¼‰
# 
# éƒ¨ç½²è¦æ±‚ï¼š
# - éœ€è¦é…ç½®RedisæœåŠ¡å™¨è¿æ¥å‚æ•°
# - å»ºè®®ä½¿ç”¨ç‹¬ç«‹çš„Redisæ•°æ®åº“é¿å…æ•°æ®å†²çª
# - å¤šèŠ‚ç‚¹éƒ¨ç½²æ—¶ç¡®ä¿æ‰€æœ‰èŠ‚ç‚¹èƒ½è®¿é—®åŒä¸€Rediså®ä¾‹
#
# ğŸ¯ æœ€ä½³ä½¿ç”¨æ–¹å¼ï¼š
# æ¨èä½¿ç”¨é…ç½®å·¥å‚æ–¹å¼åˆ›å»ºåˆ†å¸ƒå¼é…ç½®ï¼š
# from crawlo.config import CrawloConfig
# config = CrawloConfig.distributed(
#     redis_host='your_redis_host',
#     redis_port=6379,
#     redis_password='your_password',
#     project_name='{{project_name}}'
# )
# process = CrawlerProcess(settings=config.to_dict())

# ============================== åˆ†å¸ƒå¼é…ç½® ==============================
# ä½¿ç”¨é…ç½®å·¥å‚åˆ›å»ºåˆ†å¸ƒå¼é…ç½®
CONFIG = CrawloConfig.distributed(
    redis_host=os.getenv('REDIS_HOST', '127.0.0.1'),
    redis_port=int(os.getenv('REDIS_PORT', 6379)),
    redis_password=os.getenv('REDIS_PASSWORD', ''),
    project_name='{{project_name}}',
    concurrency=16,
    download_delay=1.0
)

# è·å–é…ç½®
locals().update(CONFIG.to_dict())

# ============================== ç½‘ç»œè¯·æ±‚é…ç½® ==============================
DOWNLOADER = "crawlo.downloader.httpx_downloader.HttpXDownloader"
DOWNLOAD_TIMEOUT = 60
VERIFY_SSL = True

# ============================== å¹¶å‘é…ç½® ==============================
CONCURRENCY = 16
MAX_RUNNING_SPIDERS = 5
DOWNLOAD_DELAY = 1.0

# ============================== é˜Ÿåˆ—é…ç½® ==============================
SCHEDULER_MAX_QUEUE_SIZE = 5000
QUEUE_MAX_RETRIES = 5
QUEUE_TIMEOUT = 300

# ============================== Redis é…ç½® ==============================
REDIS_HOST = os.getenv('REDIS_HOST', '127.0.0.1')
REDIS_PORT = int(os.getenv('REDIS_PORT', 6379))
REDIS_PASSWORD = os.getenv('REDIS_PASSWORD', '')
REDIS_DB = int(os.getenv('REDIS_DB', 0))

# æ ¹æ®æ˜¯å¦æœ‰å¯†ç ç”Ÿæˆ URL
if REDIS_PASSWORD:
    REDIS_URL = f'redis://:{REDIS_PASSWORD}@{REDIS_HOST}:{REDIS_PORT}/{REDIS_DB}'
else:
    REDIS_URL = f'redis://{REDIS_HOST}:{REDIS_PORT}/{REDIS_DB}'

# ============================== æ•°æ®å­˜å‚¨é…ç½® ==============================
# MySQL é…ç½®
MYSQL_HOST = os.getenv('MYSQL_HOST', '127.0.0.1')
MYSQL_PORT = int(os.getenv('MYSQL_PORT', 3306))
MYSQL_USER = os.getenv('MYSQL_USER', 'root')
MYSQL_PASSWORD = os.getenv('MYSQL_PASSWORD', '123456')
MYSQL_DB = os.getenv('MYSQL_DB', '{{project_name}}')
MYSQL_TABLE = '{{project_name}}_data'
MYSQL_BATCH_SIZE = 100
MYSQL_USE_BATCH = True

# MongoDB é…ç½®
MONGO_URI = os.getenv('MONGO_URI', 'mongodb://localhost:27017')
MONGO_DATABASE = '{{project_name}}_db'
MONGO_COLLECTION = '{{project_name}}_items'
MONGO_BATCH_SIZE = 100
MONGO_USE_BATCH = True

# ============================== å»é‡é…ç½® ==============================
# æ˜ç¡®æŒ‡å®šåˆ†å¸ƒå¼æ¨¡å¼ä¸‹ä½¿ç”¨Rediså»é‡ç®¡é“
DEFAULT_DEDUP_PIPELINE = 'crawlo.pipelines.redis_dedup_pipeline.RedisDedupPipeline'
FILTER_CLASS = 'crawlo.filters.aioredis_filter.AioRedisFilter'
REDIS_TTL = 0
CLEANUP_FP = 0
FILTER_DEBUG = True

# ============================== ä¸­é—´ä»¶ä¸ç®¡é“ ==============================
MIDDLEWARES = [
    'crawlo.middleware.request_ignore.RequestIgnoreMiddleware',
    'crawlo.middleware.download_delay.DownloadDelayMiddleware',
    'crawlo.middleware.default_header.DefaultHeaderMiddleware',
    'crawlo.middleware.proxy.ProxyMiddleware',
    'crawlo.middleware.offsite.OffsiteMiddleware', 
    
    'crawlo.middleware.retry.RetryMiddleware',
    'crawlo.middleware.response_code.ResponseCodeMiddleware',
    'crawlo.middleware.response_filter.ResponseFilterMiddleware',
]

PIPELINES = [
    'crawlo.pipelines.console_pipeline.ConsolePipeline',
    # '{{project_name}}.pipelines.DatabasePipeline',
    # 'crawlo.pipelines.mysql_pipeline.AsyncmyMySQLPipeline',
    # 'crawlo.pipelines.mongo_pipeline.MongoPipeline',
]

# æ˜ç¡®æ·»åŠ Rediså»é‡ç®¡é“åˆ°ç®¡é“åˆ—è¡¨å¼€å¤´
PIPELINES.insert(0, DEFAULT_DEDUP_PIPELINE)

# ============================== æ‰©å±•ç»„ä»¶ ==============================
EXTENSIONS = [
    'crawlo.extension.log_interval.LogIntervalExtension',
    'crawlo.extension.log_stats.LogStats',
    'crawlo.extension.logging_extension.CustomLoggerExtension',
    # 'crawlo.extension.memory_monitor.MemoryMonitorExtension',
    # 'crawlo.extension.request_recorder.RequestRecorderExtension',
]

# ============================== æ—¥å¿—é…ç½® ==============================
LOG_LEVEL = 'INFO'
LOG_FILE = f'logs/{{project_name}}.log'
STATS_DUMP = True

# ============================== ä»£ç†é…ç½® ==============================
PROXY_ENABLED = False
PROXY_API_URL = ""
PROXY_EXTRACTOR = "proxy"
PROXY_REFRESH_INTERVAL = 60
PROXY_API_TIMEOUT = 10

# ============================== è‡ªå®šä¹‰é…ç½® ==============================
# åœ¨æ­¤å¤„æ·»åŠ é¡¹ç›®ç‰¹å®šçš„é…ç½®é¡¹