#!/usr/bin/python
# -*- coding: UTF-8 -*-
"""
# @Time    : 2025-08-31 22:36
# @Author  : crawl-coder
# @Desc    : å‘½ä»¤è¡Œå…¥å£ï¼šcrawlo run <spider_name>|allï¼Œç”¨äºè¿è¡ŒæŒ‡å®šçˆ¬è™«ã€‚
"""
import sys
import asyncio
import configparser
import os
from pathlib import Path
from importlib import import_module

from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from rich.text import Text
from rich import box
from rich.progress import Progress, SpinnerColumn, TextColumn

from crawlo.crawler import CrawlerProcess
from crawlo.utils.log import get_logger
from crawlo.project import get_settings, _find_project_root
from crawlo.commands.stats import record_stats

logger = get_logger(__name__)
console = Console()


def check_redis_connection(settings):
    """æ£€æŸ¥Redisè¿æ¥ï¼ˆåˆ†å¸ƒå¼æ¨¡å¼ä¸‹ï¼‰"""
    try:
        # æ£€æŸ¥æ˜¯å¦ä¸ºåˆ†å¸ƒå¼æ¨¡å¼
        run_mode = settings.get('RUN_MODE', 'standalone')
        queue_type = settings.get('QUEUE_TYPE', 'memory')
        
        if run_mode == 'distributed' or queue_type == 'redis':
            import redis.asyncio as redis
            redis_url = settings.get('REDIS_URL', 'redis://127.0.0.1:6379/0')
            redis_host = settings.get('REDIS_HOST', '127.0.0.1')
            redis_port = settings.get('REDIS_PORT', 6379)
            
            console.print(f"ğŸ” æ£€æŸ¥ Redis è¿æ¥: {redis_host}:{redis_port}")
            
            # åˆ›å»ºRedisè¿æ¥è¿›è¡Œæµ‹è¯•
            async def _test_redis():
                try:
                    r = redis.from_url(redis_url, encoding="utf-8", decode_responses=True)
                    await r.ping()
                    await r.close()
                    return True
                except Exception as e:
                    console.print(f"âŒ Redis è¿æ¥å¤±è´¥: {e}")
                    return False
            
            # è¿è¡Œå¼‚æ­¥æµ‹è¯•
            if not asyncio.run(_test_redis()):
                raise ConnectionError(f"æ— æ³•è¿æ¥åˆ° Redis æœåŠ¡å™¨ {redis_host}:{redis_port}")
                
            console.print("âœ… Redis è¿æ¥æ­£å¸¸")
            return True
        else:
            # éåˆ†å¸ƒå¼æ¨¡å¼ï¼Œè·³è¿‡Redisæ£€æŸ¥
            return True
    except ImportError:
        console.print("âš ï¸  Redis å®¢æˆ·ç«¯æœªå®‰è£…ï¼Œè·³è¿‡è¿æ¥æ£€æŸ¥")
        return True
    except Exception as e:
        console.print(f"âŒ Redis è¿æ¥æ£€æŸ¥å¤±è´¥: {e}")
        return False


def main(args):
    """
    ä¸»å‡½æ•°ï¼šè¿è¡ŒæŒ‡å®šçˆ¬è™«
    ç”¨æ³•:
        crawlo run <spider_name>|all [--json] [--no-stats]
    """
    if len(args) < 1:
        console.print("[bold red]âŒ ç”¨æ³•:[/bold red] [blue]crawlo run[/blue] <çˆ¬è™«åç§°>|all [bold yellow][--json] [--no-stats][/bold yellow]")
        console.print("ğŸ’¡ ç¤ºä¾‹:")
        console.print("   [blue]crawlo run baidu[/blue]")
        console.print("   [blue]crawlo run all[/blue]")
        console.print("   [blue]crawlo run all --json --no-stats[/blue]")
        return 1

    # è§£æå‚æ•°
    spider_arg = args[0]
    show_json = "--json" in args
    no_stats = "--no-stats" in args

    try:
        # 1. æŸ¥æ‰¾é¡¹ç›®æ ¹ç›®å½•
        project_root = _find_project_root()
        if not project_root:
            msg = ":cross_mark: [bold red]æ‰¾ä¸åˆ° 'crawlo.cfg'[/bold red]\nğŸ’¡ è¯·åœ¨é¡¹ç›®ç›®å½•ä¸­è¿è¡Œæ­¤å‘½ä»¤ã€‚"
            if show_json:
                console.print_json(data={"success": False, "error": "æœªæ‰¾åˆ°é¡¹ç›®æ ¹ç›®å½•"})
                return 1
            else:
                console.print(Panel(
                    Text.from_markup(msg),
                    title="âŒ éCrawloé¡¹ç›®",
                    border_style="red",
                    padding=(1, 2)
                ))
                return 1

        project_root_str = str(project_root)
        if project_root_str not in sys.path:
            sys.path.insert(0, project_root_str)

        # 2. è¯»å– crawlo.cfg è·å– settings æ¨¡å—
        cfg_file = os.path.join(project_root, "crawlo.cfg")
        if not os.path.exists(cfg_file):
            msg = f"åœ¨ {project_root} ä¸­æœªæ‰¾åˆ° crawlo.cfg"
            if show_json:
                console.print_json(data={"success": False, "error": msg})
                return 1
            else:
                console.print(Panel(msg, title="âŒ ç¼ºå°‘é…ç½®æ–‡ä»¶", border_style="red"))
                return 1

        config = configparser.ConfigParser()
        config.read(cfg_file, encoding="utf-8")

        if not config.has_section("settings") or not config.has_option("settings", "default"):
            msg = "crawlo.cfg ä¸­ç¼ºå°‘ [settings] éƒ¨åˆ†æˆ– 'default' é€‰é¡¹"
            if show_json:
                console.print_json(data={"success": False, "error": msg})
                return 1
            else:
                console.print(Panel(msg, title="âŒ æ— æ•ˆé…ç½®", border_style="red"))
                return 1

        settings_module = config.get("settings", "default")
        project_package = settings_module.split(".")[0]

        # 3. ç¡®ä¿é¡¹ç›®åŒ…å¯å¯¼å…¥
        try:
            import_module(project_package)
        except ImportError as e:
            msg = f"å¯¼å…¥é¡¹ç›®åŒ… '{project_package}' å¤±è´¥: {e}"
            if show_json:
                console.print_json(data={"success": False, "error": msg})
                return 1
            else:
                console.print(Panel(msg, title="âŒ å¯¼å…¥é”™è¯¯", border_style="red"))
                return 1

        # 4. åŠ è½½ settings å’Œçˆ¬è™«æ¨¡å—
        settings = get_settings()
        
        # æ£€æŸ¥Redisè¿æ¥ï¼ˆå¦‚æœæ˜¯åˆ†å¸ƒå¼æ¨¡å¼ï¼‰
        if not check_redis_connection(settings):
            if show_json:
                console.print_json(data={"success": False, "error": "Redisè¿æ¥æ£€æŸ¥å¤±è´¥"})
                return 1
            else:
                return 1
        
        spider_modules = [f"{project_package}.spiders"]
        process = CrawlerProcess(settings=settings, spider_modules=spider_modules)

        # === æƒ…å†µ1ï¼šè¿è¡Œæ‰€æœ‰çˆ¬è™« ===
        if spider_arg.lower() == "all":
            spider_names = process.get_spider_names()
            if not spider_names:
                msg = "æœªæ‰¾åˆ°çˆ¬è™«ã€‚"
                if show_json:
                    console.print_json(data={"success": False, "error": msg})
                    return 1
                else:
                    console.print(Panel(
                        Text.from_markup(
                            ":cross_mark: [bold red]æœªæ‰¾åˆ°çˆ¬è™«ã€‚[/bold red]\n\n"
                            "[bold]ğŸ’¡ ç¡®ä¿:[/bold]\n"
                            "  â€¢ çˆ¬è™«å®šä¹‰äº '[cyan]spiders/[/cyan]' ç›®å½•\n"
                            "  â€¢ å…·æœ‰ [green]`name`[/green] å±æ€§\n"
                            "  â€¢ æ¨¡å—å·²å¯¼å…¥ (ä¾‹å¦‚é€šè¿‡ [cyan]__init__.py[/cyan])"
                        ),
                        title="âŒ æœªæ‰¾åˆ°çˆ¬è™«",
                        border_style="red",
                        padding=(1, 2)
                    ))
                    return 1

            # æ˜¾ç¤ºå³å°†è¿è¡Œçš„çˆ¬è™«åˆ—è¡¨
            table = Table(
                title=f"ğŸš€ å¯åŠ¨å…¨éƒ¨ {len(spider_names)} ä¸ªçˆ¬è™«",
                box=box.ROUNDED,
                show_header=True,
                header_style="bold magenta"
            )
            table.add_column("åç§°", style="cyan")
            table.add_column("ç±»å", style="green")

            for name in sorted(spider_names):
                cls = process.get_spider_class(name)
                table.add_row(name, cls.__name__)

            console.print(table)
            console.print()

            # æ³¨å†Œ stats è®°å½•ï¼ˆé™¤é --no-statsï¼‰
            if not no_stats:
                for crawler in process.crawlers:
                    crawler.signals.connect(record_stats, signal="spider_closed")

            # å¹¶è¡Œè¿è¡Œæ‰€æœ‰çˆ¬è™«
            with Progress(
                SpinnerColumn(),
                TextColumn("[progress.description]{task.description}"),
                transient=True,
            ) as progress:
                task = progress.add_task("æ­£åœ¨è¿è¡Œæ‰€æœ‰çˆ¬è™«...", total=None)
                asyncio.run(process.crawl(spider_names))

            if show_json:
                console.print_json(data={"success": True, "spiders": spider_names})
            else:
                console.print(Panel(
                    ":tada: [bold green]æ‰€æœ‰çˆ¬è™«è¿è¡Œå®Œæˆï¼[/bold green]",
                    title="âœ… å…¨éƒ¨å®Œæˆ",
                    border_style="green"
                ))
            return 0

        # === æƒ…å†µ2ï¼šè¿è¡Œå•ä¸ªçˆ¬è™« ===
        spider_name = spider_arg
        if not process.is_spider_registered(spider_name):
            available = process.get_spider_names()
            msg = f"çˆ¬è™« '[cyan]{spider_name}[/cyan]' æœªæ‰¾åˆ°ã€‚"
            if show_json:
                console.print_json(data={
                    "success": False,
                    "error": msg,
                    "available": available
                })
                return 1
            else:
                panel_content = Text.from_markup(msg + "\n")
                if available:
                    panel_content.append("\nğŸ’¡ å¯ç”¨çˆ¬è™«:\n")
                    for name in sorted(available):
                        cls = process.get_spider_class(name)
                        panel_content.append(f"  â€¢ [cyan]{name}[/cyan] ([green]{cls.__name__}[/green])\n")
                else:
                    panel_content.append("\nğŸ’¡ æœªæ‰¾åˆ°çˆ¬è™«ã€‚è¯·æ£€æŸ¥çˆ¬è™«æ¨¡å—ã€‚")

                console.print(Panel(
                    panel_content,
                    title="âŒ çˆ¬è™«æœªæ‰¾åˆ°",
                    border_style="red",
                    padding=(1, 2)
                ))
                return 1

        spider_class = process.get_spider_class(spider_name)

        # æ˜¾ç¤ºå¯åŠ¨ä¿¡æ¯
        if not show_json:
            info_table = Table(
                title=f"ğŸš€ å¯åŠ¨çˆ¬è™«: [bold cyan]{spider_name}[/bold cyan]",
                box=box.SIMPLE,
                show_header=False,
                title_style="bold green"
            )
            info_table.add_column("Key", style="yellow")
            info_table.add_column("Value", style="cyan")
            info_table.add_row("Project", project_package)
            info_table.add_row("Class", spider_class.__name__)
            info_table.add_row("Module", spider_class.__module__)
            console.print(info_table)
            console.print()

        # æ³¨å†Œ stats è®°å½•
        if not no_stats:
            for crawler in process.crawlers:
                crawler.signals.connect(record_stats, signal="spider_closed")

        # è¿è¡Œçˆ¬è™«
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            transient=True,
        ) as progress:
            task = progress.add_task(f"æ­£åœ¨è¿è¡Œ {spider_name}...", total=None)
            asyncio.run(process.crawl(spider_name))

        if show_json:
            console.print_json(data={"success": True, "spider": spider_name})
        else:
            console.print(Panel(
                f":tada: [bold green]çˆ¬è™« '[cyan]{spider_name}[/cyan]' è¿è¡Œå®Œæˆï¼[/bold green]",
                title="âœ… å®Œæˆ",
                border_style="green"
            ))
        return 0

    except KeyboardInterrupt:
        msg = "âš ï¸  çˆ¬è™«è¢«ç”¨æˆ·ä¸­æ–­ã€‚"
        if show_json:
            console.print_json(data={"success": False, "error": msg})
        else:
            console.print(f"[bold yellow]{msg}[/bold yellow]")
        return 1
    except Exception as e:
        logger.exception("Exception during 'crawlo run'")
        msg = f"æ„å¤–é”™è¯¯: {e}"
        if show_json:
            console.print_json(data={"success": False, "error": msg})
        else:
            console.print(f"[bold red]âŒ {msg}[/bold red]")
        return 1


if __name__ == "__main__":
    """
    æ”¯æŒç›´æ¥è¿è¡Œï¼š
        python -m crawlo.commands.run spider_name
    """
    sys.exit(main(sys.argv[1:]))