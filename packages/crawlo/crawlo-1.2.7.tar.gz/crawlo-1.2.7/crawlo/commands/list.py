#!/usr/bin/python
# -*- coding: UTF-8 -*-
"""
# @Time    : 2025-08-31 22:33
# @Author  : crawl-coder
# @Desc    : å‘½ä»¤è¡Œå…¥å£ï¼šcrawlo listï¼Œç”¨äºåˆ—å‡ºæ‰€æœ‰å·²æ³¨å†Œçš„çˆ¬è™«
"""
import sys
from pathlib import Path
from importlib import import_module

from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.text import Text
from rich import box

from crawlo.crawler import CrawlerProcess
from crawlo.utils.log import get_logger
from .utils import validate_project_environment, show_error_panel

logger = get_logger(__name__)
console = Console()


def main(args):
    """
    ä¸»å‡½æ•°ï¼šåˆ—å‡ºæ‰€æœ‰å¯ç”¨çˆ¬è™«
    ç”¨æ³•: crawlo list [--json]
    """
    show_json = "--json" in args
    
    # è¿‡æ»¤æ‰å‚æ•°åæ£€æŸ¥æ˜¯å¦æœ‰é¢å¤–å‚æ•°
    filtered_args = [arg for arg in args if not arg.startswith('--')]
    if filtered_args:
        if show_json:
            console.print_json(data={"success": False, "error": "ç”¨æ³•: crawlo list [--json]"})
        else:
            console.print("[bold red]âŒ é”™è¯¯:[/bold red] ç”¨æ³•: [blue]crawlo list[/blue] [--json]")
        return 1

    try:
        # éªŒè¯é¡¹ç›®ç¯å¢ƒ
        is_valid, project_package, error_msg = validate_project_environment()
        if not is_valid:
            if show_json:
                console.print_json(data={"success": False, "error": error_msg})
            else:
                show_error_panel("éCrawloé¡¹ç›®", error_msg)
            return 1

        # åˆå§‹åŒ– CrawlerProcess å¹¶åŠ è½½çˆ¬è™«æ¨¡å—
        spider_modules = [f"{project_package}.spiders"]
        process = CrawlerProcess(spider_modules=spider_modules)

        # è·å–æ‰€æœ‰çˆ¬è™«åç§°
        spider_names = process.get_spider_names()
        if not spider_names:
            if show_json:
                console.print_json(data={
                    "success": True, 
                    "spiders": [],
                    "message": "é¡¹ç›®ä¸­æœªæ‰¾åˆ°çˆ¬è™«"
                })
            else:
                console.print(Panel(
                    Text.from_markup(
                        ":envelope_with_arrow: [bold]æœªæ‰¾åˆ°çˆ¬è™«[/bold] äº '[cyan]spiders/[/cyan]' ç›®å½•ã€‚\n\n"
                        "[bold]ğŸ’¡ ç¡®ä¿:[/bold]\n"
                        "  â€¢ çˆ¬è™«ç±»ç»§æ‰¿è‡ª [blue]`crawlo.spider.Spider`[/blue]\n"
                        "  â€¢ æ¯ä¸ªçˆ¬è™«éƒ½æœ‰ [green]`name`[/green] å±æ€§\n"
                        "  â€¢ çˆ¬è™«å·²åœ¨ [cyan]`spiders/__init__.py`[/cyan] ä¸­å¯¼å…¥ (å¦‚æœä½¿ç”¨åŒ…)"
                    ),
                    title="ğŸ“­ æœªæ‰¾åˆ°çˆ¬è™«",
                    border_style="yellow",
                    padding=(1, 2)
                ))
            return 0

        # å‡†å¤‡çˆ¬è™«ä¿¡æ¯
        spider_info = []
        for name in sorted(spider_names):
            spider_cls = process.get_spider_class(name)
            module_name = spider_cls.__module__.replace(f"{project_package}.", "")
            
            # è·å–é¢å¤–ä¿¡æ¯
            start_urls_count = len(getattr(spider_cls, 'start_urls', []))
            allowed_domains = getattr(spider_cls, 'allowed_domains', [])
            custom_settings = getattr(spider_cls, 'custom_settings', {})
            
            spider_info.append({
                "name": name,
                "class": spider_cls.__name__,
                "module": module_name,
                "start_urls_count": start_urls_count,
                "allowed_domains": allowed_domains,
                "has_custom_settings": bool(custom_settings)
            })

        # JSON è¾“å‡º
        if show_json:
            console.print_json(data={
                "success": True,
                "count": len(spider_info),
                "spiders": spider_info
            })
            return 0

        # è¡¨æ ¼è¾“å‡º
        table = Table(
            title=f"ğŸ“‹ æ‰¾åˆ° {len(spider_names)} ä¸ªçˆ¬è™«",
            box=box.ROUNDED,
            show_header=True,
            header_style="bold magenta",
            title_style="bold green"
        )
        table.add_column("åç§°", style="cyan", no_wrap=True)
        table.add_column("ç±»å", style="green")
        table.add_column("æ¨¡å—", style="dim")
        table.add_column("URLæ•°", style="blue", justify="center")
        table.add_column("åŸŸå", style="yellow")
        table.add_column("è‡ªå®šä¹‰è®¾ç½®", style="magenta", justify="center")

        for info in spider_info:
            domains_display = ", ".join(info["allowed_domains"][:2])  # æ˜¾ç¤ºå‰2ä¸ªåŸŸå
            if len(info["allowed_domains"]) > 2:
                domains_display += f" (+{len(info['allowed_domains'])-2})"
            elif not domains_display:
                domains_display = "-"
                
            table.add_row(
                info["name"],
                info["class"],
                info["module"],
                str(info["start_urls_count"]),
                domains_display,
                "âœ“" if info["has_custom_settings"] else "-"
            )

        console.print(table)
        
        # æ˜¾ç¤ºä½¿ç”¨æç¤º
        console.print("\n[bold]ğŸš€ ä¸‹ä¸€æ­¥æ“ä½œ:[/bold]")
        console.print("  [blue]crawlo run[/blue] <çˆ¬è™«åç§°>    # è¿è¡ŒæŒ‡å®šçˆ¬è™«")
        console.print("  [blue]crawlo run[/blue] all             # è¿è¡Œæ‰€æœ‰çˆ¬è™«")
        console.print("  [blue]crawlo check[/blue] <çˆ¬è™«åç§°>  # æ£€æŸ¥çˆ¬è™«æœ‰æ•ˆæ€§")
        
        return 0

    except Exception as e:
        if show_json:
            console.print_json(data={"success": False, "error": str(e)})
        else:
            console.print(f"[bold red]âŒ æ„å¤–é”™è¯¯:[/bold red] {e}")
        logger.exception("æ‰§è¡Œ 'crawlo list' æ—¶å‘ç”Ÿå¼‚å¸¸")
        return 1