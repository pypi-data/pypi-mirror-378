{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: Error Handling and External Data\n",
    "\n",
    "In this tutorial, we'll learn how to handle errors gracefully in DaggerML and work with external data sources like files and APIs.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Complete Tutorials 1 and 2 first. We'll build on those concepts while adding error handling and external data capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DaggerML ready for error handling and external data tutorial!\n"
     ]
    }
   ],
   "source": [
    "# Import required modules\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from daggerml import Dml, Error\n",
    "\n",
    "from dml_util import funkify\n",
    "\n",
    "# Create a DaggerML instance\n",
    "dml = Dml(repo=\"tutorial\", branch=\"main\")\n",
    "os.environ.update({\"DML_S3_BUCKET\": \"does-not-matter\", \"DML_S3_PREFIX\": \"does-not-matter\"})\n",
    "print(\"DaggerML ready for error handling and external data tutorial!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Errors in DaggerML\n",
    "\n",
    "DaggerML captures and stores errors as part of your computation graph. This means you can handle errors gracefully and continue processing other parts of your workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@funkify\n",
    "def divide_numbers(dag):\n",
    "    \"\"\"Divide two numbers, handling division by zero.\"\"\"\n",
    "    return dag.argv[1].value() / dag.argv[2].value()\n",
    "\n",
    "# Create a DAG for error handling examples\n",
    "dag = dml.new(\"error_handling\", \"Learning error handling in DaggerML\")\n",
    "\n",
    "# Add our functions\n",
    "dag.divide_fn = divide_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Errors Gracefully\n",
    "\n",
    "Let's see how DaggerML handles functions that raise errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Normal Division ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scriptrunner [944c0ecee26bed3fc10d4785c0a2d066] :: pid = 31193 started\n",
      "scriptrunner [944c0ecee26bed3fc10d4785c0a2d066] :: pid = 31193 running\n",
      "scriptrunner [944c0ecee26bed3fc10d4785c0a2d066] :: pid = 31193 running\n",
      "scriptrunner [944c0ecee26bed3fc10d4785c0a2d066] :: pid = 31193 running\n",
      "scriptrunner [944c0ecee26bed3fc10d4785c0a2d066] :: pid = 31193 running\n",
      "scriptrunner [944c0ecee26bed3fc10d4785c0a2d066] :: pid = 31193 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Ã· 2 = 5.0\n",
      "\n",
      "=== Division by Zero (Error Handling) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scriptrunner [81bbf738b81d228378ff22a9e28ea569] :: pid = 31936 started\n",
      "scriptrunner [81bbf738b81d228378ff22a9e28ea569] :: pid = 31936 running\n",
      "scriptrunner [81bbf738b81d228378ff22a9e28ea569] :: pid = 31936 running\n",
      "scriptrunner [81bbf738b81d228378ff22a9e28ea569] :: pid = 31936 running\n",
      "scriptrunner [81bbf738b81d228378ff22a9e28ea569] :: pid = 31936 running\n",
      "scriptrunner [81bbf738b81d228378ff22a9e28ea569] :: pid = 31936 finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught DaggerML Error: Traceback (most recent call last) from python:\n",
      "  File \"/Users/amn/code/daggerml/dml-util/src/dml_util/funk.py\", line 250, in aws_fndag\n",
      "    yield dag\n",
      "  File \"/var/folders/s9/25vs18pn1kj680k76kc6zvlm0000gn/T/dml.03supcvi/script.py\", line 10, in <module>\n",
      "    res = divide_numbers(dag)\n",
      "  File \"/var/folders/s9/25vs18pn1kj680k76kc6zvlm0000gn/T/dml.03supcvi/script.py\", line 6, in divide_numbers\n",
      "    return dag.argv[1].value() / dag.argv[2].value()\n",
      "ZeroDivisionError: division by zero\n",
      "The error is stored in the DAG and can be handled appropriately\n"
     ]
    }
   ],
   "source": [
    "# Normal division (should work fine)\n",
    "print(\"=== Normal Division ===\")\n",
    "dag.normal_result = dag.divide_fn(10, 2)\n",
    "print(f\"10 Ã· 2 = {dag.normal_result.value()}\")\n",
    "\n",
    "# Division by zero (will cause an error)\n",
    "print(\"\\n=== Division by Zero (Error Handling) ===\")\n",
    "try:\n",
    "    dag.error_result = dag.divide_fn(10, 0)\n",
    "    print(f\"10 Ã· 0 = {dag.error_result.value()}\")\n",
    "except Error as e:\n",
    "    print(f\"Caught DaggerML Error: {e}\")\n",
    "    print(\"The error is stored in the DAG and can be handled appropriately\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with External Files\n",
    "\n",
    "Let's create some sample data files and learn how to work with external data in DaggerML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some sample data files for our tutorial\n",
    "sample_data_dir = Path(\"tutorial_data\")\n",
    "sample_data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Create a JSON file\n",
    "json_data = {\n",
    "    \"products\": [\n",
    "        {\"id\": 1, \"name\": \"Laptop\", \"price\": 999.99, \"category\": \"Electronics\"},\n",
    "        {\"id\": 2, \"name\": \"Book\", \"price\": 15.99, \"category\": \"Education\"},\n",
    "        {\"id\": 3, \"name\": \"Coffee\", \"price\": 4.50, \"category\": \"Food\"},\n",
    "        {\"id\": 4, \"name\": \"Headphones\", \"price\": 79.99, \"category\": \"Electronics\"}\n",
    "    ],\n",
    "    \"metadata\": {\n",
    "        \"version\": \"1.0\",\n",
    "        \"last_updated\": \"2024-01-15\"\n",
    "    }\n",
    "}\n",
    "\n",
    "json_file = sample_data_dir / \"products.json\"\n",
    "with open(json_file, 'w') as f:\n",
    "    json.dump(json_data, f, indent=2)\n",
    "\n",
    "# Create a CSV-like text file\n",
    "csv_data = \"\"\"name,age,city,score\n",
    "Alice,25,New York,85\n",
    "Bob,30,San Francisco,92\n",
    "Charlie,35,Chicago,78\n",
    "Diana,28,Boston,88\n",
    "Eve,32,Seattle,95\"\"\"\n",
    "\n",
    "csv_file = sample_data_dir / \"people.csv\"\n",
    "with open(csv_file, 'w') as f:\n",
    "    f.write(csv_data)\n",
    "\n",
    "print(f\"Created sample data files in {sample_data_dir}:\")\n",
    "print(f\"  - {json_file}\")\n",
    "print(f\"  - {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@funkify\n",
    "def load_json_file(dag):\n",
    "    \"\"\"Load and validate JSON data from a file.\"\"\"\n",
    "    file_path = dag.argv[1].value()\n",
    "\n",
    "    dag.file_path = file_path\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            dag.raw_content = f.read()\n",
    "\n",
    "        dag.data = json.loads(dag.raw_content)\n",
    "        dag.success = True\n",
    "        dag.error = None\n",
    "\n",
    "        # Basic validation\n",
    "        dag.has_products = \"products\" in dag.data\n",
    "        dag.product_count = len(dag.data.get(\"products\", []))\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        dag.success = False\n",
    "        dag.error = f\"File not found: {file_path}\"\n",
    "        dag.data = None\n",
    "    except json.JSONDecodeError as e:\n",
    "        dag.success = False\n",
    "        dag.error = f\"Invalid JSON: {e}\"\n",
    "        dag.data = None\n",
    "    except Exception as e:\n",
    "        dag.success = False\n",
    "        dag.error = f\"Unexpected error: {e}\"\n",
    "        dag.data = None\n",
    "\n",
    "    return dag.data\n",
    "\n",
    "@funkify\n",
    "def parse_csv_simple(dag):\n",
    "    \"\"\"Parse simple CSV data.\"\"\"\n",
    "    file_path = dag.argv[1].value()\n",
    "\n",
    "    dag.file_path = file_path\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = f.read().strip().split('\\n')\n",
    "\n",
    "        dag.headers = lines[0].split(',')\n",
    "        dag.rows = []\n",
    "\n",
    "        for line in lines[1:]:\n",
    "            values = line.split(',')\n",
    "            row = {}\n",
    "            for i, header in enumerate(dag.headers):\n",
    "                if i < len(values):\n",
    "                    # Try to convert to number if possible\n",
    "                    value = values[i]\n",
    "                    try:\n",
    "                        if '.' in value:\n",
    "                            value = float(value)\n",
    "                        else:\n",
    "                            value = int(value)\n",
    "                    except ValueError:\n",
    "                        pass  # Keep as string\n",
    "                    row[header] = value\n",
    "            dag.rows.append(row)\n",
    "\n",
    "        dag.success = True\n",
    "        dag.error = None\n",
    "\n",
    "    except Exception as e:\n",
    "        dag.success = False\n",
    "        dag.error = str(e)\n",
    "        dag.rows = []\n",
    "        dag.headers = []\n",
    "\n",
    "    return dag.rows\n",
    "\n",
    "# Add file processing functions to DAG\n",
    "dag.load_json_fn = load_json_file\n",
    "dag.parse_csv_fn = parse_csv_simple\n",
    "\n",
    "# Load the files\n",
    "print(\"=== Loading External Data ===\")\n",
    "dag.json_data = dag.load_json_fn(str(json_file))\n",
    "dag.csv_data = dag.parse_csv_fn(str(csv_file))\n",
    "\n",
    "print(f\"JSON loaded successfully: {dag.json_data.load().success.value()}\")\n",
    "if dag.json_data.load().success.value():\n",
    "    print(f\"  Products found: {dag.json_data.load().product_count.value()}\")\n",
    "\n",
    "print(f\"CSV loaded successfully: {dag.csv_data.load().success.value()}\")\n",
    "if dag.csv_data.load().success.value():\n",
    "    print(f\"  Rows parsed: {len(dag.csv_data.value())}\")\n",
    "    print(f\"  Headers: {dag.csv_data.load().headers.value()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup and Summary\n",
    "\n",
    "Let's clean up our temporary files and summarize what we've built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up sample files\n",
    "import shutil\n",
    "\n",
    "if sample_data_dir.exists():\n",
    "    shutil.rmtree(sample_data_dir)\n",
    "    print(\"Cleaned up sample data files\")\n",
    "\n",
    "# Create final summary\n",
    "dag.tutorial_summary = {\n",
    "    \"error_handling_patterns\": [\n",
    "        \"Try-catch within functions\",\n",
    "        \"Safe fallback values\",\n",
    "        \"Graceful degradation\"\n",
    "    ],\n",
    "    \"external_data_sources\": [\n",
    "        \"JSON files\",\n",
    "        \"CSV files\",\n",
    "        \"With validation and error recovery\"\n",
    "    ],\n",
    "    \"functions_created\": len([k for k in dag.keys() if k.endswith('_fn')]),\n",
    "    \"total_nodes\": len(dag.keys())\n",
    "}\n",
    "\n",
    "print(\"=== Tutorial 3 Complete! ===\")\n",
    "print(\"You've learned:\")\n",
    "print(\"âœ… Error handling in DaggerML functions\")\n",
    "print(\"âœ… Working with external JSON and CSV files\")\n",
    "print(\"âœ… Data validation and parsing\")\n",
    "print(\"âœ… Robust data loading patterns\")\n",
    "\n",
    "summary = dag.tutorial_summary.value()\n",
    "print(f\"\\nTotal functions created: {summary['functions_created']}\")\n",
    "print(f\"Total DAG nodes: {summary['total_nodes']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What We've Mastered\n",
    "\n",
    "In this tutorial, you've learned advanced DaggerML patterns:\n",
    "\n",
    "### 1. Error Handling\n",
    "- âœ… **Exception Management**: How DaggerML captures and stores errors\n",
    "- âœ… **Safe Functions**: Building functions that handle errors gracefully\n",
    "- âœ… **Error Recovery**: Continuing workflows despite individual failures\n",
    "\n",
    "### 2. External Data Integration\n",
    "- âœ… **File Loading**: Reading JSON and CSV files safely\n",
    "- âœ… **Data Validation**: Checking and validating external data\n",
    "- âœ… **Parsing Strategies**: Converting text data to structured formats\n",
    "\n",
    "### 3. Best Practices\n",
    "- âœ… **Always validate external data** before processing\n",
    "- âœ… **Provide meaningful error messages** for debugging\n",
    "- âœ… **Store intermediate results** to help with debugging\n",
    "- âœ… **Design functions to be resilient** to unexpected inputs\n",
    "\n",
    "## Next Tutorial Preview\n",
    "\n",
    "In Tutorial 4, we'll explore:\n",
    "- Advanced execution environments (local, cloud, containers)\n",
    "- Storage systems for artifact management\n",
    "- Scaling computations and production deployment\n",
    "\n",
    "You're building serious DaggerML expertise! ðŸ”§ðŸ’ª"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dml-util",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
