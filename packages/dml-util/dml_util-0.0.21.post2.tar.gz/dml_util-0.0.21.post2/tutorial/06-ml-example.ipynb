{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fea98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from daggerml import Dml\n",
    "\n",
    "from dml_util import S3Store, funkify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7007e613",
   "metadata": {},
   "outputs": [],
   "source": [
    "dml = Dml(repo=\"tutorial\", branch=\"main\")\n",
    "dag = dml.new(\"ml-example-2\")\n",
    "s3 = S3Store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510eebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@funkify\n",
    "def load_data(dag):\n",
    "    from tempfile import NamedTemporaryFile\n",
    "\n",
    "    import pandas as pd\n",
    "    from sklearn.datasets import load_iris\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    from dml_util import S3Store\n",
    "\n",
    "    s3 = S3Store()\n",
    "    params = dag.argv[1].value()\n",
    "    X, y = load_iris(as_frame=True, return_X_y=True)\n",
    "    splits = train_test_split(X, y, random_state=params[\"random_state\"])\n",
    "    out = {}\n",
    "    for name, spl in zip([\"X_train\", \"X_test\", \"y_train\", \"y_test\"], splits):\n",
    "        with NamedTemporaryFile() as temp:\n",
    "            if isinstance(spl,pd.Series):\n",
    "                spl = spl.to_frame(\"class\")\n",
    "            spl.to_parquet(temp.name)\n",
    "            temp.seek(0)\n",
    "            out[name] = s3.put(filepath=temp.name, suffix=\".parquet\")\n",
    "\n",
    "    return out\n",
    "\n",
    "dag.load_data = load_data\n",
    "params = {\"random_state\": 2}\n",
    "iris_data = dag.load_data(params, name=\"iris_data\")\n",
    "iris_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ee63248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'daggerml.core.Resource'>\n",
      "script\n",
      "#!/usr/bin/env python3\n",
      "from dml_util import aws_fndag\n",
      "\n",
      "def fit_model(dag):\n",
      "    import pickle\n",
      "    from time import time\n",
      "\n",
      "    import pandas as pd\n",
      "    from sklearn.cluster import KMeans\n",
      "\n",
      "    from dml_util import S3Store\n",
      "\n",
      "    t_0 = time()\n",
      "    train = dag.argv[1].value()\n",
      "    params = dag.argv[2].value()\n",
      "    clusterer = KMeans(**params)\n",
      "    iris_train = pd.read_parquet(train.uri,engine=\"fastparquet\")\n",
      "    fitted = clusterer.fit(iris_train)\n",
      "    s3 = S3Store()\n",
      "    t_n = time()\n",
      "    dag.elapsed = t_n - t_0\n",
      "\n",
      "    return s3.put(pickle.dumps(fitted), suffix=\".pkl\")\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    with aws_fndag() as dag:\n",
      "        res = fit_model(dag)\n",
      "        if dag._ref is None:\n",
      "            dag.result = res\n"
     ]
    }
   ],
   "source": [
    "@funkify\n",
    "def fit_model(dag):\n",
    "    import pickle\n",
    "    from time import time\n",
    "\n",
    "    import pandas as pd\n",
    "    from sklearn.cluster import KMeans\n",
    "\n",
    "    from dml_util import S3Store\n",
    "\n",
    "    t_0 = time()\n",
    "    train = dag.argv[1].value()\n",
    "    params = dag.argv[2].value()\n",
    "    clusterer = KMeans(**params)\n",
    "    iris_train = pd.read_parquet(train.uri,engine=\"fastparquet\")\n",
    "    fitted = clusterer.fit(iris_train)\n",
    "    s3 = S3Store()\n",
    "    t_n = time()\n",
    "    dag.elapsed = t_n - t_0\n",
    "\n",
    "    return s3.put(pickle.dumps(fitted), suffix=\".pkl\")\n",
    "\n",
    "print(type(fit_model))\n",
    "print(fit_model.uri)\n",
    "print(fit_model.data[\"script\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f31115",
   "metadata": {},
   "outputs": [],
   "source": [
    "dag.fit_model = fit_model\n",
    "fitted = dag.fit_model(iris_data[\"X_train\"], {\"n_clusters\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e324700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@funkify\n",
    "def predict(dag):\n",
    "    import pickle\n",
    "    from tempfile import NamedTemporaryFile\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    from dml_util import S3Store\n",
    "    s3 = S3Store()\n",
    "\n",
    "    model = pickle.loads(s3.get(dag.argv[1]))\n",
    "    X_test = pd.read_parquet(dag.argv[2].value().uri, engine=\"fastparquet\")\n",
    "    predictions = model.transform(X_test)\n",
    "    preds_df = pd.DataFrame(predictions,index=X_test.index,columns=[f\"c{i}\" for i in range(predictions.shape[1])])\n",
    "\n",
    "    with NamedTemporaryFile() as temp:\n",
    "        preds_df.to_parquet(temp.name)\n",
    "        temp.seek(0)\n",
    "        return s3.put(filepath=temp.name, suffix=\".parquet\")\n",
    "\n",
    "dag.predict = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc68651",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dag.predict(fitted, iris_data[\"X_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7239519",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_parquet(predictions.value().uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aedcabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dag.result = predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
