{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Used to Generate Benchmark Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import polars_ds as pds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel ML metrics evaluations on segments \n",
    "\n",
    "Use cases:\n",
    "\n",
    "1. Evaluate ML model performance in market A, B, C.\n",
    "2. The Dataframe contains a column that defines the \"split\" of the dataframe. Then this can simulatneously evaluate ML model's performances on each of the train, test, recent, or any other split you have.\n",
    "3. Evaluate ML model performance over time, e.g. weekly / monthly \n",
    "\n",
    "Comparison: \n",
    "\n",
    "Polars + PDS vs. Pandas + Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a \n",
    "from datetime import date\n",
    "\n",
    "dates = pl.date_range(date(2001, 1, 1), date(2025, 5, 1), \"1d\", eager=True)\n",
    "df = pds.frame(size=len(dates)).select(\n",
    "    pds.random().alias(\"predicted\"),\n",
    "    (pds.random() > 0.25).cast(pl.UInt8).alias(\"actual_target\"),\n",
    "    dates = dates,\n",
    ")\n",
    "df_pd = df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, log_loss, brier_score_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "df_pd[\"year\"] = df['dates'].dt.year()\n",
    "df_pd.groupby([\"year\"]).apply(\n",
    "    lambda df_group: pd.Series({\n",
    "        \"count\": len(df_group[\"actual_target\"]),\n",
    "        \"roc_auc\": roc_auc_score(df_group[\"actual_target\"], df_group[\"predicted\"]),\n",
    "        \"log_loss\": roc_auc_score(df_group[\"actual_target\"], df_group[\"predicted\"])\n",
    "    })\n",
    "    , include_groups=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "df.group_by(pl.col(\"dates\").dt.year()).agg(\n",
    "    count = pl.len(),\n",
    "    roc_auc = pds.query_roc_auc(\"actual_target\", \"predicted\"),\n",
    "    log_loss = pds.query_log_loss(\"actual_target\", \"predicted\")\n",
    ").sort(\"dates\")\n",
    "# Run this in linux, you should see\n",
    "# 1/4 of the time, less lines of code + easier to understand syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Traditional ML Pipelines\n",
    "\n",
    "Use cases:\n",
    "\n",
    "1. Data Transformation before model training\n",
    "2. Feature Engineering pipelines, etc.\n",
    "\n",
    "Comparison: \n",
    "\n",
    "Polars + PDS vs. Pandas + Sklearn vs. Polars + Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A random Dataframe with 50k records\n",
    "size = 50_000\n",
    "df_pl = pds.frame(size=size).select(\n",
    "    pds.random(0.0, 1.0).alias(\"x1\"),\n",
    "    pds.random(0.0, 1.0).alias(\"x2\"),\n",
    "    pds.random(0.0, 1.0).alias(\"x3\"),\n",
    ").with_columns(\n",
    "    x4 = pl.when(pl.col(\"x3\") > 0.3).then(None).otherwise(pl.col(\"x3\")),\n",
    "    x5 = pl.when(pl.col(\"x2\") > 0.5).then(None).otherwise(pl.col(\"x2\")),\n",
    ")\n",
    "df_pd = df_pl.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pl.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas + Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "set_config(transform_output=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_step = ColumnTransformer(\n",
    "    [(\"MedianImputer1\", SimpleImputer(strategy=\"median\"), [3]),\n",
    "    (\"MedianImputer2\", SimpleImputer(strategy=\"median\"), [4])],\n",
    "    remainder = \"passthrough\",\n",
    "    verbose_feature_names_out = False,\n",
    ")\n",
    "\n",
    "pipe = Pipeline(steps = [\n",
    "    (\"Imputer\", impute_step), # impute only column 3 and 4\n",
    "    (\"StandardScaler\", StandardScaler()), # Scale all columns\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit_transform(df_pd)[[\"x1\", \"x2\", \"x3\", \"x4\", \"x5\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "pipe.fit_transform(df_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polars + Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import set_config\n",
    "set_config(transform_output=\"polars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit_transform(df_pl).select([\"x1\", \"x2\", \"x3\", \"x4\", \"x5\"]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "pipe.fit_transform(df_pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you use sklearn, there is not a lot of time difference because they underlying engine\n",
    "# is not parallel (there are options but they don't work properly on Linux, which is basically\n",
    "# all cloud compute nowadays.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polars + Polars DS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polars_ds.modeling.pipeline import Pipeline, Blueprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp = (\n",
    "    Blueprint(df_pl, name = \"example_pipeline\") \n",
    "    .impute([\"x4\", \"x5\"], method = \"median\")\n",
    "    .scale(pl.all(), method = \"standard\")\n",
    ")\n",
    "\n",
    "pipe = bp.materialize() # bp.fit() also works\n",
    "pipe.transform(df_pl).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "pipe = bp.materialize() # bp.fit() also works\n",
    "pipe.transform(df_pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This reason for this incredible speedup is\n",
    "# 1. PDS run natively in Polars, which means free parallelization\n",
    "# 2. Impute, despite being a very common data transformation, is very slow in Sklearn\n",
    "# but is extremely fast in Polars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
