"""
Greeum v2.0 í†µí•© CLI ì‹œìŠ¤í…œ

ì‚¬ìš©ë²•:
  greeum memory add "ìƒˆë¡œìš´ ê¸°ì–µ"
  greeum memory search "ê²€ìƒ‰ì–´"
  greeum mcp serve --transport stdio
  greeum api serve --port 5000
"""

try:
    import click
except ImportError:
    print("[ERROR] Click not installed. Install with: pip install greeum")
    import sys
    sys.exit(1)

import os
import sys
import sqlite3
from pathlib import Path
from typing import Optional

from ..config_store import (
    DEFAULT_DATA_DIR,
    DEFAULT_ST_MODEL,
    GreeumConfig,
    ensure_data_dir,
    load_config,
    mark_semantic_ready,
    save_config,
)
from ..core.database_manager import DatabaseManager
from ..core.branch_schema import BranchSchemaSQL


def _download_sentence_transformer(model: str) -> Path:
    try:
        from sentence_transformers import SentenceTransformer
    except ImportError as exc:
        raise ImportError(
            "sentence-transformers not installed. Install with 'pip install greeum[full]' "
            "or 'pip install sentence-transformers'."
        ) from exc

    cache_dir = Path.home() / ".cache" / "sentence_transformers"
    SentenceTransformer(model, cache_folder=str(cache_dir))
    return cache_dir

@click.group()
@click.version_option()
@click.option('--verbose', '-v', is_flag=True, help='Enable verbose logging')
@click.option('--debug', is_flag=True, help='Enable debug logging (most verbose)')
@click.option('--quiet', '-q', is_flag=True, help='Suppress all non-essential output')
@click.pass_context
def main(ctx: click.Context, verbose: bool, debug: bool, quiet: bool):
    """Greeum Universal Memory System"""
    
    # Contextì— ë¡œê·¸ ì„¤ì • ì €ì¥
    ctx.ensure_object(dict)
    ctx.obj['verbose'] = verbose
    ctx.obj['debug'] = debug
    ctx.obj['quiet'] = quiet
    
    # Console output ì„¤ì •ì„ ìœ„í•œ í™˜ê²½ë³€ìˆ˜ ì„¤ì •
    if verbose or debug:
        os.environ['GREEUM_CLI_VERBOSE'] = '1'
    else:
        os.environ.pop('GREEUM_CLI_VERBOSE', None)
    
    # ë¡œê·¸ ë ˆë²¨ ì„¤ì •
    import logging
    
    if debug:
        log_level = logging.DEBUG
    elif verbose:
        log_level = logging.INFO
    elif quiet:
        log_level = logging.ERROR
    else:
        log_level = logging.WARNING  # ê¸°ë³¸ê°’: ê²½ê³  ì´ìƒë§Œ í‘œì‹œ
    
    # ë¡œê·¸ í¬ë§· ì„¤ì •
    if debug:
        log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    elif verbose:
        log_format = '%(levelname)s: %(message)s'
    else:
        log_format = '%(message)s'
    
    logging.basicConfig(
        level=log_level,
        format=log_format,
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # íŠ¹ì • ë¡œê±°ë“¤ì˜ ë ˆë²¨ ì¡°ì • (ë„ˆë¬´ ì‹œë„ëŸ¬ìš´ ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤)
    if not debug:
        logging.getLogger('urllib3').setLevel(logging.WARNING)
        logging.getLogger('requests').setLevel(logging.WARNING)
        logging.getLogger('sqlalchemy').setLevel(logging.WARNING)

    # Ensure data directory from config is available if user hasn't set env vars
    config = load_config()
    data_dir = config.data_dir or str(DEFAULT_DATA_DIR)
    ensure_data_dir(data_dir)
    os.environ.setdefault('GREEUM_DATA_DIR', data_dir)


@main.command()
@click.option('--data-dir', type=click.Path(file_okay=False, dir_okay=True, writable=True), help='Custom data directory')
@click.option('--skip-warmup', is_flag=True, help='Skip SentenceTransformer warm-up step')
def setup(data_dir: Optional[str], skip_warmup: bool):
    """Interactive first-time setup (data dir + optional warm-up)."""

    click.echo("ğŸ› ï¸  Greeum setup wizard")
    config = load_config()

    default_dir = data_dir or config.data_dir or str(DEFAULT_DATA_DIR)
    chosen_dir = click.prompt(
        "Data directory (used for memories, cache, logs)",
        default=str(Path(default_dir).expanduser()),
    )

    target_dir = ensure_data_dir(chosen_dir)
    os.environ['GREEUM_DATA_DIR'] = str(target_dir)

    semantic_ready = config.semantic_ready
    warmup_performed = False

    if skip_warmup:
        click.echo("Skipping embedding warm-up (hash fallback will be used by default).")
    else:
        default_confirm = not config.semantic_ready
        if click.confirm("Run SentenceTransformer warm-up now?", default=default_confirm):
            click.echo(f"ğŸ“¦ Downloading {DEFAULT_ST_MODEL} â€¦")
            try:
                cache_dir = _download_sentence_transformer(DEFAULT_ST_MODEL)
            except ImportError as exc:
                click.echo(f"[ERROR] {exc}", err=True)
                semantic_ready = False
            except Exception as exc:  # noqa: BLE001
                click.echo(f"[ERROR] Warm-up failed: {exc}", err=True)
                semantic_ready = False
            else:
                click.echo(f"âœ… Warm-up complete. Model cached at {cache_dir}.")
                semantic_ready = True
                warmup_performed = True
        else:
            click.echo("Warm-up skipped. You can run 'greeum mcp warmup' later.")

    config.data_dir = str(target_dir)
    config.semantic_ready = semantic_ready
    save_config(config)

    if warmup_performed:
        mark_semantic_ready(True)
    elif not semantic_ready:
        mark_semantic_ready(False)

    click.echo("\nSetup summary:")
    click.echo(f"   â€¢ Data directory: {target_dir}")
    click.echo(
        "   â€¢ Semantic embeddings: "
        + ("ready" if semantic_ready else "hash fallback (run warmup to enable)")
    )
    click.echo("   â€¢ Next step: add 'greeum mcp serve -t stdio' to your MCP config")
@main.group()
def memory():
    """Memory management commands (STM/LTM)"""
    pass

@main.group() 
def mcp():
    """MCP server commands"""
    pass

@main.group()
def ltm():
    """Long-term memory (LTM) specialized commands"""
    pass

@main.group()
def stm():
    """Short-term memory (STM) specialized commands"""
    pass

@main.group()
def api():
    """API server commands"""
    pass

@main.group()
def slots():
    """AI Context Slots management (v2.5.1 enhanced)"""
    pass

@main.group()
def migrate():
    """Database migration commands (v2.5.3 AI-Powered Migration)"""
    pass

@main.group()
def backup():
    """Memory backup and restore commands (v2.6.1)"""
    pass

@main.group() 
def restore():
    """Memory restore commands (v2.6.1)"""
    pass

@main.group()
def dashboard():
    """Memory dashboard and analytics (v2.6.2)"""
    pass

@main.group()
def graph():
    """Graph network management (v3.0.0)"""
    pass

@main.group()
def metrics():
    """Metrics and performance monitoring"""
    pass

@main.group()
def validate():
    """Documentation and code validation"""
    pass

@main.command()
@click.option('--check', is_flag=True, help='ì§„ë‹¨ë§Œ ìˆ˜í–‰')
@click.option('--fix', is_flag=True, help='ìë™ ë³µêµ¬ í¬í•¨')
@click.option('--force', is_flag=True, help='ê°•ì œ ë³µêµ¬')
@click.option('--no-backup', is_flag=True, help='ë°±ì—… ìƒëµ')
@click.option('--db-path', help='ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ')
def doctor(check: bool, fix: bool, force: bool, no_backup: bool, db_path: str):
    """System diagnostics and repair tool (ì²´í¬, ë§ˆì´ê·¸ë ˆì´ì…˜, ì •ë¦¬, ìµœì í™”)"""
    try:
        from .doctor import GreeumDoctor

        doctor_instance = GreeumDoctor(db_path)

        # ë°±ì—…
        if (fix or force) and not no_backup:
            backup_path = doctor_instance.backup_database()
            click.echo(f"ğŸ“¦ ë°±ì—… ìƒì„±: {backup_path}")

        # ì§„ë‹¨
        health = doctor_instance.check_health()
        doctor_instance.print_report(health)

        # ë³µêµ¬
        if fix or force or (not check and doctor_instance.issues):
            if not check and not fix and not force:
                response = click.confirm("\në³µêµ¬ë¥¼ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?", default=False)
                if not response:
                    click.echo("ë³µêµ¬ê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                    return

            fixes = doctor_instance.fix_issues(force)
            if fixes:
                click.echo(f"\nâœ… ë³µêµ¬ ì™„ë£Œ: {len(fixes)}ê°œ ë¬¸ì œ í•´ê²°")
                for fix_msg in fixes:
                    click.echo(f"  â€¢ {fix_msg}")

            # ì¬ì§„ë‹¨
            click.echo("\nğŸ”„ ë³µêµ¬ í›„ ì¬ì§„ë‹¨...")
            health = doctor_instance.check_health()
            click.echo(f"\nìµœì¢… ìƒíƒœ: ì ìˆ˜ {health['total_score']:.0f}/100")

        sys.exit(0 if health['total_score'] >= 70 else 1)

    except Exception as e:
        click.echo(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)


# Memory ì„œë¸Œëª…ë ¹ì–´ë“¤
@memory.command()
@click.argument('content')
@click.option('--importance', '-i', default=0.5, help='Importance score (0.0-1.0)')
@click.option('--tags', '-t', help='Comma-separated tags')
@click.option('--slot', '-s', type=click.Choice(['A', 'B', 'C']), help='Insert near specified anchor slot')
def add(content: str, importance: float, tags: Optional[str], slot: Optional[str]):
    """Add new memory to long-term storage"""
    try:
        if slot:
            # Use anchor-based write
            from ..api.write import write as anchor_write
            
            result = anchor_write(
                text=content,
                slot=slot,
                policy={'importance': importance, 'tags': tags}
            )
            
            click.echo(f"âœ… Memory added near anchor {slot} (Block #{result})")
            
        else:
            # Use traditional write
            from ..core import BlockManager, DatabaseManager
            from ..text_utils import process_user_input
            
            db_manager = DatabaseManager()
            block_manager = BlockManager(db_manager)
            
            # í…ìŠ¤íŠ¸ ì²˜ë¦¬
            processed = process_user_input(content)
            keywords = processed.get('keywords', [])
            tag_list = tags.split(',') if tags else processed.get('tags', [])
            embedding = processed.get('embedding', [0.0] * 384)
            
            # ë¸”ë¡ ì¶”ê°€
            block = block_manager.add_block(
                context=content,
                keywords=keywords,
                tags=tag_list,
                embedding=embedding,
                importance=importance
            )
            
            if block:
                # block is now just the block_index (int) instead of a dict
                click.echo(f"âœ… Memory added (Block #{block})")
            else:
                click.echo("[ERROR] Failed to add memory")
            
    except Exception as e:
        click.echo(f"[ERROR] Error: {e}")
        sys.exit(1)

@memory.command()
@click.argument('query')
@click.option('--count', '-c', default=5, help='Number of results')
@click.option('--threshold', '-th', default=0.1, help='Similarity threshold')
@click.option('--slot', '-s', type=click.Choice(['A', 'B', 'C']), help='Use anchor-based localized search')
@click.option('--radius', '-r', type=int, help='Graph search radius (1-3)')
@click.option('--no-fallback', is_flag=True, help='Disable fallback to global search')
def search(query: str, count: int, threshold: float, slot: str, radius: int, no_fallback: bool):
    """Search memories by keywords/semantic similarity"""
    try:
        from ..core.block_manager import BlockManager
        from ..core.database_manager import DatabaseManager

        # Use BlockManager for DFS-based search instead of SearchEngine
        db_manager = DatabaseManager()
        block_manager = BlockManager(db_manager)

        # Perform search with v3 DFS system
        result = block_manager.search_with_slots(
            query=query,
            limit=count,
            use_slots=True,
            entry="cursor",
            depth=3 if slot else 0,
            fallback=not no_fallback
        )

        # Extract blocks from result
        if isinstance(result, dict):
            blocks = result.get('items', [])
            metadata = result.get('meta', {})
        else:
            blocks = result
        metadata = result.get('metadata', {})
        timing = result.get('timing', {})
        
        if blocks:
            # Display search info
            if slot:
                search_type = f"ğŸ¯ Anchor-based search (slot {slot})"
                if metadata.get('fallback_used'):
                    search_type += " â†’ [PROCESS] Global fallback"
                click.echo(search_type)
                click.echo(f"   Hit rate: {metadata.get('local_hit_rate', 0):.1%}")
                click.echo(f"   Avg hops: {metadata.get('avg_hops', 0)}")
            else:
                click.echo("ğŸ” Global semantic search")
            
            # Display timing
            total_ms = sum(timing.values())
            click.echo(f"   Search time: {total_ms:.1f}ms")
            
            click.echo(f"\nğŸ“‹ Found {len(blocks)} memories:")
            for i, block in enumerate(blocks, 1):
                timestamp = block.get('timestamp', 'Unknown')
                content = block.get('context', 'No content')[:80]
                relevance = block.get('relevance_score', 0)
                final_score = block.get('final_score', relevance)
                
                click.echo(f"{i}. [{timestamp}] {content}...")
                click.echo(f"   Score: {final_score:.3f}")
        else:
            if slot and not no_fallback:
                click.echo(f"[ERROR] No memories found in anchor slot {slot}, and fallback disabled")
            else:
                click.echo("[ERROR] No memories found")

    except Exception as e:
        click.echo(f"[ERROR] Search failed: {e}")
        sys.exit(1)


@memory.command('reindex')
@click.option(
    '--data-dir',
    type=click.Path(file_okay=False, dir_okay=True, writable=True),
    help='Target data directory (defaults to configured data store)',
)
@click.option('--disable-faiss', is_flag=True, help='Skip FAISS vector index rebuild')
def memory_reindex(data_dir: Optional[str], disable_faiss: bool) -> None:
    """Rebuild branch-aware indices for the selected database."""
    from ..core.branch_index import BranchIndexManager

    if disable_faiss:
        os.environ['GREEUM_DISABLE_FAISS'] = 'true'

    if data_dir:
        target_dir = Path(data_dir).expanduser()
        db_path = target_dir if target_dir.suffix == '.db' else target_dir / 'memory.db'
        manager = DatabaseManager(connection_string=str(db_path))
    else:
        manager = DatabaseManager()

    click.echo('ğŸ”„ Rebuilding branch indices...')
    try:
        branch_manager = BranchIndexManager(manager)
        stats = branch_manager.get_stats()
        click.echo(
            "âœ… Rebuilt {count} branches ({mode}, vectorized={vectorized}).".format(
                count=stats['branch_count'],
                mode=stats['mode'],
                vectorized=stats['vectorized_branches'],
            )
        )
    except Exception as exc:  # noqa: BLE001 - surface to CLI
        click.echo(f"[ERROR] Branch reindex failed: {exc}")
        sys.exit(1)
    finally:
        try:
            manager.conn.close()
        except Exception:
            pass
        except Exception:
            pass

# MCP ì„œë¸Œëª…ë ¹ì–´ë“¤
@mcp.command()
@click.option('--transport', '-t', default='stdio', help='Transport type (stdio/http/ws)')
@click.option('--port', '-p', default=3000, help='Port for HTTP or WebSocket transports')
@click.option('--host', default='127.0.0.1', show_default=True, help='Host for HTTP transport')
@click.option('--verbose', '-v', is_flag=True, help='Enable verbose logging (INFO level)')
@click.option('--debug', '-d', is_flag=True, help='Enable debug logging (DEBUG level)')
@click.option('--quiet', '-q', is_flag=True, help='[DEPRECATED] Use default behavior instead')
@click.option('--semantic/--no-semantic', default=False, show_default=True,
              help='Enable semantic embeddings (requires cached SentenceTransformer)')
def serve(transport: str, port: int, host: str, verbose: bool, debug: bool, quiet: bool, semantic: bool):
    """Start MCP server for Claude Code integration"""  
    config = load_config()
    # ë¡œê¹… ë ˆë²¨ ê²°ì • (ìƒˆë¡œìš´ ì •ì±…: ê¸°ë³¸ì€ ì¡°ìš©í•¨)
    if debug:
        log_level = 'debug'
        click.echo(f"ğŸ” Starting Greeum MCP server ({transport}) - DEBUG mode...")
    elif verbose:
        log_level = 'verbose'
        click.echo(f"[NOTE] Starting Greeum MCP server ({transport}) - VERBOSE mode...")
    else:
        log_level = 'quiet'
        # ê¸°ë³¸ì€ ì¡°ìš©í•¨ (ì¶œë ¥ ì—†ìŒ)
    
    # --quiet í”Œë˜ê·¸ í˜¸í™˜ì„± ê²½ê³ 
    if quiet:
        if verbose or debug:
            click.echo("âš ï¸  Warning: --quiet is deprecated and conflicts with --verbose/--debug")
        else:
            click.echo("âš ï¸  Warning: --quiet is deprecated. Default behavior is now quiet.")
    
    if transport == 'stdio':
        ensure_data_dir(config.data_dir)
        os.environ.setdefault('GREEUM_DATA_DIR', config.data_dir)
        if semantic:
            # Allow explicit opt-in by clearing the fallback flag
            if os.getenv('GREEUM_DISABLE_ST'):
                os.environ.pop('GREEUM_DISABLE_ST')
            if verbose or debug and not config.semantic_ready:
                click.echo('[WARN] Semantic mode requested but warm-up is not recorded; first startup may take longer.')
        else:
            os.environ.setdefault('GREEUM_DISABLE_ST', '1')
            if verbose or debug:
                if config.semantic_ready:
                    click.echo('[NOTE] Semantic embeddings available. Use --semantic to enable them for this session.')
                else:
                    click.echo('[NOTE] SentenceTransformer disabled (hash fallback). Use --semantic after warm-up to re-enable.')
        try:
            # Native MCP Server ì‚¬ìš© (FastMCP ì™„ì „ ë°°ì œ, anyio ê¸°ë°˜ ì•ˆì „í•œ ì‹¤í–‰)
            from ..mcp.native import run_server_sync
            run_server_sync(log_level=log_level)
        except ImportError as e:
            if verbose or debug:
                click.echo(f"Native MCP server import failed: {e}")
                click.echo("Please ensure anyio>=4.5 is installed: pip install anyio>=4.5")
            sys.exit(1)
        except KeyboardInterrupt:
            if verbose or debug:
                click.echo("\nMCP server stopped")
        except Exception as e:
            # anyio CancelledErrorë„ ì—¬ê¸°ì„œ ìºì¹˜ë¨ - ì¡°ìš©íˆ ì²˜ë¦¬
            error_msg = str(e)
            if "CancelledError" in error_msg or "cancelled" in error_msg.lower():
                if verbose or debug:
                    click.echo("\nMCP server stopped")
            else:
                if verbose or debug:
                    click.echo(f"MCP server error: {e}")
                sys.exit(1)
    elif transport == 'http':
        try:
            from ..mcp.native.http_server import run_http_server
            run_http_server(host=host, port=port, log_level=log_level)
        except RuntimeError as e:
            if verbose or debug:
                click.echo(str(e))
            sys.exit(1)
        except KeyboardInterrupt:
            if verbose or debug:
                click.echo("\nMCP HTTP server stopped")
        except Exception as e:
            if verbose or debug:
                click.echo(f"MCP HTTP server error: {e}")
            sys.exit(1)
    elif transport == 'websocket':
        try:
            # WebSocket transport (í–¥í›„ í™•ì¥)
            from ..mcp.cli_entry import run_cli_server
            run_cli_server(transport='websocket', port=port)
        except ImportError as e:
            if verbose or debug:
                click.echo(f"MCP server import failed: {e}")
                click.echo("Please ensure all dependencies are installed")
            sys.exit(1)
        except NotImplementedError:
            if verbose or debug:
                click.echo(f"WebSocket transport not implemented yet")
            sys.exit(1)
        except KeyboardInterrupt:
            if verbose or debug:
                click.echo("\nMCP server stopped")
        except Exception as e:
            if verbose or debug:
                click.echo(f"MCP server error: {e}")
            sys.exit(1)
    else:
        if verbose or debug:
            click.echo(f"[ERROR] Transport '{transport}' not supported")
        sys.exit(1)


@mcp.command('warmup')
@click.option('--model', default='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
              show_default=True, help='SentenceTransformer model to pre-download')
def warmup_embeddings(model: str):
    """Download the semantic embedding model so --semantic starts instantly."""

    click.echo(f"ğŸ“¦ Downloading {model} â€¦")

    try:
        cache_dir = _download_sentence_transformer(model)
    except ImportError as exc:
        click.echo(f"[ERROR] {exc}", err=True)
        mark_semantic_ready(False)
        sys.exit(1)
    except Exception as exc:  # noqa: BLE001 - surface full error to user
        click.echo(f"[ERROR] Warm-up failed: {exc}", err=True)
        mark_semantic_ready(False)
        sys.exit(1)

    mark_semantic_ready(True)
    click.echo(f"âœ… Warm-up complete. Model cached at {cache_dir}.")
    click.echo("   Use 'greeum mcp serve --semantic' to enable semantic embeddings.")


# API ì„œë¸Œëª…ë ¹ì–´ë“¤  
@api.command()
@click.option('--port', '-p', default=5000, help='Server port')
@click.option('--host', '-h', default='localhost', help='Server host')
def serve(port: int, host: str):
    """Start REST API server"""
    click.echo(f"ğŸŒ Starting Greeum API server on {host}:{port}...")
    
    try:
        from ..api.memory_api import app
        import uvicorn
        uvicorn.run(app, host=host, port=port)
    except ImportError:
        click.echo("[ERROR] API server dependencies not installed. Try: pip install greeum[api]")
        sys.exit(1)
    except KeyboardInterrupt:
        click.echo("\nğŸ‘‹ API server stopped")

# LTM ì„œë¸Œëª…ë ¹ì–´ë“¤
@ltm.command()
@click.option('--trends', is_flag=True, help='Analyze emotional and topic trends')
@click.option('--period', '-p', default='6m', help='Analysis period (e.g., 6m, 1y)')
@click.option('--output', '-o', default='text', help='Output format (text/json)')
def analyze(trends: bool, period: str, output: str):
    """Analyze long-term memory patterns and trends"""
    click.echo(f"ğŸ” Analyzing LTM patterns...")
    
    if trends:
        click.echo(f"ğŸ“Š Trend analysis for period: {period}")
    
    try:
        from ..core import BlockManager, DatabaseManager
        import json
        from datetime import datetime, timedelta
        
        # ê¸°ê°„ íŒŒì‹±
        period_map = {'m': 'months', 'y': 'years', 'd': 'days', 'w': 'weeks'}
        period_num = int(period[:-1])
        period_unit = period_map.get(period[-1], 'months')
        
        db_manager = DatabaseManager()
        block_manager = BlockManager(db_manager)
        
        # ì „ì²´ ë¸”ë¡ ì¡°íšŒ
        all_blocks = block_manager.get_blocks()
        
        analysis = {
            "total_blocks": len(all_blocks),
            "analysis_period": period,
            "analysis_date": datetime.now().isoformat(),
            "summary": f"Analyzed {len(all_blocks)} memory blocks"
        }
        
        if trends:
            # í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„
            keyword_freq = {}
            for block in all_blocks:
                keywords = block.get('keywords', [])
                for keyword in keywords:
                    keyword_freq[keyword] = keyword_freq.get(keyword, 0) + 1
            
            # ìƒìœ„ í‚¤ì›Œë“œ
            top_keywords = sorted(keyword_freq.items(), key=lambda x: x[1], reverse=True)[:10]
            analysis["top_keywords"] = top_keywords
        
        if output == 'json':
            click.echo(json.dumps(analysis, indent=2, ensure_ascii=False))
        else:
            click.echo(f"[IMPROVE] Analysis Results:")
            click.echo(f"  â€¢ Total memories: {analysis['total_blocks']}")
            click.echo(f"  â€¢ Period: {analysis['analysis_period']}")
            if trends and 'top_keywords' in analysis:
                click.echo(f"  â€¢ Top keywords:")
                for keyword, freq in analysis['top_keywords'][:5]:
                    click.echo(f"    - {keyword}: {freq} times")
                    
    except Exception as e:
        click.echo(f"[ERROR] Analysis failed: {e}")
        sys.exit(1)

@ltm.command()
@click.option('--repair', is_flag=True, help='Attempt to repair integrity issues')
def verify(repair: bool):
    """Verify blockchain-like LTM integrity"""
    click.echo("ğŸ” Verifying LTM blockchain integrity...")
    
    try:
        from ..core import BlockManager, DatabaseManager
        import hashlib
        
        db_manager = DatabaseManager()
        block_manager = BlockManager(db_manager)
        
        all_blocks = block_manager.get_blocks()
        
        issues = []
        verified_count = 0
        
        for i, block in enumerate(all_blocks):
            # í•´ì‹œ ê²€ì¦
            if 'hash' in block:
                # ë¸”ë¡ ë°ì´í„°ë¡œë¶€í„° í•´ì‹œ ì¬ê³„ì‚°
                block_data = {
                    'block_index': block.get('block_index'),
                    'timestamp': block.get('timestamp'),
                    'context': block.get('context'),
                    'prev_hash': block.get('prev_hash', '')
                }
                calculated_hash = hashlib.sha256(
                    str(block_data).encode()
                ).hexdigest()[:16]
                
                if block.get('hash') != calculated_hash:
                    issues.append(f"Block #{block.get('block_index', i)}: Hash mismatch")
                else:
                    verified_count += 1
            else:
                issues.append(f"Block #{block.get('block_index', i)}: Missing hash")
        
        # ê²°ê³¼ ì¶œë ¥
        total_blocks = len(all_blocks)
        click.echo(f"âœ… Verified {verified_count}/{total_blocks} blocks")
        
        if issues:
            click.echo(f"âš ï¸  Found {len(issues)} integrity issues:")
            for issue in issues[:10]:  # ìµœëŒ€ 10ê°œë§Œ í‘œì‹œ
                click.echo(f"  â€¢ {issue}")
            
            if repair:
                click.echo("ğŸ”¨ Repair functionality not implemented yet")
        else:
            click.echo("[SUCCESS] All blocks verified successfully!")
                    
    except Exception as e:
        click.echo(f"[ERROR] Verification failed: {e}")
        sys.exit(1)

@ltm.command()
@click.option('--format', '-f', default='json', help='Export format (json/blockchain/csv)')
@click.option('--output', '-o', help='Output file path')
@click.option('--limit', '-l', type=int, help='Limit number of blocks')
def export(format: str, output: str, limit: int):
    """Export LTM data in various formats"""
    click.echo(f"ğŸ“¤ Exporting LTM data (format: {format})...")
    
    try:
        from ..core import BlockManager, DatabaseManager
        import json
        import csv
        from pathlib import Path
        
        db_manager = DatabaseManager()
        block_manager = BlockManager(db_manager)
        
        all_blocks = block_manager.get_blocks()
        
        if limit:
            all_blocks = all_blocks[:limit]
        
        # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ ê²°ì •
        if not output:
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output = f"greeum_ltm_export_{timestamp}.{format}"
        
        output_path = Path(output)
        
        if format == 'json':
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(all_blocks, f, indent=2, ensure_ascii=False)
                
        elif format == 'blockchain':
            # ë¸”ë¡ì²´ì¸ í˜•íƒœë¡œ êµ¬ì¡°í™”
            blockchain_data = {
                "chain_info": {
                    "total_blocks": len(all_blocks),
                    "export_date": datetime.now().isoformat(),
                    "format_version": "1.0"
                },
                "blocks": all_blocks
            }
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(blockchain_data, f, indent=2, ensure_ascii=False)
                
        elif format == 'csv':
            with open(output_path, 'w', newline='', encoding='utf-8') as f:
                if all_blocks:
                    writer = csv.DictWriter(f, fieldnames=all_blocks[0].keys())
                    writer.writeheader()
                    writer.writerows(all_blocks)
        
        click.echo(f"âœ… Exported {len(all_blocks)} blocks to: {output_path}")
        click.echo(f"ğŸ“„ File size: {output_path.stat().st_size} bytes")
                    
    except Exception as e:
        click.echo(f"[ERROR] Export failed: {e}")
        sys.exit(1)

# STM ì„œë¸Œëª…ë ¹ì–´ë“¤
@stm.command()
@click.argument('content')
@click.option('--ttl', default='1h', help='Time to live (e.g., 1h, 30m, 2d)')
@click.option('--importance', '-i', default=0.3, help='Importance score (0.0-1.0)')
def add(content: str, ttl: str, importance: float):
    """Add content to short-term memory with TTL"""
    click.echo(f"[MEMORY] Adding to STM (TTL: {ttl})...")
    
    try:
        from ..core import STMManager, DatabaseManager
        import re
        from datetime import datetime, timedelta
        
        # TTL íŒŒì‹±
        ttl_pattern = r'(\d+)([hmdw])'
        match = re.match(ttl_pattern, ttl.lower())
        if not match:
            click.echo("[ERROR] Invalid TTL format. Use: 1h, 30m, 2d, 1w")
            sys.exit(1)
        
        amount, unit = match.groups()
        amount = int(amount)
        
        unit_map = {'m': 'minutes', 'h': 'hours', 'd': 'days', 'w': 'weeks'}
        unit_name = unit_map.get(unit, 'hours')
        
        # TTL ê³„ì‚°
        kwargs = {unit_name: amount}
        expiry_time = datetime.now() + timedelta(**kwargs)
        
        db_manager = DatabaseManager()
        stm_manager = STMManager(db_manager)
        
        # STMì— ì¶”ê°€
        memory_data = {
            'content': content,
            'importance': importance,
            'ttl_seconds': int(timedelta(**kwargs).total_seconds()),
            'expiry_time': expiry_time.isoformat()
        }
        result = stm_manager.add_memory(memory_data)
        
        if result:
            click.echo(f"âœ… Added to STM (expires: {expiry_time.strftime('%Y-%m-%d %H:%M:%S')})")
        else:
            click.echo("[ERROR] Failed to add to STM")
            sys.exit(1)
                    
    except Exception as e:
        click.echo(f"[ERROR] STM add failed: {e}")
        sys.exit(1)

@stm.command()
@click.option('--threshold', '-t', default=0.8, help='Importance threshold for promotion')
@click.option('--dry-run', is_flag=True, help='Show what would be promoted without doing it')
def promote(threshold: float, dry_run: bool):
    """Promote important STM entries to LTM"""
    click.echo(f"ğŸ” Promoting STM â†’ LTM (threshold: {threshold})...")
    
    try:
        from ..core import STMManager, BlockManager, DatabaseManager
        from ..text_utils import process_user_input
        
        db_manager = DatabaseManager()
        stm_manager = STMManager(db_manager)
        block_manager = BlockManager(db_manager)
        
        # STMì—ì„œ ëª¨ë“  í•­ëª© ì¡°íšŒ (ì¶©ë¶„íˆ í° ìˆ˜ë¡œ)
        stm_entries = stm_manager.get_recent_memories(count=1000)
        
        candidates = []
        for entry in stm_entries:
            if entry.get('importance', 0) >= threshold:
                candidates.append(entry)
        
        if not candidates:
            click.echo(f"ğŸ“­ No STM entries above threshold {threshold}")
            return
        
        click.echo(f"ğŸ¯ Found {len(candidates)} candidates for promotion:")
        
        promoted_count = 0
        for entry in candidates:
            content = entry.get('content', '')
            importance = entry.get('importance', 0)
            
            click.echo(f"  â€¢ {content[:50]}... (importance: {importance:.2f})")
            
            if not dry_run:
                # LTMìœ¼ë¡œ ìŠ¹ê²©
                keywords, tags = process_user_input(content)
                
                # ê°„ë‹¨í•œ ì„ë² ë”© (ì‹¤ì œë¡œëŠ” ë” ì •êµí•˜ê²Œ)
                simple_embedding = [hash(word) % 1000 / 1000.0 for word in content.split()[:10]]
                simple_embedding.extend([0.0] * (10 - len(simple_embedding)))  # 10ì°¨ì›ìœ¼ë¡œ íŒ¨ë”©
                
                ltm_block = block_manager.add_block(
                    context=content,
                    keywords=keywords,
                    tags=tags,
                    embedding=simple_embedding,
                    importance=importance,
                    metadata={'promoted_from_stm': True}
                )
                
                if ltm_block:
                    # STMì—ì„œ ì œê±°
                    stm_manager.remove_memory(entry.get('id', ''))
                    promoted_count += 1
        
        if dry_run:
            click.echo(f"ğŸ” Dry run: {len(candidates)} entries would be promoted")
        else:
            click.echo(f"âœ… Promoted {promoted_count}/{len(candidates)} entries to LTM")
                    
    except Exception as e:
        click.echo(f"[ERROR] Promotion failed: {e}")
        sys.exit(1)

@stm.command()
@click.option('--smart', is_flag=True, help='Use intelligent cleanup based on importance')
@click.option('--expired', is_flag=True, help='Remove only expired entries')
@click.option('--threshold', '-t', default=0.2, help='Remove entries below this importance')
def cleanup(smart: bool, expired: bool, threshold: float):
    """Clean up short-term memory entries"""
    click.echo("ğŸ§¹ Cleaning up STM...")
    
    try:
        from ..core import STMManager, DatabaseManager
        from datetime import datetime
        
        db_manager = DatabaseManager()
        stm_manager = STMManager(db_manager)
        stm_entries = stm_manager.get_recent_memories(count=1000)
        
        if not stm_entries:
            click.echo("ğŸ“­ STM is already empty")
            return
        
        removed_count = 0
        total_count = len(stm_entries)
        
        click.echo(f"ğŸ“Š Total STM entries: {total_count}")
        
        for entry in stm_entries:
            should_remove = False
            reason = ""
            
            if expired:
                # ë§Œë£Œëœ í•­ëª©ë§Œ ì œê±°
                expiry = entry.get('expiry_time')
                if expiry and datetime.now() > datetime.fromisoformat(expiry):
                    should_remove = True
                    reason = "expired"
            
            elif smart:
                # ì§€ëŠ¥í˜• ì •ë¦¬
                importance = entry.get('importance', 0)
                if importance < threshold:
                    should_remove = True
                    reason = f"low importance ({importance:.2f} < {threshold})"
            
            else:
                # ê¸°ë³¸: ë‚®ì€ ì¤‘ìš”ë„ë§Œ
                importance = entry.get('importance', 0)
                if importance < 0.1:
                    should_remove = True
                    reason = "very low importance"
            
            if should_remove:
                entry_id = entry.get('id', '')
                content = entry.get('content', '')[:30]
                
                if stm_manager.remove_memory(entry_id):
                    click.echo(f"  ğŸ—‘ï¸  Removed: {content}... ({reason})")
                    removed_count += 1
        
        click.echo(f"âœ… Cleanup complete: {removed_count}/{total_count} entries removed")
        click.echo(f"ğŸ“Š Remaining STM entries: {total_count - removed_count}")
                    
    except Exception as e:
        click.echo(f"[ERROR] Cleanup failed: {e}")
        sys.exit(1)

# AI Context Slots ì„œë¸Œëª…ë ¹ì–´ë“¤ (v3.0.0.post5)
@slots.command()
def status():
    """Display current AI Context Slots status (v3.0.0.post5)"""
    click.echo("[MEMORY] AI Context Slots Status Report (v3.0.0.post5)")
    click.echo("=" * 50)
    
    try:
        from ..core.working_memory import AIContextualSlots
        from datetime import datetime
        
        # AI Context Slots ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        slots_instance = AIContextualSlots()
        
        # ìŠ¬ë¡¯ ìƒíƒœ í™•ì¸
        status = slots_instance.get_status()
        
        active_count = sum(1 for s in status.values() if s is not None)
        click.echo(f"Active Slots: {active_count}/3")
        
        for slot_name, slot_info in status.items():
            if slot_info:
                slot_type = slot_info['type']
                content = slot_info['content_preview']
                timestamp = slot_info['timestamp']
                importance = slot_info['importance']
                is_anchor = slot_info['is_anchor']
                
                # ìŠ¬ë¡¯ íƒ€ì…ë³„ ì•„ì´ì½˜
                type_icon = {"context": "ğŸ¯", "anchor": "âš“", "buffer": "ğŸ“‹"}.get(slot_type, "ğŸ”¹")
                
                click.echo(f"\n{type_icon} {slot_name.upper()} Slot ({slot_type})")
                click.echo(f"   Content: {content}")
                click.echo(f"   Importance: {importance:.2f}")
                click.echo(f"   Created: {timestamp}")
                
                if is_anchor and slot_info.get('anchor_block'):
                    click.echo(f"   [LINK] LTM Anchor: Block #{slot_info['anchor_block']}")
                    
            else:
                click.echo(f"\nâ­• {slot_name.upper()} Slot: Empty")
        
        click.echo("\n" + "=" * 50)
        click.echo("ğŸ’¡ Use 'greeum slots set <content>' to add to slots")
        click.echo("ğŸ’¡ Use 'greeum slots clear <slot_name>' to clear specific slot")
                    
    except Exception as e:
        click.echo(f"[ERROR] Error reading slots status: {e}")
        sys.exit(1)

@slots.command()
@click.argument('content')
@click.option('--importance', '-i', default=0.5, help='Importance score (0.0-1.0)')
@click.option('--ltm-anchor', type=int, help='LTM block ID for anchoring')
@click.option('--radius', default=5, help='Search radius for LTM anchor')
def set(content: str, importance: float, ltm_anchor: int, radius: int):
    """Add content to AI Context Slots with smart allocation"""
    click.echo(f"[MEMORY] Adding content to AI Context Slots...")
    
    try:
        from ..core.working_memory import AIContextualSlots
        
        # AI Context Slots ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        slots_instance = AIContextualSlots()
        
        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = {
            'importance': importance,
            'metadata': {'cli_command': True}
        }
        
        if ltm_anchor:
            context['ltm_block_id'] = ltm_anchor
            context['search_radius'] = radius
        
        # AIê°€ ìµœì  ìŠ¬ë¡¯ ê²°ì •
        used_slot = slots_instance.ai_decide_usage(content, context)
        
        # ê²°ê³¼ ì¶œë ¥
        click.echo(f"âœ… Content added to {used_slot.upper()} slot")
        click.echo(f"[NOTE] Content: {content[:80]}{'...' if len(content) > 80 else ''}")
        click.echo(f"ğŸ¯ AI chose {used_slot} slot based on content analysis")
        
        if ltm_anchor:
            click.echo(f"[LINK] LTM Anchor: Block #{ltm_anchor} (radius: {radius})")
        
    except Exception as e:
        click.echo(f"[ERROR] Failed to add to slots: {e}")
        sys.exit(1)

@slots.command()
@click.argument('slot_name', type=click.Choice(['active', 'anchor', 'buffer', 'all']))
def clear(slot_name: str):
    """Clear specific slot or all slots"""
    click.echo(f"ğŸ—‘ï¸  Clearing {slot_name} slot(s)...")
    
    try:
        from ..core.working_memory import AIContextualSlots
        
        # AI Context Slots ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        slots_instance = AIContextualSlots()
        
        if slot_name == "all":
            # ëª¨ë“  ìŠ¬ë¡¯ ë¹„ìš°ê¸°
            cleared_count = 0
            for slot in ['active', 'anchor', 'buffer']:
                if slots_instance.clear_slot(slot):
                    cleared_count += 1
            
            click.echo(f"âœ… Cleared {cleared_count} slots")
            
        else:
            # íŠ¹ì • ìŠ¬ë¡¯ ë¹„ìš°ê¸°
            if slots_instance.clear_slot(slot_name):
                click.echo(f"âœ… Cleared {slot_name.upper()} slot")
            else:
                click.echo(f"âš ï¸  {slot_name.upper()} slot was already empty")
        
    except Exception as e:
        click.echo(f"[ERROR] Failed to clear slot: {e}")
        sys.exit(1)

@slots.command()
@click.argument('query')
@click.option('--limit', '-l', default=5, help='Maximum number of results')
def search(query: str, limit: int):
    """Search using AI Context Slots integration"""
    click.echo(f"ğŸ” Searching with AI Context Slots: '{query}'")
    
    try:
        from greeum.core import DatabaseManager
        from greeum.core.block_manager import BlockManager
        
        db_manager = DatabaseManager()
        block_manager = BlockManager(db_manager)
        
        # ìŠ¬ë¡¯ í†µí•© ê²€ìƒ‰ ì‹¤í–‰
        results = block_manager.search_with_slots(
            query=query, 
            limit=limit, 
            use_slots=True
        )
        
        if results:
            click.echo(f"ğŸ“‹ Found {len(results)} results:")
            
            for i, result in enumerate(results, 1):
                source = result.get('source', 'unknown')
                content = result.get('context', 'No content')[:80]
                importance = result.get('importance', 0)
                
                if source == 'working_memory':
                    slot_type = result.get('slot_type', 'unknown')
                    type_icon = {"context": "ğŸ¯", "anchor": "âš“", "buffer": "ğŸ“‹"}.get(slot_type, "ğŸ”¹")
                    click.echo(f"{i}. {type_icon} [{slot_type.upper()} SLOT] {content}...")
                else:
                    block_index = result.get('block_index', '?')
                    click.echo(f"{i}. ğŸ“š [LTM #{block_index}] {content}...")
                
                click.echo(f"   Importance: {importance:.2f}")
        else:
            click.echo("[ERROR] No results found")
        
    except Exception as e:
        click.echo(f"[ERROR] Search failed: {e}")
        sys.exit(1)

# Migration ì„œë¸Œëª…ë ¹ì–´ë“¤ (v2.5.3 AI-Powered Migration)
@migrate.command()
@click.option('--data-dir', default='data', help='Data directory path')
@click.option('--force', is_flag=True, help='Force migration even if already v2.5.3')
def check(data_dir: str, force: bool):
    """Check database schema version and trigger migration if needed"""
    click.echo("ğŸ” Checking Greeum database schema version...")
    
    try:
        from pathlib import Path

        db_path = Path(data_dir).expanduser() / "memory.db"
        db_path.parent.mkdir(parents=True, exist_ok=True)

        manager = DatabaseManager(str(db_path))
        cursor = manager.conn.cursor()

        needs_migration = BranchSchemaSQL.check_migration_needed(cursor)

        if force or needs_migration:
            manager._apply_branch_migration(cursor)
            manager._initialize_branch_structures(cursor)
            manager.conn.commit()
            click.echo("\nâœ… Branch schema migration applied.")
        else:
            click.echo("\nâœ… Branch schema already up to date.")

        manager.conn.close()
        sys.exit(0)

    except Exception as e:
        click.echo(f"[ERROR] Migration check failed: {e}")
        sys.exit(1)

@migrate.command()
@click.option('--data-dir', default='data', help='Data directory path')
def status(data_dir: str):
    """Check current migration status and schema version"""
    click.echo("ğŸ“Š Greeum Database Migration Status")
    click.echo("=" * 40)
    
    try:
        from pathlib import Path

        db_path = Path(data_dir).expanduser() / "memory.db"

        if not db_path.exists():
            click.echo("ğŸ“‚ Database Status: Not found")
            click.echo("   This appears to be a new installation")
            return

        manager = DatabaseManager(str(db_path))
        cursor = manager.conn.cursor()

        cursor.execute("PRAGMA table_info(blocks)")
        columns = {row[1] for row in cursor.fetchall()}
        branch_columns = {
            'root', 'before', 'after', 'xref',
            'slot', 'branch_similarity', 'branch_created_at'
        }

        branch_ready = branch_columns.issubset(columns)
        slot_rows = []
        try:
            cursor.execute("SELECT slot_name, block_hash, branch_root FROM stm_slots ORDER BY slot_name")
            slot_rows = cursor.fetchall()
        except sqlite3.OperationalError:
            pass

        click.echo(f"ğŸ“‚ Database Size: {db_path.stat().st_size} bytes")
        click.echo(f"ğŸ“‹ Branch Columns Present: {'yes' if branch_ready else 'no'}")

        if slot_rows:
            click.echo("\nğŸ¯ STM Slots:")
            for slot_name, block_hash, branch_root in slot_rows:
                head = block_hash[:8] + '...' if block_hash else 'None'
                branch = branch_root[:8] + '...' if branch_root else 'None'
                click.echo(f"   â€¢ {slot_name}: head={head}, branch={branch}")
        else:
            click.echo("\nâš ï¸  STM slot entries not initialized (run 'greeum migrate check').")

        pending = BranchSchemaSQL.check_migration_needed(cursor)
        click.echo("\nâœ… Migration Status: {}".format("Ready" if not pending else "Additional migration required"))

        manager.conn.close()

    except Exception as e:
        click.echo(f"[ERROR] Status check failed: {e}")
        sys.exit(1)

@migrate.command()
@click.option('--data-dir', default='data', help='Data directory path')
@click.option('--backup-id', help='Specific backup ID to rollback to')
@click.option('--reason', default='Manual rollback', help='Reason for rollback')
def rollback(data_dir: str, backup_id: str, reason: str):
    """Rollback to previous database state using backups"""
    click.echo("â†©ï¸  Emergency rollback tooling has been deprecated in the branch-aware preview.")
    click.echo("   Please restore from your manual backup if needed.")
    sys.exit(0)

@migrate.command()
@click.option('--data-dir', default='data', help='Data directory path')
def validate(data_dir: str):
    """Validate migration results and database health"""
    click.echo("ğŸ” Automated migration validation is not available in this preview build.")
    click.echo("   Please run manual smoke tests after 'greeum migrate check'.")
    sys.exit(0)

@migrate.command()
@click.option('--data-dir', default='data', help='Data directory path')
@click.option('--keep-backups', default=5, help='Number of backups to keep')
def cleanup(data_dir: str, keep_backups: int):
    """Clean up old migration backups"""
    click.echo("ğŸ§¹ Backup cleanup is not implemented in the branch-aware preview.")
    click.echo("   Remove unwanted backup files manually if needed.")
    sys.exit(0)

# v2.6.1 Backup ì„œë¸Œëª…ë ¹ì–´ë“¤
@backup.command()
@click.option('--output', '-o', required=True, help='ë°±ì—… íŒŒì¼ ì €ì¥ ê²½ë¡œ')
@click.option('--include-metadata/--no-metadata', default=True, help='ì‹œìŠ¤í…œ ë©”íƒ€ë°ì´í„° í¬í•¨ ì—¬ë¶€')
def export(output: str, include_metadata: bool):
    """ì „ì²´ ë©”ëª¨ë¦¬ë¥¼ ë°±ì—… íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
    try:
        from ..core.backup_restore import MemoryBackupEngine
        # from ..core.hierarchical_memory import HierarchicalMemorySystem  # REMOVED: File deleted
        from ..core.database_manager import DatabaseManager
        from pathlib import Path
        
        click.echo("[PROCESS] ë©”ëª¨ë¦¬ ë°±ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        # ê³„ì¸µì  ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” - SIMPLIFIED
        db_manager = DatabaseManager()
        # HierarchicalMemorySystem removed - using DatabaseManager directly
        
        backup_engine = MemoryBackupEngine(db_manager)
        success = backup_engine.create_backup(output, include_metadata)
        
        if success:
            click.echo(f"âœ… ë°±ì—… ì™„ë£Œ: {output}")
            backup_path = Path(output)
            if backup_path.exists():
                size_mb = backup_path.stat().st_size / (1024 * 1024)
                click.echo(f"ğŸ“ íŒŒì¼ í¬ê¸°: {size_mb:.2f} MB")
        else:
            click.echo("[ERROR] ë°±ì—… ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
            
    except Exception as e:
        click.echo(f"ğŸ’¥ ë°±ì—… ì¤‘ ì˜¤ë¥˜: {e}")


@backup.command()
@click.option('--schedule', type=click.Choice(['hourly', 'daily', 'weekly', 'monthly']), 
              required=True, help='ë°±ì—… ì£¼ê¸° ì„¤ì •')
@click.option('--output-dir', '-d', help='ë°±ì—… ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: ~/greeum-backups)')
@click.option('--max-backups', type=int, default=10, help='ë³´ì¡´í•  ìµœëŒ€ ë°±ì—… ìˆ˜ (ê¸°ë³¸: 10ê°œ)')
@click.option('--enable/--disable', default=True, help='ìë™ ë°±ì—… í™œì„±í™”/ë¹„í™œì„±í™”')
def auto(schedule: str, output_dir: str, max_backups: int, enable: bool):
    """ìë™ ë°±ì—… ìŠ¤ì¼€ì¤„ ì„¤ì • ë° ê´€ë¦¬
    
    Examples:
        greeum backup auto --schedule daily --output-dir ~/backups
        greeum backup auto --schedule weekly --max-backups 5
        greeum backup auto --schedule daily --disable
    """
    try:
        from pathlib import Path
        import json
        import os
        
        if not output_dir:
            output_dir = str(Path.home() / "greeum-backups")
        
        # ë°±ì—… ë””ë ‰í† ë¦¬ ìƒì„±
        backup_path = Path(output_dir)
        backup_path.mkdir(parents=True, exist_ok=True)
        
        # ìë™ ë°±ì—… ì„¤ì • íŒŒì¼ ê²½ë¡œ
        config_file = backup_path / "auto_backup_config.json"
        
        if enable:
            # ìë™ ë°±ì—… í™œì„±í™”
            from datetime import datetime
            
            config = {
                "enabled": True,
                "schedule": schedule,
                "output_dir": str(backup_path),
                "max_backups": max_backups,
                "last_backup": None,
                "created_at": datetime.now().isoformat()
            }
            
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
            
            click.echo(f"âœ… ìë™ ë°±ì—… í™œì„±í™”ë¨")
            click.echo(f"   [DATE] ì£¼ê¸°: {schedule}")
            click.echo(f"   ğŸ“ ë””ë ‰í† ë¦¬: {output_dir}")
            click.echo(f"   ğŸ”¢ ìµœëŒ€ ë°±ì—… ìˆ˜: {max_backups}ê°œ")
            click.echo()
            click.echo("ğŸ’¡ ìë™ ë°±ì—… ì‹¤í–‰ ë°©ë²•:")
            
            if schedule == 'hourly':
                cron_expr = "0 * * * *"
            elif schedule == 'daily':
                cron_expr = "0 2 * * *"  # ìƒˆë²½ 2ì‹œ
            elif schedule == 'weekly':
                cron_expr = "0 2 * * 0"  # ì¼ìš”ì¼ ìƒˆë²½ 2ì‹œ
            else:  # monthly
                cron_expr = "0 2 1 * *"  # ë§¤ì›” 1ì¼ ìƒˆë²½ 2ì‹œ
            
            click.echo(f"   crontabì— ì¶”ê°€: {cron_expr} greeum backup run-auto")
            click.echo("   ë˜ëŠ” ì‹œìŠ¤í…œ ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ 'greeum backup run-auto' ì‹¤í–‰")
            
        else:
            # ìë™ ë°±ì—… ë¹„í™œì„±í™”
            if config_file.exists():
                config_file.unlink()
                click.echo("âœ… ìë™ ë°±ì—…ì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤")
            else:
                click.echo("â„¹ï¸  ìë™ ë°±ì—…ì´ ì´ë¯¸ ë¹„í™œì„±í™” ìƒíƒœì…ë‹ˆë‹¤")
                
    except Exception as e:
        click.echo(f"ğŸ’¥ ìë™ ë°±ì—… ì„¤ì • ì‹¤íŒ¨: {e}")


@backup.command()
def run_auto():
    """ìë™ ë°±ì—… ì‹¤í–‰ (ìŠ¤ì¼€ì¤„ëŸ¬ì—ì„œ í˜¸ì¶œ)
    
    ì´ ëª…ë ¹ì–´ëŠ” cronì´ë‚˜ ì‹œìŠ¤í…œ ìŠ¤ì¼€ì¤„ëŸ¬ì—ì„œ í˜¸ì¶œë©ë‹ˆë‹¤.
    """
    try:
        from pathlib import Path
        from datetime import datetime, timedelta
        import json
        import glob
        
        # ê¸°ë³¸ ë°±ì—… ë””ë ‰í† ë¦¬
        backup_dir = Path.home() / "greeum-backups"
        config_file = backup_dir / "auto_backup_config.json"
        
        if not config_file.exists():
            click.echo("âš ï¸  ìë™ ë°±ì—…ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'greeum backup auto' ëª…ë ¹ì–´ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”")
            return
        
        # ì„¤ì • ë¡œë“œ
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        if not config.get('enabled', False):
            click.echo("â„¹ï¸  ìë™ ë°±ì—…ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤")
            return
        
        schedule = config['schedule']
        max_backups = config.get('max_backups', 10)
        last_backup = config.get('last_backup')
        
        # ë§ˆì§€ë§‰ ë°±ì—… ì´í›„ ì¶©ë¶„í•œ ì‹œê°„ì´ ì§€ë‚¬ëŠ”ì§€ í™•ì¸
        now = datetime.now()
        should_backup = True
        
        if last_backup:
            last_backup_time = datetime.fromisoformat(last_backup)
            
            if schedule == 'hourly' and now - last_backup_time < timedelta(hours=1):
                should_backup = False
            elif schedule == 'daily' and now - last_backup_time < timedelta(days=1):
                should_backup = False
            elif schedule == 'weekly' and now - last_backup_time < timedelta(weeks=1):
                should_backup = False
            elif schedule == 'monthly' and now - last_backup_time < timedelta(days=30):
                should_backup = False
        
        if not should_backup:
            click.echo("â„¹ï¸  ì•„ì§ ë°±ì—… ì‹œê°„ì´ ì•„ë‹™ë‹ˆë‹¤")
            return
        
        # ë°±ì—… ì‹¤í–‰
        timestamp = now.strftime("%Y%m%d_%H%M%S")
        backup_filename = f"auto_backup_{timestamp}.json"
        backup_path = backup_dir / backup_filename
        
        click.echo(f"[PROCESS] ìë™ ë°±ì—… ì‹¤í–‰: {backup_filename}")
        
        # ë°±ì—… ì—”ì§„ ì´ˆê¸°í™” ë° ë°±ì—… ì‹¤í–‰
        from ..core.backup_restore import MemoryBackupEngine
        # from ..core.hierarchical_memory import HierarchicalMemorySystem  # REMOVED: File deleted
        from ..core.database_manager import DatabaseManager
        
        db_manager = DatabaseManager()
        
        backup_engine = MemoryBackupEngine(db_manager)
        success = backup_engine.create_backup(str(backup_path), include_metadata=True)
        
        if success:
            # ë°±ì—… ì„¤ì • ì—…ë°ì´íŠ¸
            config['last_backup'] = now.isoformat()
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
            
            # ì˜¤ë˜ëœ ë°±ì—… íŒŒì¼ ì •ë¦¬
            backup_pattern = str(backup_dir / "auto_backup_*.json")
            backup_files = sorted(glob.glob(backup_pattern), reverse=True)  # ìµœì‹ ë¶€í„°
            
            if len(backup_files) > max_backups:
                old_backups = backup_files[max_backups:]
                for old_backup in old_backups:
                    Path(old_backup).unlink()
                    click.echo(f"ğŸ—‘ï¸  ì˜¤ë˜ëœ ë°±ì—… ì‚­ì œ: {Path(old_backup).name}")
            
            file_size = backup_path.stat().st_size / (1024 * 1024)
            click.echo(f"âœ… ìë™ ë°±ì—… ì™„ë£Œ: {backup_filename} ({file_size:.2f} MB)")
            click.echo(f"ğŸ“Š ë³´ì¡´ëœ ë°±ì—… ìˆ˜: {min(len(backup_files), max_backups)}ê°œ")
            
        else:
            click.echo("[ERROR] ìë™ ë°±ì—… ì‹¤íŒ¨")
            
    except Exception as e:
        click.echo(f"ğŸ’¥ ìë™ ë°±ì—… ì‹¤í–‰ ì‹¤íŒ¨: {e}")


@backup.command()
def status():
    """ìë™ ë°±ì—… ìƒíƒœ í™•ì¸"""
    try:
        from pathlib import Path
        from datetime import datetime
        import json
        import glob
        
        backup_dir = Path.home() / "greeum-backups"
        config_file = backup_dir / "auto_backup_config.json"
        
        if not config_file.exists():
            click.echo("âšª ìë™ ë°±ì—…: ë¯¸ì„¤ì •")
            click.echo("ğŸ’¡ 'greeum backup auto --schedule daily' ë¡œ ì„¤ì •í•˜ì„¸ìš”")
            return
        
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        status_emoji = "ğŸŸ¢" if config.get('enabled', False) else "ğŸ”´"
        status_text = "í™œì„±í™”" if config.get('enabled', False) else "ë¹„í™œì„±í™”"
        
        click.echo(f"{status_emoji} ìë™ ë°±ì—…: {status_text}")
        
        if config.get('enabled', False):
            click.echo(f"   [DATE] ì£¼ê¸°: {config.get('schedule', 'unknown')}")
            click.echo(f"   ğŸ“ ë””ë ‰í† ë¦¬: {config.get('output_dir', 'unknown')}")
            click.echo(f"   ğŸ”¢ ìµœëŒ€ ë³´ì¡´: {config.get('max_backups', 10)}ê°œ")
            
            last_backup = config.get('last_backup')
            if last_backup:
                click.echo(f"   ğŸ•’ ë§ˆì§€ë§‰ ë°±ì—…: {last_backup}")
            else:
                click.echo(f"   ğŸ•’ ë§ˆì§€ë§‰ ë°±ì—…: ì—†ìŒ")
        
        # ë°±ì—… íŒŒì¼ ëª©ë¡
        backup_pattern = str(backup_dir / "auto_backup_*.json")
        backup_files = sorted(glob.glob(backup_pattern), reverse=True)
        
        if backup_files:
            click.echo(f"\nğŸ“‹ ë°±ì—… íŒŒì¼ ({len(backup_files)}ê°œ):")
            for backup_file in backup_files[:5]:  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
                backup_path = Path(backup_file)
                size_mb = backup_path.stat().st_size / (1024 * 1024)
                mtime = datetime.fromtimestamp(backup_path.stat().st_mtime)
                click.echo(f"   â€¢ {backup_path.name} ({size_mb:.2f} MB, {mtime.strftime('%Y-%m-%d %H:%M')})")
            
            if len(backup_files) > 5:
                click.echo(f"   ... ë° {len(backup_files) - 5}ê°œ ë”")
        else:
            click.echo("\nğŸ“‹ ë°±ì—… íŒŒì¼: ì—†ìŒ")
            
    except Exception as e:
        click.echo(f"ğŸ’¥ ìë™ ë°±ì—… ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")


# v2.6.1 Restore ì„œë¸Œëª…ë ¹ì–´ë“¤
@restore.command()
@click.argument('backup_file', type=click.Path(exists=True))
@click.option('--from-date', help='ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)')
@click.option('--to-date', help='ë ë‚ ì§œ (YYYY-MM-DD)')  
@click.option('--keywords', help='í‚¤ì›Œë“œ í•„í„° (ì‰¼í‘œë¡œ êµ¬ë¶„)')
@click.option('--layers', help='ê³„ì¸µ í•„í„° (working,stm,ltm ì¤‘ ì„ íƒ)')
@click.option('--importance-min', type=float, help='ìµœì†Œ ì¤‘ìš”ë„ (0.0-1.0)')
@click.option('--importance-max', type=float, help='ìµœëŒ€ ì¤‘ìš”ë„ (0.0-1.0)')
@click.option('--tags', help='íƒœê·¸ í•„í„° (ì‰¼í‘œë¡œ êµ¬ë¶„)')
@click.option('--merge/--replace', default=False, help='ë³‘í•© ëª¨ë“œ (ê¸°ë³¸: êµì²´)')
@click.option('--preview/--execute', default=True, help='ë¯¸ë¦¬ë³´ê¸°ë§Œ í‘œì‹œ (ê¸°ë³¸: ë¯¸ë¦¬ë³´ê¸°)')
def from_file(
    backup_file: str,
    from_date: str,
    to_date: str, 
    keywords: str,
    layers: str,
    importance_min: float,
    importance_max: float,
    tags: str,
    merge: bool,
    preview: bool
):
    """ë°±ì—… íŒŒì¼ë¡œë¶€í„° ë©”ëª¨ë¦¬ ë³µì›"""
    try:
        from ..core.backup_restore import MemoryRestoreEngine, RestoreFilter
        # from ..core.hierarchical_memory import HierarchicalMemorySystem  # REMOVED
        from ..core.database_manager import DatabaseManager
        # from ..core.memory_layer import MemoryLayerType  # REMOVED
        from datetime import datetime
        
        # ë³µì› í•„í„° ìƒì„±
        date_from = None
        if from_date:
            try:
                date_from = datetime.strptime(from_date, '%Y-%m-%d')
            except ValueError:
                click.echo(f"âš ï¸ ì˜ëª»ëœ ì‹œì‘ ë‚ ì§œ í˜•ì‹: {from_date}")
        
        date_to = None
        if to_date:
            try:
                date_to = datetime.strptime(to_date, '%Y-%m-%d') 
            except ValueError:
                click.echo(f"âš ï¸ ì˜ëª»ëœ ë ë‚ ì§œ í˜•ì‹: {to_date}")
        
        keyword_list = None
        if keywords:
            keyword_list = [kw.strip() for kw in keywords.split(',') if kw.strip()]
        
        layer_list = None
        if layers:
            # Simplified layer mapping without MemoryLayerType enum
            layer_names = [layer.strip().lower() for layer in layers.split(',')]
            layer_list = layer_names  # Just pass as strings
        
        tag_list = None
        if tags:
            tag_list = [tag.strip() for tag in tags.split(',') if tag.strip()]
        
        filter_config = RestoreFilter(
            date_from=date_from,
            date_to=date_to,
            keywords=keyword_list,
            layers=layer_list,
            importance_min=importance_min,
            importance_max=importance_max,
            tags=tag_list
        )
        
        # ê³„ì¸µì  ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” - SIMPLIFIED
        db_manager = DatabaseManager()
        # HierarchicalMemorySystem removed - using DatabaseManager directly
        
        restore_engine = MemoryRestoreEngine(system)
        
        if preview:
            # ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ
            click.echo("ğŸ” ë³µì› ë¯¸ë¦¬ë³´ê¸°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
            preview_text = restore_engine.preview_restore(backup_file, filter_config)
            click.echo(preview_text)
            
            if click.confirm('ë³µì›ì„ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?'):
                preview = False  # ì‹¤ì œ ë³µì›ìœ¼ë¡œ ì „í™˜
            else:
                click.echo("ë³µì›ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤")
                return
        
        if not preview:
            # ì‹¤ì œ ë³µì› ì‹¤í–‰
            click.echo("[PROCESS] ë©”ëª¨ë¦¬ ë³µì›ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            
            result = restore_engine.restore_from_backup(
                backup_file=backup_file,
                filter_config=filter_config,
                merge_mode=merge,
                dry_run=False
            )
            
            # ê²°ê³¼ í‘œì‹œ
            if result.success:
                click.echo("âœ… ë³µì› ì™„ë£Œ!")
                click.echo(f"ğŸ“Š ë³µì› ê²°ê³¼:")
                click.echo(f"   [MEMORY] Working Memory: {result.working_count}ê°œ")
                click.echo(f"   [FAST] STM: {result.stm_count}ê°œ") 
                click.echo(f"   ğŸ›ï¸  LTM: {result.ltm_count}ê°œ")
                click.echo(f"   [IMPROVE] ì´ ì²˜ë¦¬: {result.total_processed}ê°œ")
                click.echo(f"   â±ï¸  ì†Œìš” ì‹œê°„: {result.execution_time:.2f}ì´ˆ")
                
                if result.error_count > 0:
                    click.echo(f"   âš ï¸  ì˜¤ë¥˜: {result.error_count}ê°œ")
                    for error in result.errors[:5]:  # ìµœëŒ€ 5ê°œ ì˜¤ë¥˜ë§Œ í‘œì‹œ
                        click.echo(f"      - {error}")
            else:
                click.echo("[ERROR] ë³µì›ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
                for error in result.errors:
                    click.echo(f"   ğŸ’¥ {error}")
                    
    except Exception as e:
        click.echo(f"ğŸ’¥ ë³µì› ì¤‘ ì˜¤ë¥˜: {e}")


# v2.6.2 Dashboard ì„œë¸Œëª…ë ¹ì–´ë“¤
@dashboard.command()
@click.option('--output', '-o', help='ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•  ê²½ë¡œ')
@click.option('--json-format', is_flag=True, help='JSON í˜•íƒœë¡œ ì¶œë ¥')
def overview(output: str, json_format: bool):
    """ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ì „ì²´ ê°œìš” í‘œì‹œ"""
    try:
        from ..core.dashboard import get_dashboard_system
        import json
        
        dashboard_system = get_dashboard_system()
        overview_data = dashboard_system.get_overview()
        
        if json_format or output:
            # JSON í˜•íƒœë¡œ ì¶œë ¥
            json_output = json.dumps(overview_data, indent=2, ensure_ascii=False)
            
            if output:
                with open(output, 'w', encoding='utf-8') as f:
                    f.write(json_output)
                click.echo(f"âœ… ëŒ€ì‹œë³´ë“œ ë¦¬í¬íŠ¸ ì €ì¥ë¨: {output}")
            else:
                click.echo(json_output)
        else:
            # ì‚¬ìš©ì ì¹œí™”ì  í˜•íƒœë¡œ ì¶œë ¥
            _display_dashboard_overview(overview_data)
            
    except Exception as e:
        click.echo(f"ğŸ’¥ ëŒ€ì‹œë³´ë“œ ê°œìš” ìƒì„± ì‹¤íŒ¨: {e}")


@dashboard.command()
@click.option('--format', 'output_format', type=click.Choice(['simple', 'detailed', 'json']), 
              default='simple', help='ì¶œë ¥ í˜•íƒœ')
def health(output_format: str):
    """ì‹œìŠ¤í…œ ê±´ê°•ë„ í™•ì¸"""
    try:
        from ..core.dashboard import get_dashboard_system
        import json
        
        dashboard_system = get_dashboard_system()
        health_data = dashboard_system.get_system_health()
        
        if output_format == 'json':
            click.echo(json.dumps(health_data.__dict__, indent=2, ensure_ascii=False, default=str))
        elif output_format == 'detailed':
            _display_health_detailed(health_data)
        else:
            _display_health_simple(health_data)
            
    except Exception as e:
        click.echo(f"ğŸ’¥ ì‹œìŠ¤í…œ ê±´ê°•ë„ í™•ì¸ ì‹¤íŒ¨: {e}")


@dashboard.command()
@click.option('--output', '-o', required=True, help='ë¦¬í¬íŠ¸ íŒŒì¼ ì €ì¥ ê²½ë¡œ')
@click.option('--include-details/--no-details', default=True, 
              help='ìƒì„¸ ê³„ì¸µ ë¶„ì„ í¬í•¨ ì—¬ë¶€')
def export(output: str, include_details: bool):
    """ì™„ì „í•œ ëŒ€ì‹œë³´ë“œ ë¦¬í¬íŠ¸ ë‚´ë³´ë‚´ê¸°"""
    try:
        from ..core.dashboard import get_dashboard_system
        from pathlib import Path
        
        dashboard_system = get_dashboard_system()
        
        success = dashboard_system.export_dashboard_report(
            output_path=output,
            include_details=include_details
        )
        
        if success:
            file_size = Path(output).stat().st_size / 1024  # KB
            click.echo(f"âœ… ëŒ€ì‹œë³´ë“œ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {output} ({file_size:.1f} KB)")
            
            if include_details:
                click.echo("ğŸ“Š ìƒì„¸ ê³„ì¸µ ë¶„ì„ í¬í•¨")
            else:
                click.echo("ğŸ“‹ ê¸°ë³¸ ê°œìš”ë§Œ í¬í•¨")
        else:
            click.echo("[ERROR] ë¦¬í¬íŠ¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")
            
    except Exception as e:
        click.echo(f"ğŸ’¥ ë¦¬í¬íŠ¸ ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {e}")


# ëŒ€ì‹œë³´ë“œ ì¶œë ¥ í—¬í¼ í•¨ìˆ˜ë“¤
def _display_dashboard_overview(data: dict):
    """ì‚¬ìš©ì ì¹œí™”ì  ëŒ€ì‹œë³´ë“œ ê°œìš” ì¶œë ¥"""
    stats = data['memory_stats']
    health = data['system_health']
    
    click.echo("[MEMORY] Greeum Memory Dashboard")
    click.echo("=" * 50)
    
    # ê¸°ë³¸ í†µê³„
    click.echo(f"ğŸ“Š ì „ì²´ ë©”ëª¨ë¦¬: {stats['total_memories']}ê°œ")
    click.echo(f"   [MEMORY] Working Memory: {stats['working_memory_count']}ê°œ")
    click.echo(f"   [FAST] STM: {stats['stm_count']}ê°œ")
    click.echo(f"   ğŸ›ï¸  LTM: {stats['ltm_count']}ê°œ")
    
    click.echo()
    
    # ì‹œìŠ¤í…œ ê±´ê°•ë„
    health_percent = health['overall_health'] * 100
    health_emoji = "ğŸŸ¢" if health_percent >= 80 else "ğŸŸ¡" if health_percent >= 60 else "ğŸ”´"
    click.echo(f"{health_emoji} ì‹œìŠ¤í…œ ê±´ê°•ë„: {health_percent:.1f}%")
    
    # ìš©ëŸ‰ ì •ë³´
    click.echo(f"ğŸ’¾ ì´ ìš©ëŸ‰: {stats['total_size_mb']:.1f} MB")
    click.echo(f"[FAST] í‰ê·  ê²€ìƒ‰ ì‹œê°„: {health['avg_search_time_ms']:.1f}ms")
    
    # ê²½ê³ ì‚¬í•­
    if health['warnings']:
        click.echo("\nâš ï¸  ì£¼ì˜ì‚¬í•­:")
        for warning in health['warnings']:
            click.echo(f"   â€¢ {warning}")
    
    # ê¶Œì¥ì‚¬í•­
    if health['recommendations']:
        click.echo("\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
        for rec in health['recommendations']:
            click.echo(f"   â€¢ {rec}")
    
    # ì¸ê¸° í‚¤ì›Œë“œ
    if 'popular_keywords' in stats:
        click.echo("\nğŸ”¥ ì¸ê¸° í‚¤ì›Œë“œ:")
        for keyword, count in stats['popular_keywords'][:5]:
            click.echo(f"   #{keyword} ({count}íšŒ)")


def _display_health_simple(health):
    """ê°„ë‹¨í•œ ê±´ê°•ë„ ì¶œë ¥"""
    health_percent = health.overall_health * 100
    health_emoji = "ğŸŸ¢" if health_percent >= 80 else "ğŸŸ¡" if health_percent >= 60 else "ğŸ”´"
    
    click.echo(f"{health_emoji} ì‹œìŠ¤í…œ ê±´ê°•ë„: {health_percent:.1f}%")
    
    if health_percent >= 80:
        click.echo("âœ… ì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤")
    elif health_percent >= 60:
        click.echo("âš ï¸  ì‹œìŠ¤í…œì— ì•½ê°„ì˜ ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤")
    else:
        click.echo("ğŸ”´ ì‹œìŠ¤í…œ ì ê²€ì´ í•„ìš”í•©ë‹ˆë‹¤")


def _display_health_detailed(health):
    """ìƒì„¸í•œ ê±´ê°•ë„ ì¶œë ¥"""
    _display_health_simple(health)
    
    click.echo(f"\n[IMPROVE] ì„±ëŠ¥ ì§€í‘œ:")
    click.echo(f"   ê²€ìƒ‰ ì†ë„: {health.avg_search_time_ms:.1f}ms")
    click.echo(f"   ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {health.memory_usage_mb:.1f}MB")
    click.echo(f"   ë°ì´í„°ë² ì´ìŠ¤ í¬ê¸°: {health.database_size_mb:.1f}MB")
    
    click.echo(f"\nğŸ¯ í’ˆì§ˆ ì§€í‘œ:")
    click.echo(f"   í‰ê·  í’ˆì§ˆ ì ìˆ˜: {health.avg_quality_score:.2f}")
    click.echo(f"   ì¤‘ë³µë¥ : {health.duplicate_rate * 100:.1f}%")
    click.echo(f"   ìŠ¹ê¸‰ ì„±ê³µë¥ : {health.promotion_success_rate * 100:.1f}%")
    
    if health.warnings:
        click.echo(f"\nâš ï¸  ê²½ê³ :")
        for warning in health.warnings:
            click.echo(f"   â€¢ {warning}")
    
    if health.recommendations:
        click.echo(f"\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
        for rec in health.recommendations:
            click.echo(f"   â€¢ {rec}")


# v2.7.0: Causal Reasoning Commands
@main.group()
def causal():
    """Causal reasoning and relationship analysis commands"""
    pass


@causal.command()
@click.argument('block_id', type=int)
@click.option('--format', 'output_format', type=click.Choice(['simple', 'detailed', 'json']), 
              default='simple', help='Output format')
def relationships(block_id: int, output_format: str):
    """Show causal relationships for a specific memory block"""
    try:
        from greeum.core import DatabaseManager
        from greeum.core.block_manager import BlockManager
        
        db_manager = DatabaseManager()
        block_manager = BlockManager(db_manager)
        
        # Get the block info
        block = db_manager.get_block(block_id)
        if not block:
            click.echo(f"âŒ Block #{block_id} not found", err=True)
            return
        
        # Get causal relationships
        relationships = block_manager.get_causal_relationships(block_id)
        
        if output_format == 'json':
            import json
            click.echo(json.dumps({
                'block_id': block_id,
                'relationships': relationships
            }, indent=2, ensure_ascii=False))
            return
        
        if not relationships:
            click.echo(f"ğŸ” No causal relationships found for block #{block_id}")
            return
        
        click.echo(f"ğŸ”— Causal relationships for block #{block_id}:")
        click.echo(f"   Context: {block['context'][:60]}...")
        click.echo()
        
        for i, rel in enumerate(relationships, 1):
            source_id = rel['source_block_id']
            target_id = rel['target_block_id']
            relation_type = rel['relation_type']
            confidence = rel['confidence']
            
            # Determine direction
            if source_id == block_id:
                direction = "â†’"
                other_id = target_id
                role = "Causes"
            else:
                direction = "â†"
                other_id = source_id
                role = "Caused by"
            
            # Get other block context
            other_block = db_manager.get_block(other_id)
            other_context = other_block['context'][:50] + "..." if other_block else "Unknown"
            
            confidence_emoji = "ğŸ”¥" if confidence >= 0.8 else "âš¡" if confidence >= 0.6 else "ğŸ’¡"
            
            click.echo(f"{i}. {confidence_emoji} {role} Block #{other_id} ({confidence:.2f})")
            click.echo(f"   {direction} {other_context}")
            click.echo(f"   Type: {relation_type}")
            
            if output_format == 'detailed':
                import json
                keywords = json.loads(rel.get('keywords_matched', '[]'))
                if keywords:
                    click.echo(f"   Keywords: {', '.join(keywords)}")
                
                temporal_gap = rel.get('temporal_gap_hours')
                if temporal_gap is not None:
                    if temporal_gap < 1:
                        gap_str = f"{temporal_gap * 60:.0f} minutes"
                    elif temporal_gap < 24:
                        gap_str = f"{temporal_gap:.1f} hours"
                    else:
                        gap_str = f"{temporal_gap / 24:.1f} days"
                    click.echo(f"   Time gap: {gap_str}")
            
            click.echo()
        
    except Exception as e:
        click.echo(f"âŒ Error analyzing relationships: {e}", err=True)


@causal.command()
@click.argument('start_block_id', type=int)
@click.option('--depth', default=3, help='Maximum chain depth to explore')
@click.option('--format', 'output_format', type=click.Choice(['simple', 'detailed', 'json']), 
              default='simple', help='Output format')
def chain(start_block_id: int, depth: int, output_format: str):
    """Find causal relationship chains starting from a block"""
    try:
        from greeum.core import DatabaseManager
        from greeum.core.block_manager import BlockManager
        
        db_manager = DatabaseManager()
        block_manager = BlockManager(db_manager)
        
        # Get the starting block
        start_block = db_manager.get_block(start_block_id)
        if not start_block:
            click.echo(f"âŒ Start block #{start_block_id} not found", err=True)
            return
        
        # Find causal chain
        chain_results = block_manager.find_causal_chain(start_block_id, depth)
        
        if output_format == 'json':
            import json
            click.echo(json.dumps({
                'start_block_id': start_block_id,
                'chain': chain_results
            }, indent=2, ensure_ascii=False))
            return
        
        if not chain_results:
            click.echo(f"ğŸ” No causal chains found starting from block #{start_block_id}")
            return
        
        click.echo(f"ğŸ”— Causal chain starting from block #{start_block_id}:")
        click.echo(f"   Start: {start_block['context'][:60]}...")
        click.echo()
        
        # Group by depth for better visualization
        by_depth = {}
        for item in chain_results:
            d = item['depth']
            if d not in by_depth:
                by_depth[d] = []
            by_depth[d].append(item)
        
        for depth_level in sorted(by_depth.keys()):
            items = by_depth[depth_level]
            indent = "  " * (depth_level + 1)
            
            for item in items:
                confidence = item['confidence']
                target_block = item['target_block']
                target_context = target_block['context'][:50] + "..."
                
                confidence_emoji = "ğŸ”¥" if confidence >= 0.8 else "âš¡" if confidence >= 0.6 else "ğŸ’¡"
                
                click.echo(f"{indent}â†“ {confidence_emoji} Block #{item['target_id']} ({confidence:.2f})")
                click.echo(f"{indent}   {target_context}")
                
                if output_format == 'detailed':
                    click.echo(f"{indent}   Type: {item['relation_type']}")
        
    except Exception as e:
        click.echo(f"âŒ Error finding causal chain: {e}", err=True)


@causal.command()
@click.option('--format', 'output_format', type=click.Choice(['simple', 'detailed', 'json']), 
              default='simple', help='Output format')
def stats(output_format: str):
    """Show causal reasoning detection statistics"""
    try:
        from greeum.core import DatabaseManager
        from greeum.core.block_manager import BlockManager
        
        db_manager = DatabaseManager()
        block_manager = BlockManager(db_manager)
        
        # Get statistics
        statistics = block_manager.get_causal_statistics()
        
        if 'error' in statistics:
            click.echo(f"âŒ {statistics['error']}", err=True)
            return
        
        if output_format == 'json':
            import json
            click.echo(json.dumps(statistics, indent=2, ensure_ascii=False))
            return
        
        click.echo("ğŸ“Š Causal Reasoning Statistics")
        click.echo("=" * 35)
        
        # Detection summary
        total_analyzed = statistics.get('total_analyzed', 0)
        relationships_found = statistics.get('relationships_found', 0)
        accuracy_estimate = statistics.get('accuracy_estimate', 0.0)
        
        click.echo(f"\nğŸ” Detection Summary:")
        click.echo(f"   Total blocks analyzed: {total_analyzed}")
        click.echo(f"   Relationships found: {relationships_found}")
        if total_analyzed > 0:
            detection_rate = (relationships_found / total_analyzed) * 100
            click.echo(f"   Detection rate: {detection_rate:.1f}%")
        click.echo(f"   Estimated accuracy: {accuracy_estimate:.1f}%")
        
        # Confidence distribution
        high_conf = statistics.get('high_confidence', 0)
        medium_conf = statistics.get('medium_confidence', 0)
        low_conf = statistics.get('low_confidence', 0)
        
        click.echo(f"\nğŸ“ˆ Confidence Distribution:")
        click.echo(f"   ğŸ”¥ High (â‰¥0.8): {high_conf}")
        click.echo(f"   âš¡ Medium (0.5-0.8): {medium_conf}")
        click.echo(f"   ğŸ’¡ Low (<0.5): {low_conf}")
        
        # Relationship types
        by_type = statistics.get('by_type', {})
        if by_type:
            click.echo(f"\nğŸ·ï¸  Relationship Types:")
            for rel_type, count in by_type.items():
                if count > 0:
                    click.echo(f"   {rel_type}: {count}")
        
        # Database statistics
        total_stored = statistics.get('total_stored', 0)
        stored_dist = statistics.get('stored_confidence_distribution', {})
        
        if output_format == 'detailed':
            click.echo(f"\nğŸ’¾ Storage Statistics:")
            click.echo(f"   Total stored relationships: {total_stored}")
            
            if stored_dist:
                click.echo(f"   Stored confidence distribution:")
                for level, count in stored_dist.items():
                    click.echo(f"     {level}: {count}")
        
    except Exception as e:
        click.echo(f"âŒ Error getting causal statistics: {e}", err=True)


# Import and register metrics commands
try:
    from .metrics_cli import metrics_group
    # Replace the empty metrics group with the real one
    main.commands.pop('metrics', None)
    main.add_command(metrics_group, name='metrics')
except ImportError:
    pass  # Metrics CLI not available

# Import and register validate commands  
try:
    from .validate_cli import validate_group
    # Replace the empty validate group with the real one
    main.commands.pop('validate', None)
    main.add_command(validate_group, name='validate')
except ImportError:
    pass  # Validate CLI not available


if __name__ == '__main__':
    main()
