#!/usr/bin/env python3
"""
End-to-End Context Preservation System Tests

v2.6.4 Context Preservation Systemì˜ ì „ì²´ ì‚¬ì´í´ì„ 
ì‹¤ì œ í™˜ê²½ê³¼ ìœ ì‚¬í•œ ì¡°ê±´ì—ì„œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.

Author: Greeum Development Team
Version: 2.6.4
"""

import os
import sys
import time
import tempfile
import unittest
import threading
from datetime import datetime, timedelta
from pathlib import Path
from unittest.mock import patch, MagicMock
import json

# Greeum ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

from greeum.core.database_manager import DatabaseManager
from greeum.core.raw_data_backup_layer import RawDataBackupLayer
from greeum.core.precompact_hook import PreCompactHookHandler, PreCompactEvent
from greeum.core.context_recovery import ContextRecoveryManager
from greeum.core.intelligent_context_processor import IntelligentContextProcessor
from greeum.core.context_backup import ContextBackupItem, ContextType
from greeum.core.claude_code_detector import ClaudeCodeDetector


class ContextPreservationE2ETest(unittest.TestCase):
    """
    ì „ì²´ Context Preservation ì‚¬ì´í´ End-to-End í…ŒìŠ¤íŠ¸
    
    ì‹¤ì œ Claude Code í™˜ê²½ì—ì„œì˜ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•˜ì—¬
    PreCompact Hook â†’ Backup â†’ Recovery â†’ Processing ì „ì²´ íë¦„ì„ ê²€ì¦í•©ë‹ˆë‹¤.
    """
    
    def setUp(self):
        """í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì •"""
        # ì„ì‹œ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
        self.test_db = tempfile.NamedTemporaryFile(suffix='.db', delete=False)
        self.test_db_path = self.test_db.name
        self.test_db.close()
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„°
        self.test_session_id = "test_session_e2e_001"
        
        # í•µì‹¬ ì»´í¬ë„ŒíŠ¸ë“¤ ì´ˆê¸°í™”
        self.db_manager = DatabaseManager(self.test_db_path)
        self.backup_layer = RawDataBackupLayer(self.db_manager)
        self.backup_layer.initialize()  # í…Œì´ë¸” ìƒì„±ì„ ìœ„í•œ ì´ˆê¸°í™”
        self.precompact_hook = PreCompactHookHandler(self.backup_layer, self.test_session_id)
        self.recovery_manager = ContextRecoveryManager(self.backup_layer)
        self.context_processor = IntelligentContextProcessor()
        self.test_contexts = [
            "ì‚¬ìš©ìê°€ ìƒˆë¡œìš´ í”„ë¡œì íŠ¸ ì‹œì‘ì„ ìš”ì²­í–ˆìŠµë‹ˆë‹¤.",
            "class ProjectManager:\n    def __init__(self):\n        self.status = 'active'",
            "í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ê²°ê³¼: ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µí–ˆìŠµë‹ˆë‹¤.",
            "ì˜¤ë¥˜ ë°œìƒ: FileNotFoundError in project_setup.py line 42",
            "í”„ë¡œì íŠ¸ ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•´ì£¼ì„¸ìš”."
        ]
        
    def tearDown(self):
        """í…ŒìŠ¤íŠ¸ ì •ë¦¬"""
        try:
            # Hook í•´ì œ
            if self.precompact_hook.is_active:
                self.precompact_hook.unregister_hook()
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            os.unlink(self.test_db_path)
        except Exception:
            pass
    
    def test_full_cycle_with_claude_code_simulation(self):
        """ì™„ì „í•œ Context Preservation ì‚¬ì´í´ í…ŒìŠ¤íŠ¸ (Claude Code í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜)"""
        print("\nğŸ”„ Full Cycle Test: Claude Code Environment Simulation")
        
        # 1. Claude Code í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜
        with patch.dict(os.environ, {
            'CLAUDECODE': '1',
            'CLAUDE_CODE_ENTRYPOINT': 'cli',
            'CLAUDE_SESSION_ID': self.test_session_id
        }):
            
            # 2. PreCompact Hook ë“±ë¡
            self.assertTrue(self.precompact_hook.register_hook())
            self.assertTrue(self.precompact_hook.is_active)
            print("âœ… PreCompact Hook ë“±ë¡ ì„±ê³µ")
            
            # 3. ì»¨í…ìŠ¤íŠ¸ ë°ì´í„° ë°±ì—… ì‹œë®¬ë ˆì´ì…˜
            backup_ids = []
            for i, context in enumerate(self.test_contexts):
                backup_item = ContextBackupItem(
                    raw_content=context,
                    context_type=ContextType.USER_MESSAGE if "ì‚¬ìš©ì" in context else ContextType.TOOL_RESULT,
                    session_id=self.test_session_id,
                    timestamp=datetime.now() + timedelta(seconds=i),
                    auto_compact_risk_score=0.8,
                    original_length=len(context),
                    recovery_metadata={
                        "test_sequence": i,
                        "e2e_test": True
                    }
                )
                
                backup_id = self.backup_layer.backup_context_immediately(
                    content=backup_item.raw_content,
                    context_type=backup_item.context_type,
                    session_id=backup_item.session_id
                )
                backup_ids.append(backup_id)
                time.sleep(0.1)  # ì‹œê°„ ì°¨ì´ ìƒì„±
            
            print(f"âœ… {len(backup_ids)} ê°œ ì»¨í…ìŠ¤íŠ¸ ë°±ì—… ì™„ë£Œ")
            
            # 4. PreCompact ì´ë²¤íŠ¸ ì‹œë®¬ë ˆì´ì…˜
            precompact_event_data = {
                'length': 15000,
                'trigger_type': 'auto_compact',
                'urgency': 0.9,
                'preview': 'Large context about to be compacted...'
            }
            
            self.precompact_hook.handle_precompact_signal(precompact_event_data)
            print("âœ… PreCompact ì´ë²¤íŠ¸ ì²˜ë¦¬ ì™„ë£Œ")
            
            # 5. ì»¨í…ìŠ¤íŠ¸ ë³µì› í…ŒìŠ¤íŠ¸
            time.sleep(0.2)  # ë°±ì—… ì™„ë£Œ ëŒ€ê¸°
            recovery_result = self.recovery_manager.recover_session_context(self.test_session_id)
            
            self.assertTrue(recovery_result['success'])
            self.assertGreater(recovery_result['quality_score'], 0.5)
            self.assertGreater(len(recovery_result['recovered_context']), 0)
            print(f"âœ… ì»¨í…ìŠ¤íŠ¸ ë³µì› ì™„ë£Œ (í’ˆì§ˆ: {recovery_result['quality_score']:.2f})")
            
            # 6. ì§€ëŠ¥í˜• ì»¨í…ìŠ¤íŠ¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
            recovered_context = recovery_result['recovered_context']
            processed_contexts = self.context_processor.optimize_context_flow([recovered_context])
            
            self.assertGreater(len(processed_contexts), 0)
            
            # ì¤‘ìš”ë„ ë¶„ì„
            importance_scores = [
                self.context_processor.analyze_context_importance(ctx)
                for ctx in self.test_contexts
            ]
            avg_importance = sum(importance_scores) / len(importance_scores)
            self.assertGreater(avg_importance, 0.3)
            print(f"âœ… ì§€ëŠ¥í˜• ì²˜ë¦¬ ì™„ë£Œ (í‰ê·  ì¤‘ìš”ë„: {avg_importance:.2f})")
            
            # 7. ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœ ê²€ì¦
            hook_status = self.precompact_hook.get_hook_status()
            processing_stats = self.context_processor.get_processing_statistics()
            
            self.assertEqual(hook_status['session_id'], self.test_session_id)
            self.assertTrue(hook_status['claude_code_detected'])
            print("âœ… ì‹œìŠ¤í…œ ìƒíƒœ ê²€ì¦ ì™„ë£Œ")
            
        print("ğŸ‰ Full Cycle Test ì„±ê³µ!")
    
    def test_emergency_backup_recovery_scenario(self):
        """ê¸´ê¸‰ ë°±ì—… ë° ë³µì› ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸"""
        print("\nğŸš¨ Emergency Backup Recovery Test")
        
        # Claude Code í™˜ê²½ ì„¤ì •
        with patch.dict(os.environ, {'CLAUDECODE': '1', 'CLAUDE_CODE_ENTRYPOINT': 'cli'}):
            
            # Hook ë“±ë¡
            self.precompact_hook.register_hook()
            
            # ê¸´ê¸‰ ìƒí™© ì‹œë®¬ë ˆì´ì…˜ (ë†’ì€ ìœ„í—˜ë„ ë°ì´í„°)
            emergency_data = {
                'critical_context': self.test_contexts,
                'session_state': {'active_task': 'project_setup', 'progress': 0.7},
                'user_intent': 'implement new feature with error handling',
                'timestamp': datetime.now().isoformat()
            }
            
            # ê¸´ê¸‰ ë°±ì—… ìˆ˜í–‰
            backup_id = self.precompact_hook.emergency_backup(emergency_data)
            self.assertIsNotNone(backup_id)
            self.assertNotIn('error', backup_id)
            print(f"âœ… ê¸´ê¸‰ ë°±ì—… ì™„ë£Œ: {backup_id}")
            
            # ë³µì› í…ŒìŠ¤íŠ¸
            time.sleep(0.1)
            recovery_result = self.recovery_manager.recover_session_context(self.precompact_hook.session_id)
            
            self.assertTrue(recovery_result['success'])
            self.assertIn('critical_context', recovery_result['recovered_context'])
            print("âœ… ê¸´ê¸‰ ë³µì› ì„±ê³µ")
            
            # ë³µì›ëœ ë°ì´í„° í’ˆì§ˆ ê²€ì¦
            quality_score = recovery_result['quality_score']
            self.assertGreater(quality_score, 0.6)  # ê¸´ê¸‰ ë°±ì—…ì€ ë†’ì€ í’ˆì§ˆ ê¸°ëŒ€
            print(f"âœ… ë³µì› í’ˆì§ˆ ê²€ì¦: {quality_score:.2f}")
    
    def test_multi_session_context_continuity(self):
        """ë‹¤ì¤‘ ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ì—°ì†ì„± í…ŒìŠ¤íŠ¸"""
        print("\nğŸ”— Multi-Session Continuity Test")
        
        # ì²« ë²ˆì§¸ ì„¸ì…˜
        session1_id = "test_session_001"
        session1_contexts = self.test_contexts[:3]
        
        for context in session1_contexts:
            backup_item = ContextBackupItem(
                raw_content=context,
                context_type=ContextType.CONVERSATION_TURN,
                session_id=session1_id,
                timestamp=datetime.now(),
                auto_compact_risk_score=0.6,
                original_length=len(context),
                recovery_metadata={"session": 1}
            )
            self.backup_layer.backup_context_immediately(
                content=backup_item.raw_content,
                context_type=backup_item.context_type,
                session_id=backup_item.session_id
            )
        
        print("âœ… ì„¸ì…˜ 1 ë°±ì—… ì™„ë£Œ")
        
        # ë‘ ë²ˆì§¸ ì„¸ì…˜
        session2_id = "test_session_002"
        session2_contexts = self.test_contexts[3:]
        
        for context in session2_contexts:
            backup_item = ContextBackupItem(
                raw_content=context,
                context_type=ContextType.CONVERSATION_TURN, 
                session_id=session2_id,
                timestamp=datetime.now() + timedelta(minutes=5),
                auto_compact_risk_score=0.7,
                original_length=len(context),
                recovery_metadata={"session": 2}
            )
            self.backup_layer.backup_context_immediately(
                content=backup_item.raw_content,
                context_type=backup_item.context_type,
                session_id=backup_item.session_id
            )
        
        print("âœ… ì„¸ì…˜ 2 ë°±ì—… ì™„ë£Œ")
        
        # ê° ì„¸ì…˜ ë³µì› í…ŒìŠ¤íŠ¸
        recovery1 = self.recovery_manager.recover_session_context(session1_id)
        recovery2 = self.recovery_manager.recover_session_context(session2_id)
        
        self.assertTrue(recovery1['success'])
        self.assertTrue(recovery2['success'])
        print("âœ… ë‘ ì„¸ì…˜ ëª¨ë‘ ë³µì› ì„±ê³µ")
        
        # ì»¨í…ìŠ¤íŠ¸ ë³‘í•© í…ŒìŠ¤íŠ¸
        merged_context = self.recovery_manager.smart_context_merge(
            recovery1['recovered_context'],
            recovery2['recovered_context']
        )
        
        self.assertGreater(len(merged_context), 0)
        self.assertIn("ì‚¬ìš©ìê°€ ìƒˆë¡œìš´", merged_context)  # ì„¸ì…˜ 1 ë‚´ìš©
        self.assertIn("ì˜¤ë¥˜ ë°œìƒ", merged_context)       # ì„¸ì…˜ 2 ë‚´ìš©
        print("âœ… ì»¨í…ìŠ¤íŠ¸ ë³‘í•© ì„±ê³µ")
    
    def test_context_processing_performance(self):
        """ì»¨í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print("\nâš¡ Context Processing Performance Test")
        
        # ëŒ€ëŸ‰ ì»¨í…ìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        large_contexts = []
        for i in range(50):
            context = f"í…ŒìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸ #{i}: ì´ê²ƒì€ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ì…ë‹ˆë‹¤. " * 10
            large_contexts.append(context)
        
        # ì¤‘ìš”ë„ ë¶„ì„ ì„±ëŠ¥ ì¸¡ì •
        start_time = time.time()
        importance_scores = [
            self.context_processor.analyze_context_importance(ctx)
            for ctx in large_contexts
        ]
        analysis_time = time.time() - start_time
        
        print(f"âœ… ì¤‘ìš”ë„ ë¶„ì„: {len(large_contexts)}ê°œ ì»¨í…ìŠ¤íŠ¸, {analysis_time:.2f}ì´ˆ")
        self.assertLess(analysis_time, 5.0)  # 5ì´ˆ ì´ë‚´
        
        # ì••ì¶• ì„±ëŠ¥ ì¸¡ì •
        start_time = time.time()
        compressed = self.context_processor.compress_redundant_context(large_contexts)
        compression_time = time.time() - start_time
        
        print(f"âœ… ì••ì¶• ì²˜ë¦¬: {compression_time:.2f}ì´ˆ")
        self.assertLess(compression_time, 3.0)  # 3ì´ˆ ì´ë‚´
        
        # ì••ì¶• íš¨ìœ¨ì„± ê²€ì¦
        original_size = sum(len(ctx) for ctx in large_contexts)
        compressed_size = len(compressed)
        compression_ratio = compressed_size / original_size
        
        print(f"âœ… ì••ì¶•ë¥ : {compression_ratio:.1%}")
        self.assertLess(compression_ratio, 0.8)  # 80% ì´í•˜ë¡œ ì••ì¶•
    
    def test_error_handling_and_recovery(self):
        """ì˜¤ë¥˜ ì²˜ë¦¬ ë° ë³µêµ¬ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ›¡ï¸  Error Handling and Recovery Test")
        
        # ì˜ëª»ëœ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
        invalid_contexts = [
            None,
            "",
            "A" * 100000,  # ë„ˆë¬´ ê¸´ ì»¨í…ìŠ¤íŠ¸
            "\x00\x01\x02",  # ë°”ì´ë„ˆë¦¬ ë°ì´í„°
            "ğŸ‰" * 1000  # ì´ëª¨ì§€ ëŒ€ëŸ‰
        ]
        
        # ê° ì˜ëª»ëœ ë°ì´í„°ì— ëŒ€í•œ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
        for i, invalid_context in enumerate(invalid_contexts):
            try:
                if invalid_context is not None:
                    importance = self.context_processor.analyze_context_importance(invalid_context)
                    self.assertIsInstance(importance, float)
                    self.assertGreaterEqual(importance, 0.0)
                    self.assertLessEqual(importance, 1.0)
                    print(f"âœ… ì˜ëª»ëœ ë°ì´í„° {i+1} ì²˜ë¦¬ ì„±ê³µ")
                else:
                    # None ë°ì´í„°ëŠ” 0.0 ë°˜í™˜ ê¸°ëŒ€
                    importance = self.context_processor.analyze_context_importance(invalid_context)
                    self.assertEqual(importance, 0.0)
                    print(f"âœ… None ë°ì´í„° ì²˜ë¦¬ ì„±ê³µ")
            except Exception as e:
                print(f"âš ï¸ ì˜ëª»ëœ ë°ì´í„° {i+1} ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸: {e}")
                # ì˜ˆì™¸ê°€ ë°œìƒí•´ë„ ì‹œìŠ¤í…œì´ ë‹¤ìš´ë˜ì§€ ì•Šìœ¼ë©´ ì„±ê³µ
                self.assertIsInstance(e, Exception)
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜ ì‹œë®¬ë ˆì´ì…˜
        with patch.object(self.backup_layer, 'backup_context_immediately', 
                         side_effect=Exception("DB Connection Error")):
            
            # Hookì´ ì˜¤ë¥˜ë¥¼ ì²˜ë¦¬í•˜ê³  ê³„ì† ì‘ë™í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸
            try:
                test_data = {"test": "error simulation"}
                result = self.precompact_hook.emergency_backup(test_data)
                self.assertIn("error_", result)  # ì˜¤ë¥˜ ID ìƒì„± í™•ì¸
                print("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜ ì²˜ë¦¬ ì„±ê³µ")
            except Exception:
                print("âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜ ì²˜ë¦¬ ì‹¤íŒ¨")
    
    def test_concurrent_operations(self):
        """ë™ì‹œ ì‘ì—… ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        print("\nğŸ§µ Concurrent Operations Test")
        
        # ë™ì‹œ ë°±ì—… ì‘ì—… í…ŒìŠ¤íŠ¸
        def backup_worker(worker_id):
            """ë°±ì—… ì›Œì»¤ í•¨ìˆ˜"""
            for i in range(10):
                backup_item = ContextBackupItem(
                    raw_content=f"ì›Œì»¤ {worker_id} ì»¨í…ìŠ¤íŠ¸ #{i}",
                    context_type=ContextType.SYSTEM_STATE,
                    session_id=f"concurrent_session_{worker_id}",
                    timestamp=datetime.now(),
                    auto_compact_risk_score=0.5,
                    original_length=50,
                    recovery_metadata={"worker": worker_id, "item": i}
                )
                
                try:
                    backup_id = self.backup_layer.backup_context_immediately(
                    content=backup_item.raw_content,
                    context_type=backup_item.context_type,
                    session_id=backup_item.session_id
                )
                    self.assertIsNotNone(backup_id)
                except Exception as e:
                    print(f"ì›Œì»¤ {worker_id} ë°±ì—… ì˜¤ë¥˜: {e}")
        
        # 3ê°œ ì›Œì»¤ë¡œ ë™ì‹œ ì‘ì—…
        threads = []
        for worker_id in range(3):
            thread = threading.Thread(target=backup_worker, args=(worker_id,))
            threads.append(thread)
            thread.start()
        
        # ëª¨ë“  ìŠ¤ë ˆë“œ ì™„ë£Œ ëŒ€ê¸°
        for thread in threads:
            thread.join(timeout=5.0)
        
        print("âœ… ë™ì‹œ ë°±ì—… ì‘ì—… ì™„ë£Œ")
        
        # ë™ì‹œ ë³µì› ì‘ì—… í…ŒìŠ¤íŠ¸
        recovery_threads = []
        recovery_results = {}
        
        def recovery_worker(session_id):
            """ë³µì› ì›Œì»¤ í•¨ìˆ˜"""
            try:
                result = self.recovery_manager.recover_session_context(f"concurrent_session_{session_id}")
                recovery_results[session_id] = result
            except Exception as e:
                print(f"ë³µì› ì›Œì»¤ {session_id} ì˜¤ë¥˜: {e}")
                recovery_results[session_id] = {"success": False, "error": str(e)}
        
        for session_id in range(3):
            thread = threading.Thread(target=recovery_worker, args=(session_id,))
            recovery_threads.append(thread)
            thread.start()
        
        for thread in recovery_threads:
            thread.join(timeout=5.0)
        
        print(f"âœ… ë™ì‹œ ë³µì› ì‘ì—… ì™„ë£Œ: {len(recovery_results)} ê²°ê³¼")
    
    def test_system_integration_health_check(self):
        """ì‹œìŠ¤í…œ í†µí•© ìƒíƒœ ê²€ì‚¬"""
        print("\nğŸ¥ System Integration Health Check")
        
        # ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ìƒíƒœ í™•ì¸
        self.assertIsNotNone(self.db_manager)
        self.assertIsNotNone(self.backup_layer)
        self.assertIsNotNone(self.precompact_hook)
        self.assertIsNotNone(self.recovery_manager)
        self.assertIsNotNone(self.context_processor)
        print("âœ… ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # ì»´í¬ë„ŒíŠ¸ ê°„ ìƒí˜¸ì‘ìš© í…ŒìŠ¤íŠ¸
        with patch.dict(os.environ, {'CLAUDECODE': '1'}):
            # Hook ë“±ë¡
            hook_success = self.precompact_hook.register_hook()
            self.assertTrue(hook_success)
            
            # ë°±ì—… ê³„ì¸µ ì‘ë™ í™•ì¸
            test_backup = ContextBackupItem(
                raw_content="ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ í…ŒìŠ¤íŠ¸",
                context_type=ContextType.SYSTEM_STATE,
                session_id="health_check_session",
                timestamp=datetime.now(),
                auto_compact_risk_score=0.5,
                original_length=20,
                recovery_metadata={"health_check": True}
            )
            
            backup_id = self.backup_layer.backup_context_immediately(
                content=test_backup.raw_content,
                context_type=test_backup.context_type,
                session_id=test_backup.session_id
            )
            self.assertIsNotNone(backup_id)
            print("âœ… ë°±ì—… ê³„ì¸µ ì‘ë™ í™•ì¸")
            
            # ë³µì› ê´€ë¦¬ì ì‘ë™ í™•ì¸
            time.sleep(0.1)
            recovery = self.recovery_manager.recover_session_context("health_check_session")
            self.assertTrue(recovery['success'])
            print("âœ… ë³µì› ê´€ë¦¬ì ì‘ë™ í™•ì¸")
            
            # í”„ë¡œì„¸ì„œ ì‘ë™ í™•ì¸
            processed = self.context_processor.analyze_context_importance("í…ŒìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸")
            self.assertIsInstance(processed, float)
            print("âœ… ì»¨í…ìŠ¤íŠ¸ í”„ë¡œì„¸ì„œ ì‘ë™ í™•ì¸")
            
        # ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ í™•ì¸
        processing_stats = self.context_processor.get_processing_statistics()
        self.assertIsInstance(processing_stats, dict)
        print(f"âœ… ì²˜ë¦¬ í†µê³„ í™•ì¸: {processing_stats}")
        
        print("ğŸ‰ ì‹œìŠ¤í…œ ìƒíƒœ ê²€ì‚¬ ì™„ë£Œ!")


def run_e2e_tests():
    """E2E í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸš€ Context Preservation System E2E í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    # í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ìƒì„±
    test_suite = unittest.TestLoader().loadTestsFromTestCase(ContextPreservationE2ETest)
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("ğŸ“Š E2E í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print(f"ì´ í…ŒìŠ¤íŠ¸: {result.testsRun}")
    print(f"ì„±ê³µ: {result.testsRun - len(result.failures) - len(result.errors)}")
    print(f"ì‹¤íŒ¨: {len(result.failures)}")
    print(f"ì˜¤ë¥˜: {len(result.errors)}")
    
    if result.failures:
        print("\nâŒ ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸:")
        for test, traceback in result.failures:
            print(f"  - {test}: {traceback}")
    
    if result.errors:
        print("\nâš ï¸ ì˜¤ë¥˜ê°€ ë°œìƒí•œ í…ŒìŠ¤íŠ¸:")
        for test, traceback in result.errors:
            print(f"  - {test}: {traceback}")
    
    success_rate = (result.testsRun - len(result.failures) - len(result.errors)) / result.testsRun * 100
    print(f"\nğŸ¯ ì„±ê³µë¥ : {success_rate:.1f}%")
    
    return result.wasSuccessful()


if __name__ == "__main__":
    # E2E í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    success = run_e2e_tests()
    
    if success:
        print("\nğŸ‰ ëª¨ë“  E2E í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µí–ˆìŠµë‹ˆë‹¤!")
        sys.exit(0)
    else:
        print("\nğŸ’¥ ì¼ë¶€ E2E í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        sys.exit(1)