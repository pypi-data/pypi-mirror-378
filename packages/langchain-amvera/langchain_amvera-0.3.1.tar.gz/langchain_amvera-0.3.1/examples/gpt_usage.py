"""
–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPT –º–æ–¥–µ–ª–µ–π —á–µ—Ä–µ–∑ Amvera API.
"""

import asyncio
from langchain_amvera import AmveraLLM
from langchain_core.messages import HumanMessage, SystemMessage


async def main():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã —Å GPT –º–æ–¥–µ–ª—è–º–∏."""
    
    print("ü§ñ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ GPT –º–æ–¥–µ–ª–µ–π Amvera API\n")
    
    # –°–ø–∏—Å–æ–∫ GPT –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    gpt_models = ["gpt-4.1", "gpt-5"]
    
    for model_name in gpt_models:
        print(f"üìã –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏: {model_name}")
        print("-" * 50)
        
        try:
            # –°–æ–∑–¥–∞–Ω–∏–µ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –º–æ–¥–µ–ª–∏
            llm = AmveraLLM(
                model=model_name,
                temperature=0.7,
                max_tokens=200,
                verbose=True
            )
            
            # –°–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            messages = [
                SystemMessage(content="–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π AI-–ø–æ–º–æ—â–Ω–∏–∫."),
                HumanMessage(content="–†–∞—Å—Å–∫–∞–∂–∏ –∫—Ä–∞—Ç–∫–∏–π —Ñ–∞–∫—Ç –æ –∫–æ—Å–º–æ—Å–µ")
            ]
            
            print(f"\nüöÄ –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ {model_name}...")
            
            # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤
            result = await llm.ainvoke(messages)
            
            print(f"\n‚úÖ –û—Ç–≤–µ—Ç –æ—Ç {model_name}:")
            print(f"{result.content}\n")
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤
            usage = llm.get_token_usage(result)
            if usage:
                print(f"üìä –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤: {usage}")
            
            # –í–µ—Ä—Å–∏—è –º–æ–¥–µ–ª–∏
            version = llm.get_model_version(result)
            if version:
                print(f"üì¶ –í–µ—Ä—Å–∏—è –º–æ–¥–µ–ª–∏: {version}")
                
            # –ó–∞–∫—Ä—ã—Ç–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
            await llm.aclose()
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å {model_name}: {e}")
        
        print("\n" + "="*60 + "\n")


def sync_example():
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPT –º–æ–¥–µ–ª–∏."""
    print("üîÑ –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø—Ä–∏–º–µ—Ä —Å GPT-4.1")
    
    try:
        llm = AmveraLLM(
            model="gpt-4.1",
            temperature=0.5,
            max_tokens=150
        )
        
        messages = [
            HumanMessage(content="–ß—Ç–æ —Ç–∞–∫–æ–µ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç? –û—Ç–≤–µ—Ç—å –∫—Ä–∞—Ç–∫–æ.")
        ]
        
        result = llm.invoke(messages)
        print(f"–û—Ç–≤–µ—Ç: {result.content}")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")


if __name__ == "__main__":
    print("üåü –ó–∞–ø—É—Å–∫ –ø—Ä–∏–º–µ—Ä–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPT –º–æ–¥–µ–ª–µ–π\n")
    
    # –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø—Ä–∏–º–µ—Ä
    sync_example()
    print("\n" + "-"*60 + "\n")
    
    # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã
    asyncio.run(main())
    
    print("‚ú® –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")