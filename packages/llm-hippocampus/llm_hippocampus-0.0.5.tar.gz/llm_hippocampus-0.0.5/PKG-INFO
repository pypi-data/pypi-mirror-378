Metadata-Version: 2.4
Name: llm-hippocampus
Version: 0.0.5
Summary: LLM Hippocampus â€” a Context Engineering playground
Home-page: 
Author: joelz
Author-email: joelz <zhongbj_2621@163.com>
Project-URL: Repository, https://github.com/redis-developer/redis-rag-workbench.git
Project-URL: Bug Tracker, https://github.com/redis-developer/redis-rag-workbench/issues
Keywords: python,redis,langchain,openai
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Programming Language :: Python
Requires-Python: >=3.11
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: openai>=1.63.0
Requires-Dist: python-dotenv>=1.0.0
Requires-Dist: langchain>=0.3.19
Requires-Dist: tiktoken>=0.9.0
Requires-Dist: redis>=5.2.1
Requires-Dist: langchain-community>=0.3.18
Requires-Dist: langchain-huggingface>=0.1.2
Requires-Dist: langchain-openai>=0.3.6
Requires-Dist: langchain-experimental>=0.3.4
Requires-Dist: python-ulid>=2.7.0
Requires-Dist: pandas==2.2.3
Requires-Dist: hf-xet>=1.1.8
Requires-Dist: redisvl>=0.8.2
Requires-Dist: sentence-transformers>=5.1.0
Requires-Dist: langchain-redis>=0.2.3
Provides-Extra: dev
Requires-Dist: mypy<2.0.0,>=1.8.0; extra == "dev"
Requires-Dist: ruff<1.0.0,>=0.2.2; extra == "dev"
Dynamic: author
Dynamic: license-file
Dynamic: requires-python

<div align="center">
<h1>ğŸš€ LLM Hippocampus</h1>

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
![Language](https://img.shields.io/github/languages/top/redis-developer/redis-rag-workbench)
![GitHub last commit](https://img.shields.io/github/last-commit/redis-developer/redis-rag-workbench)
![Python](https://img.shields.io/badge/python-3.11%2B-blue)

ğŸ¯ Build up and manage the LLM 's memory

</div>

ğŸ”¥ **LLM Hippocampus** helping your project for building and experimenting with **Context Engineering** applications. harness the full power of Redis for **lightning-fast vector search**, **intelligent semantic caching**, **persistent LLM memory**, and **smart context engineering **.

âœ¨ **What makes this special?**
- ğŸš€ **One-command setup** - pip install llm-hippocampus
- âš¡  **LLM support** - OpenAI
- ğŸ¯ **Redis-powered** - Vector search, caching, and memory management
- ğŸ³ **Docker ready** - Building... 
- ğŸ”§ **Developer-first** - Support to Hot load by installing llm-hippocampus

---

## Table of Contents

- [Quick Start](#quick-start)
- [Prerequisites](#prerequisites)
- [Getting Started](#getting-started)
  - [Available Commands](#available-commands)
  - [Development Workflows](#development-workflows)
  - [Environment Configuration](#environment-configuration)
- [Using Google VertexAI](#using-google-vertexai)
- [Project Structure](#project-structure)
- [Connecting to Redis Cloud](#connecting-to-redis-cloud)
- [Troubleshooting](#troubleshooting)
- [Contributing](#contributing)
- [License](#license)
- [Learn More](#learn-more)


## Quick Start

**Get up and install in your project:**

```bash
pip install llm-hippocampus
or
uv add llm-hippocampus
```

Welcome to LLM Hippocampus! ğŸ‰

---

## Prerequisites

1. Make sure you have the following tools available:
   - [python](https://www.docker.com/products/docker-desktop/) 3.11+
   - [uv](https://docs.astral.sh/uv/)
   - [Redis Stack](https://redis.io/)
2. Setup one or more of the following:
   - [OpenAI API](https://platform.openai.com/)
     - You will need an API Key

## Getting Started
```python
from dotenv import load_dotenv
from llm_hippocampus import env
from llm_hippocampus.core.utils import list2np_array
from llm_hippocampus.core.redis import create_search_index, client, load_data2search_index, vector_query
from llm_hippocampus.session import Session
load_dotenv()
# Load the model
session = Session()
embeddings = session.get_embedding_model()
schema = {
    "index": {
        "name": "data_agent_chain",
        "prefix": "data_agent_chain",
    },
    "fields": [
        {"name": "query", "type": "text"},
        {"name": "scope", "type": "text"},
        {"name": "intent", "type": "text"},
        {
            "name": "query_embedding",
            "type": "vector",
            "attrs": {
                "dims": 768,
                "distance_metric": "cosine",
                "algorithm": "flat",
                "datatype": "float32"
            }
        }
    ]
}

data = [
    {
        'query': 'SAAJ91çš„ç®¡ç†è´¹ç‡å’Œæ‰˜ç®¡è´¹ç‡æ˜¯å¤šå°‘ï¼Ÿ',
        'scope': "äº§å“åŸºæœ¬ä¿¡æ¯",
        'intent': 'ç®¡ç†è´¹ç‡ã€æ‰˜ç®¡è´¹ç‡',
        'query_embedding': list2np_array(embeddings.encode(
            "SAAJ91çš„ç®¡ç†è´¹ç‡å’Œæ‰˜ç®¡è´¹ç‡æ˜¯å¤šå°‘ï¼Ÿ",
            precision=schema["fields"][3]["attrs"]["datatype"],
            truncate_dim=schema["fields"][3]["attrs"]["dims"])).tobytes()
    },
    {
        'query': 'SATP77åœ¨äº2025å¹´06æœˆ01æ—¥è‡³2025å¹´06æœˆ30æ—¥çš„è‚¡ç¥¨æŒä»“æ˜ç»†',
        'scope': "è‚¡ç¥¨æŒä»“ä¿¡æ¯",
        'intent': 'è‚¡ç¥¨æŒä»“ä¿¡æ¯',
        'query_embedding': list2np_array(embeddings.encode(
            "SATP77åœ¨äº2025å¹´06æœˆ01æ—¥è‡³2025å¹´06æœˆ30æ—¥çš„è‚¡ç¥¨æŒä»“æ˜ç»†",
            precision=schema["fields"][3]["attrs"]["datatype"],
            truncate_dim=schema["fields"][3]["attrs"]["dims"])).tobytes()
    },
    {
        'query': 'æˆªè‡³äº2025å¹´01æœˆ01æ—¥è‡³2025å¹´12æœˆ31æ—¥ï¼Œ001120çš„æˆ·å‡å®šæŠ•é‡‘é¢ï¼Ÿ',
        'scope': "å®¢æˆ·å®šæŠ•æƒ…å†µ",
        'intent': 'å®¢æˆ·å®šæŠ•æƒ…å†µ',
        'query_embedding': list2np_array(embeddings.encode(
            "æˆªè‡³äº2025å¹´01æœˆ01æ—¥è‡³2025å¹´12æœˆ31æ—¥ï¼Œ001120çš„æˆ·å‡å®šæŠ•é‡‘é¢",
            precision=schema["fields"][3]["attrs"]["datatype"],
            truncate_dim=schema["fields"][3]["attrs"]["dims"])).tobytes()
    }
]

redis_client = client(env.REDIS_URL)
index = create_search_index(redis_client, schema)
keys = load_data2search_index(index, data)

query = "400001çš„ç®¡ç†è´¹ç‡"
args = {
    "distance_threshold": session.distance_threshold,
    "top_k": session.top_k,
    "vector_field_name": "query_embedding",
    "precision": schema["fields"][3]["attrs"]["datatype"],
    "truncate_dim": schema["fields"][3]["attrs"]["dims"],
    "return_fileds": ["query", "scope", "intent"],
}

results = vector_query(query, index, embeddings, schema, **args)
```

### Development Workflows
- Building


## Project Structure


## Contributing

ğŸ¤ Contributions are welcome! Please feel free to submit a Pull Request.

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Troubleshooting

## Learn More
