# ArgLogger

ä¸€ä¸ªç”¨äºè®°å½•æœºå™¨å­¦ä¹ å®éªŒçš„ Python åŒ…ï¼Œå¯ä»¥æ ¹æ® argparse é…ç½®è‡ªåŠ¨åˆ›å»ºæ•°æ®åº“è¡¨æˆ– CSV æ–‡ä»¶ï¼Œæ–¹ä¾¿ä¿å­˜å’Œç®¡ç†å®éªŒç»“æœã€‚

## ç‰¹æ€§

- ğŸš€ **è‡ªåŠ¨åŒ–**: ä» argparse é…ç½®è‡ªåŠ¨ç”Ÿæˆè¡¨ç»“æ„
- ğŸ’¾ **å¤šåç«¯æ”¯æŒ**: æ”¯æŒ SQLite æ•°æ®åº“å’Œ CSV æ–‡ä»¶å­˜å‚¨
- ğŸ”„ **çµæ´»æ“ä½œ**: æ”¯æŒå¢åˆ æ”¹æŸ¥æ“ä½œ
- â° **æ—¶é—´æˆ³**: è‡ªåŠ¨æ·»åŠ åˆ›å»ºå’Œæ›´æ–°æ—¶é—´
- ğŸ¯ **ç±»å‹æ¨æ–­**: æ™ºèƒ½æ¨æ–­æ•°æ®ç±»å‹
- ğŸ“Š **æ˜“äºç»Ÿè®¡**: ä¾¿äºåç»­çš„ç»“æœåˆ†æå’Œç»Ÿè®¡

## å®‰è£…

```bash
pip install arglogger
```

æˆ–è€…ä»æºç å®‰è£…ï¼š

```bash
git clone https://github.com/MinsGoing/arglogger.git
cd arglogger
pip install -e .
```

## å¿«é€Ÿå¼€å§‹

### åŸºæœ¬ç”¨æ³•

```python
import argparse
from arglogger import ArgLogger

# åˆ›å»º argparse parser
parser = argparse.ArgumentParser()
parser.add_argument('--learning_rate', type=float, default=0.001)
parser.add_argument('--batch_size', type=int, default=32)
parser.add_argument('--epochs', type=int, default=100)
parser.add_argument('--model', type=str, default='resnet50')

# è§£æå‚æ•°ï¼ˆè¿™é‡Œæ˜¯ç¤ºä¾‹å‚æ•°ï¼‰
args = parser.parse_args(['--learning_rate', '0.01', '--batch_size', '64'])

# åˆ›å»ºå®éªŒè®°å½•å™¨
logger = ArgLogger(
    experiment_name='my_experiment',
    backend='sqlite',  # æˆ–è€… 'csv'
    parser=parser  # æˆ–è€…ä¼ å…¥ args=args
)

# è®°å½•å®éªŒç»“æœ
logger.log_result({
    'learning_rate': args.learning_rate,
    'batch_size': args.batch_size,
    'epochs': args.epochs,
    'model': args.model,
    'accuracy': 0.95,
    'loss': 0.05
})

# è·å–æ‰€æœ‰ç»“æœ
results = logger.get_results()
print(results)

# å…³é—­è¿æ¥
logger.close()
```

### ä½¿ç”¨ CSV åç«¯

```python
from arglogger import ArgLogger

# ä½¿ç”¨ CSV æ–‡ä»¶å­˜å‚¨
logger = ArgLogger(
    experiment_name='csv_experiment',
    backend='csv',
    storage_path='experiments/results.csv',
    args=args
)

# è®°å½•ç»“æœ
logger.log_result({
    'accuracy': 0.92,
    'precision': 0.88,
    'recall': 0.90,
    'f1_score': 0.89
})
```

### å®Œæ•´çš„å®éªŒè„šæœ¬ç¤ºä¾‹

```python
import argparse
from arglogger import ArgLogger

def train_model(args):
    """æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹"""
    # è¿™é‡Œæ˜¯ä½ çš„è®­ç»ƒä»£ç 
    accuracy = 0.95  # å‡è®¾çš„ç»“æœ
    loss = 0.05
    return accuracy, loss

def main():
    # è®¾ç½®å‚æ•°
    parser = argparse.ArgumentParser(description='Machine Learning Experiment')
    parser.add_argument('--learning_rate', type=float, default=0.001)
    parser.add_argument('--batch_size', type=int, default=32)
    parser.add_argument('--epochs', type=int, default=100)
    parser.add_argument('--model', type=str, default='resnet50')
    parser.add_argument('--optimizer', type=str, default='adam')
    parser.add_argument('--dataset', type=str, default='cifar10')
    
    args = parser.parse_args()
    
    # åˆ›å»ºå®éªŒè®°å½•å™¨
    logger = ArgLogger(
        experiment_name='ml_experiments',
        backend='sqlite',
        storage_path='experiments.db',
        args=args
    )
    
    # è®­ç»ƒæ¨¡å‹
    accuracy, loss = train_model(args)
    
    # è®°å½•ç»“æœ
    logger.log_result({
        'learning_rate': args.learning_rate,
        'batch_size': args.batch_size,
        'epochs': args.epochs,
        'model': args.model,
        'optimizer': args.optimizer,
        'dataset': args.dataset,
        'accuracy': accuracy,
        'loss': loss,
        'notes': f'Experiment with {args.model} on {args.dataset}'
    })
    
    print(f'Experiment logged: Accuracy={accuracy:.4f}, Loss={loss:.4f}')
    
    # æŸ¥çœ‹å†å²ç»“æœ
    results = logger.get_results(limit=5)
    print(f'\\nLast 5 experiments:')
    for result in results:
        print(f'ID: {result["id"]}, Model: {result["model"]}, Accuracy: {result["accuracy"]:.4f}')
    
    logger.close()

if __name__ == '__main__':
    main()
```

## é«˜çº§åŠŸèƒ½

### æ›´æ–°å’Œåˆ é™¤ç»“æœ

```python
# æ›´æ–°ç»“æœ
logger.update_result(
    condition={'id': 1},  # æ¡ä»¶
    updates={'accuracy': 0.96, 'notes': 'Updated accuracy'}  # æ›´æ–°å†…å®¹
)

# åˆ é™¤ç»“æœ
logger.delete_results(condition={'id': 1})
```

### åŠ¨æ€æ·»åŠ åˆ—

```python
# æ·»åŠ æ–°åˆ—
logger.add_column('validation_accuracy', 'REAL')

# è®°å½•åŒ…å«æ–°åˆ—çš„ç»“æœ
logger.log_result({
    'accuracy': 0.95,
    'validation_accuracy': 0.92
})
```

### æŸ¥çœ‹è¡¨ç»“æ„

```python
# è·å–å½“å‰è¡¨ç»“æ„
schema = logger.get_schema()
print(schema)
```

## API æ–‡æ¡£

### ArgLogger ç±»

#### æ„é€ å‡½æ•°

```python
ArgLogger(
    experiment_name: str,
    backend: str = 'sqlite',
    storage_path: Optional[str] = None,
    parser: Optional[argparse.ArgumentParser] = None,
    args: Optional[argparse.Namespace] = None,
    auto_timestamp: bool = True
)
```

**å‚æ•°:**
- `experiment_name`: å®éªŒåç§°ï¼ˆç”¨ä½œè¡¨åæˆ–æ–‡ä»¶åï¼‰
- `backend`: å­˜å‚¨åç«¯ï¼Œ'sqlite' æˆ– 'csv'
- `storage_path`: å­˜å‚¨è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨å®éªŒåç§°ï¼‰
- `parser`: ArgumentParser å®ä¾‹ï¼ˆç”¨äºè‡ªåŠ¨æå–è¡¨ç»“æ„ï¼‰
- `args`: è§£æåçš„å‚æ•°å¯¹è±¡ï¼ˆç”¨äºè‡ªåŠ¨æå–è¡¨ç»“æ„ï¼‰
- `auto_timestamp`: æ˜¯å¦è‡ªåŠ¨æ·»åŠ æ—¶é—´æˆ³åˆ—

#### ä¸»è¦æ–¹æ³•

- `log_result(results: Dict[str, Any], **kwargs)`: è®°å½•å®éªŒç»“æœ
- `get_results(limit: Optional[int] = None)`: è·å–å®éªŒç»“æœ
- `update_result(condition: Dict[str, Any], updates: Dict[str, Any])`: æ›´æ–°ç»“æœ
- `delete_results(condition: Dict[str, Any])`: åˆ é™¤ç»“æœ
- `add_column(column_name: str, column_type: str)`: æ·»åŠ åˆ—
- `get_schema()`: è·å–å½“å‰è¡¨ç»“æ„
- `close()`: å…³é—­è¿æ¥

## æ”¯æŒçš„æ•°æ®ç±»å‹

- `INTEGER`: æ•´æ•°
- `REAL`: æµ®ç‚¹æ•°
- `TEXT`: å­—ç¬¦ä¸²
- `BOOLEAN`: å¸ƒå°”å€¼

å¤æ‚ç±»å‹ï¼ˆå¦‚åˆ—è¡¨ã€å­—å…¸ï¼‰ä¼šè‡ªåŠ¨åºåˆ—åŒ–ä¸º JSON å­—ç¬¦ä¸²å­˜å‚¨ã€‚

## ç¤ºä¾‹åœºæ™¯

### 1. æœºå™¨å­¦ä¹ æ¨¡å‹æ¯”è¾ƒ

```python
models = ['resnet50', 'vgg16', 'mobilenet']
learning_rates = [0.001, 0.01, 0.1]

for model in models:
    for lr in learning_rates:
        # è®­ç»ƒæ¨¡å‹
        accuracy = train_model(model, lr)
        
        # è®°å½•ç»“æœ
        logger.log_result({
            'model': model,
            'learning_rate': lr,
            'accuracy': accuracy
        })
```

### 2. è¶…å‚æ•°æœç´¢

```python
import itertools

# å®šä¹‰è¶…å‚æ•°ç©ºé—´
param_grid = {
    'batch_size': [16, 32, 64],
    'learning_rate': [0.001, 0.01],
    'dropout': [0.2, 0.5]
}

# ç½‘æ ¼æœç´¢
for params in itertools.product(*param_grid.values()):
    param_dict = dict(zip(param_grid.keys(), params))
    
    # è®­ç»ƒå’Œè¯„ä¼°
    results = train_and_evaluate(**param_dict)
    
    # è®°å½•ç»“æœ
    logger.log_result({**param_dict, **results})
```

## æ³¨æ„äº‹é¡¹

1. SQLite æ–‡ä»¶ä¼šè‡ªåŠ¨åˆ›å»ºï¼Œä½† CSV æ–‡ä»¶çš„ç›®å½•éœ€è¦å­˜åœ¨
2. è¡¨åå’Œåˆ—åä¼šè‡ªåŠ¨æ¸…ç†ï¼Œç§»é™¤ç‰¹æ®Šå­—ç¬¦
3. è‡ªåŠ¨æ—¶é—´æˆ³ä½¿ç”¨ ISO æ ¼å¼
4. CSV åç«¯ä¾èµ– pandasï¼Œç¡®ä¿å·²å®‰è£…

## è®¸å¯è¯

MIT License

## è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## æ›´æ–°æ—¥å¿—

### v0.1.0
- åˆå§‹ç‰ˆæœ¬
- æ”¯æŒ SQLite å’Œ CSV åç«¯
- è‡ªåŠ¨ä» argparse ç”Ÿæˆè¡¨ç»“æ„
- åŸºæœ¬çš„ CRUD æ“ä½œ