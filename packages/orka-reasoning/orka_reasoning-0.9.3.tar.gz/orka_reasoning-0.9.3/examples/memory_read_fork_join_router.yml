orchestrator:
  id: orka-ui
  strategy: parallel
  queue: orka:generated
  agents:
    - memory-read_0
    - openai-answer_2
    - fork_3
    - join_9
    - openai-binary_10
    - router_11
    - memory-write_final
agents:
  - id: memory-read_0
    type: memory
    memory_preset: "semantic"  # Facts and knowledge base (30 days)
    queue: orka:memory-read_0
    config:
      operation: read
      # ðŸŽ¯ Preset provides: limit=10, similarity_threshold=0.65, vector_weight=0.7,
      # text_weight=0.3, enable_hybrid_search=true, ef_runtime=15, etc.
      memory_category_filter: stored
      similarity_threshold: 0.75  # Override preset default of 0.65
    namespace: fact_validator
    prompt: Retrieve any stored memories about how the subject '{{ get_input() }}' was classified or understood in the past. Return "NONE" if nothing matches.
  - id: openai-answer_2
    type: local_llm
    model: gpt-oss:20b
    model_url: http://localhost:11434/api/generate
    provider: ollama
    temperature: 0.7
    queue: orka:openai-answer_2
    prompt: Given previous context {{ get_agent_response('memory-read_0') }}, provide an initial detailed answer to {{ get_input() }}. Be comprehensive and informative.
  - id: fork_3
    type: fork
    targets:
      - - openai-binary_4
        - openai-classification_5
        - openai-answer_6
      - - openai-answer_7
        - failover_11
    depends_on:
      - openai-answer_2
  - id: openai-binary_4
    type: local_llm
    model: gpt-oss:20b
    model_url: http://localhost:11434/api/generate
    provider: ollama
    temperature: 0.1
    queue: orka:openai-binary_4
    prompt: Does the question {{ get_input() }} require factual validation? Answer with exactly 'true' or 'false' only.
    depends_on:
      - fork_3
  - id: openai-answer_7
    type: local_llm
    model: gpt-oss:20b
    model_url: http://localhost:11434/api/generate
    provider: ollama
    temperature: 0.5
    queue: orka:openai-answer_7
    prompt: Provide a concise summary for the question {{ get_input() }}. Be clear and to the point.
    depends_on:
      - fork_3
  - id: openai-classification_5
    type: local_llm
    model: gpt-oss:20b
    model_url: http://localhost:11434/api/generate
    provider: ollama
    temperature: 0.2
    queue: orka:openai-classification_5
    prompt: | 
      Classify the domain of the question {{ get_input() }}. Choose exactly one from: science, history, technology, geography, culture, general. Answer with only the domain name.
    depends_on:
      - openai-binary_4
  - id: failover_11
    type: failover
    input: openai-answer_7
    children:
      - id: duckduckgo_12
        type: duckduckgo
        queue: orka:duckduckgo_12
        prompt: "{{ get_input() }}"
      - id: duckduckgo_13
        type: duckduckgo
        queue: orka:duckduckgo_13
        prompt: "{{ get_input() }}"
    depends_on:
      - openai-answer_7
      - duckduckgo_12
      - duckduckgo_13
  - id: openai-answer_6
    type: local_llm
    model: gpt-oss:20b
    model_url: http://localhost:11434/api/generate
    provider: ollama
    temperature: 0.8
    queue: orka:openai-answer_6
    prompt: "Provide an alternative perspective or deeper insight into the question {{ get_input() }} considering domain: {{ get_agent_response('openai-classification_5') }}. Be creative and thoughtful."
    depends_on:
      - openai-classification_5
  - id: join_9
    type: join
    group: fork_3
  - id: openai-binary_10
    type: local_llm
    model: gpt-oss:20b
    model_url: http://localhost:11434/api/generate
    provider: ollama
    temperature: 0.1
    queue: orka:openai-binary_10
    prompt: "Is the provided information coherent and complete based on outputs: {{ get_agent_response('join_9') }}? Answer with exactly 'true' or 'false' only."
    depends_on:
      - join_9
  - id: router_11
    type: router
    params:
      decision_key: openai-binary_10
      routing_map:
        "true":
          - openai-answer_14
          - memory-write_final
        "false":
          - openai-answer_15
          - memory-write_final
    depends_on:
      - openai-binary_10
  - id: openai-answer_14
    type: local_llm
    model: gpt-oss:20b
    model_url: http://localhost:11434/api/generate
    provider: ollama
    temperature: 0.6
    queue: orka:openai-answer_14
    prompt: Given confirmed coherent inputs {{ get_agent_response('join_9') }}, provide a polished final response to {{ get_input() }}. Be professional and comprehensive.
    depends_on:
      - router_11
  - id: openai-answer_15
    type: local_llm
    model: gpt-oss:20b
    model_url: http://localhost:11434/api/generate
    provider: ollama
    temperature: 0.7
    queue: orka:openai-answer_15
    prompt: "Given identified gaps in coherence or completeness in {{ get_agent_response('join_9') }}, clarify or complete the information to fully answer {{ get_input() }}. Fill in the missing pieces."
    depends_on:
      - router_11
  - id: memory-write_final
    type: memory
    memory_preset: "semantic"  # Facts and knowledge base (30 days)
    queue: orka:memory-write_final
    config:
      operation: write
      vector: true
      vector_field_name: "content_vector"
      force_recreate_index: false
    namespace: fact_validator
    prompt: "{{ safe_get_response('openai-answer_14', get_agent_response('openai-answer_15')) }}"
    metadata:
      source: '{{ "openai-answer_14" if get_agent_response("openai-answer_14") else "openai-answer_15" }}'
      result: "{{ safe_get_response('openai-answer_14', get_agent_response('openai-answer_15')) }}"
      category: stored
    key_template: "{{ get_input() }}"
