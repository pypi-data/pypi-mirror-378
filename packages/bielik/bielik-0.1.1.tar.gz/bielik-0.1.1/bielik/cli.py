#!/usr/bin/env python3
"""
bielik CLI - interactive chat shell using Ollama.
Tries REST API first, falls back to `ollama` library if available.
"""

import os
import sys
import requests

OLLAMA_HOST = os.environ.get("OLLAMA_HOST", "http://localhost:11434")
DEFAULT_MODEL = os.environ.get("BIELIK_MODEL", "bielik")
CHAT_ENDPOINT = OLLAMA_HOST.rstrip("/") + "/v1/chat/completions"

# try to import official ollama client
try:
    import ollama
    HAVE_OLLAMA = True
except ImportError:
    HAVE_OLLAMA = False


def send_chat(messages, model=DEFAULT_MODEL):
    """Send chat messages to Ollama via REST API or ollama lib fallback."""
    payload = {"model": model, "messages": messages, "stream": False}

    # try REST first
    try:
        resp = requests.post(CHAT_ENDPOINT, json=payload, timeout=30)
        resp.raise_for_status()
        data = resp.json()
        choice = data.get("choices", [{}])[0]
        msg = choice.get("message", {}).get("content")
        if msg:
            return msg
    except Exception as e:
        print(f"[REST API failed: {e}]")

    # fallback: official ollama library
    if HAVE_OLLAMA:
        try:
            response = ollama.chat(model=model, messages=messages)
            return response["message"]["content"]
        except Exception as e:
            return f"[OLLAMA LIB ERROR] {e}"

    return "[ERROR] No working Ollama integration (REST and lib failed)."


def show_welcome():
    """Display welcome message and help for beginners."""
    print("ğŸ¦… " + "="*50)
    print("   BIELIK - Polski Asystent AI")
    print("   Powered by Ollama + Speakleash")
    print("="*53)
    print()
    print("ğŸ“‹ DostÄ™pne komendy:")
    print("  :help    - pokaÅ¼ tÄ™ pomoc")
    print("  :status  - sprawdÅº poÅ‚Ä…czenie z Ollama")
    print("  :clear   - wyczyÅ›Ä‡ historiÄ™ rozmowy")
    print("  :exit    - zakoÅ„cz sesjÄ™")
    print("  Ctrl+C   - szybkie wyjÅ›cie")
    print()
    print("ğŸ’¡ WskazÃ³wki:")
    print("  â€¢ Pisz po polsku - Bielik rozumie jÄ™zyk polski!")
    print("  â€¢ Zadawaj pytania, proÅ› o pomoc, rozmawiaj naturalnie")
    print("  â€¢ JeÅ›li Ollama nie dziaÅ‚a, zobaczysz komunikat o bÅ‚Ä™dzie")
    print()


def check_ollama_status():
    """Check if Ollama is running and accessible."""
    import requests
    try:
        # Quick health check
        resp = requests.get(f"{OLLAMA_HOST.rstrip('/')}/api/tags", timeout=5)
        if resp.status_code == 200:
            data = resp.json()
            models = [m['name'] for m in data.get('models', [])]
            if any('bielik' in model.lower() for model in models):
                return "âœ… Ollama dziaÅ‚a, model Bielik dostÄ™pny"
            else:
                return f"âš ï¸ Ollama dziaÅ‚a, ale brak modelu 'bielik'. DostÄ™pne: {', '.join(models[:3])}"
        else:
            return f"âŒ Ollama odpowiada, ale bÅ‚Ä…d HTTP {resp.status_code}"
    except Exception as e:
        return f"âŒ Ollama niedostÄ™pny: {str(e)}"


def main():
    show_welcome()
    
    # Check Ollama status at startup
    status = check_ollama_status()
    print(f"ğŸ”— Status: {status}")
    print()
    
    if "âŒ" in status:
        print("ğŸš¨ UWAGA: Ollama nie dziaÅ‚a poprawnie!")
        print("ğŸ“– Jak naprawiÄ‡:")
        print("  1. Zainstaluj Ollama: https://ollama.com")
        print("  2. Uruchom: ollama serve")
        print("  3. Zainstaluj model: ollama pull bielik")
        print("  4. SprawdÅº: ollama list")
        print()
        
        try:
            continue_anyway = input("Czy kontynuowaÄ‡ mimo problemÃ³w? (t/N): ").lower()
            if continue_anyway not in ['t', 'tak', 'y', 'yes']:
                print("Sesja przerwana. Napraw Ollama i sprÃ³buj ponownie.")
                return
        except (EOFError, KeyboardInterrupt):
            print("\nSesja przerwana.")
            return
        print()
    
    print("ğŸš€ Gotowy do rozmowy! Napisz coÅ›...")
    print("â”€" * 53)
    
    messages = [{"role": "system", "content": "You are Bielik, a helpful Polish AI assistant. Respond in Polish unless asked otherwise."}]
    
    try:
        while True:
            try:
                user = input("\nğŸ§‘ Ty: ").strip()
            except EOFError:
                print("\nğŸ‘‹ Do zobaczenia!")
                break
                
            if not user:
                continue
                
            # Handle special commands
            if user.startswith(':'):
                if user in [":exit", ":quit", ":q"]:
                    print("ğŸ‘‹ Do zobaczenia!")
                    break
                elif user == ":help":
                    show_welcome()
                    continue
                elif user == ":status":
                    status = check_ollama_status()
                    print(f"ğŸ”— Status: {status}")
                    continue
                elif user == ":clear":
                    messages = [{"role": "system", "content": "You are Bielik, a helpful Polish AI assistant. Respond in Polish unless asked otherwise."}]
                    print("ğŸ§¹ Historia rozmowy wyczyszczona.")
                    continue
                else:
                    print(f"â“ Nieznana komenda: {user}. Wpisz :help aby zobaczyÄ‡ dostÄ™pne komendy.")
                    continue
            
            messages.append({"role": "user", "content": user})
            print("ğŸ¦… Bielik myÅ›li...", end="", flush=True)
            
            resp = send_chat(messages)
            print("\rğŸ¦… Bielik: " + " "*20)  # Clear "thinking" message
            print(f"    {resp}")
            
            # Only add to history if it's a real response, not an error
            if not resp.startswith("[ERROR]") and not resp.startswith("[REST ERROR]") and not resp.startswith("[OLLAMA LIB ERROR]"):
                messages.append({"role": "assistant", "content": resp})
            
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ Przerwano przez uÅ¼ytkownika. Do zobaczenia!")
        sys.exit(0)


if __name__ == "__main__":
    main()
