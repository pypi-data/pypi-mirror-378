{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05001c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be226b8",
   "metadata": {},
   "source": [
    "# filoma.ml â€” minimal examples\n",
    "Tiny examples showing filename feature discovery and dataset splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda8c09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run these cells with: PYTHONPATH=./src\n",
    "import polars as pl\n",
    "\n",
    "from filoma import ml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b19d56e",
   "metadata": {},
   "source": [
    "## Discover tokens from filenames (separator='_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f8002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame({\"path\": [\"LCFM/20200312/LAPAZ_image_01.tif\", \"OTHER/20210101/SITE_image_01.tif\"]})\n",
    "df2 = ml.add_filename_features(df, sep=\"_\", prefix=None, include_parent=False, path_col=\"path\")\n",
    "print(df2.columns)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ccba61",
   "metadata": {},
   "source": [
    "## Split by single token (token1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d06520",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = ml.split_data(df2, train_val_test=(60, 20, 20), feature=(\"token1\",), path_col=\"path\", seed=0)\n",
    "print(len(train), len(val), len(test))\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac36a4b",
   "metadata": {},
   "source": [
    "## Split by combined features (parent + token2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6705eef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = ml.add_filename_features(df, sep=\"_\", prefix=None, include_parent=True, path_col=\"path\")\n",
    "train, val, test = ml.split_data(df3, train_val_test=(60, 20, 20), feature=(\"parent\", \"token2\"), path_col=\"path\", seed=0)\n",
    "print(len(train), len(val), len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4454af8",
   "metadata": {},
   "source": [
    "## Custom token names and auto names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f5a0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = ml.add_filename_features(df, sep=\"_\", prefix=None, token_names=[\"site\", \"kind\", \"idx\"], path_col=\"path\")\n",
    "print(df4.columns)\n",
    "df5 = ml.add_filename_features(df, sep=\"_\", prefix=\"fn\", token_names=\"auto\", path_col=\"path\")\n",
    "print(df5.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff63065c",
   "metadata": {},
   "source": [
    "## Include all path parts as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc96bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = ml.add_filename_features(df, sep=\"_\", prefix=None, include_all_parts=True, path_col=\"path\")\n",
    "print(df6.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd47d0b",
   "metadata": {},
   "source": [
    "## Use a custom path column\n",
    "\n",
    "If your paths live in a column with a different name (for example `my_path`), pass `path_col` to discovery and splitting functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c4751b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_custom = pl.DataFrame({\"my_path\": [\"LCFM/20200312/LAPAZ_image_01.tif\", \"OTHER/20210101/SITE_image_01.tif\"]})\n",
    "df_custom2 = ml.add_filename_features(df_custom, sep=\"_\", prefix=None, include_parent=True, include_all_parts=True, path_col=\"my_path\")\n",
    "print(df_custom2.columns)\n",
    "print(df_custom2)\n",
    "train, val, test = ml.split_data(df_custom2, discover=False, feature=\"path_parts\", path_parts=(-1,), path_col=\"my_path\", seed=0)\n",
    "print(len(train), len(val), len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb533275",
   "metadata": {},
   "source": [
    "## Return types: filoma wrapper and pandas\n",
    "Below are two short examples showing how to request the `filoma.DataFrame` wrapper and a `pandas.DataFrame` from `ml.split_data`. The `pandas` example will fall back with a message if pandas is not installed. Run with `PYTHONPATH=./src`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbec2b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: return the filoma.DataFrame wrapper\n",
    "df7 = pl.DataFrame({\"path\": [\"LCFM/20200312/LAPAZ_image_01.tif\", \"OTHER/20210101/SITE_image_01.tif\"]})\n",
    "df7 = ml.add_filename_features(df7, sep=\"_\", prefix=None, include_parent=True, path_col=\"path\")\n",
    "train_f, val_f, test_f = ml.split_data(\n",
    "    df7, train_val_test=(60, 20, 20), feature=\"path_parts\", path_parts=(-1,), path_col=\"path\", seed=0, return_type=\"filoma\"\n",
    ")\n",
    "# filoma.DataFrame implements .to_polars() and other helpers\n",
    "print(\"train_f type:\", type(train_f))\n",
    "print(\"train_f is filoma.DataFrame -> to_polars columns:\", getattr(train_f, \"to_polars\")().columns)\n",
    "print(\"split sizes:\", len(train_f), len(val_f), len(test_f))\n",
    "print(\"train_f head:\")\n",
    "print(train_f.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2623d406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: return pandas.DataFrame (if pandas + pyarrow are installed)\n",
    "# We check for both pandas and pyarrow and show an actionable message if missing.\n",
    "try:\n",
    "    import pandas as pd  # noqa: F401\n",
    "    import pyarrow  # noqa: F401\n",
    "except ImportError:\n",
    "    print(\"pandas or pyarrow not available, skipping pandas example\")\n",
    "    print(\"Install with: pip install pandas pyarrow\")\n",
    "else:\n",
    "    df8 = pl.DataFrame({\"path\": [\"LCFM/20200312/LAPAZ_image_01.tif\", \"OTHER/20210101/SITE_image_01.tif\"]})\n",
    "    df8 = ml.add_filename_features(df8, sep=\"_\", prefix=None, include_parent=True, path_col=\"path\")\n",
    "    try:\n",
    "        train_p, val_p, test_p = ml.split_data(\n",
    "            df8, train_val_test=(60, 20, 20), feature=\"path_parts\", path_parts=(-1,), path_col=\"path\", seed=0, return_type=\"filoma\"\n",
    "        )\n",
    "        print(\"train_p type:\", type(train_p))\n",
    "        print(\"train_p head:\")\n",
    "        print(train_p.head())\n",
    "    except Exception as e:\n",
    "        print(\"conversion failed:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc42cd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary test: create 10 underscored .txt files, run discovery + split_data, then clean up\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "from filoma import ml\n",
    "\n",
    "tmp = Path(\"tests/tmp_ml_files\")\n",
    "if tmp.exists():\n",
    "    shutil.rmtree(tmp)\n",
    "# create folders\n",
    "(tmp / \"A\").mkdir(parents=True, exist_ok=True)\n",
    "(tmp / \"B\" / \"C\").mkdir(parents=True, exist_ok=True)\n",
    "(tmp / \"D\").mkdir(parents=True, exist_ok=True)\n",
    "(tmp / \"E\" / \"sub\").mkdir(parents=True, exist_ok=True)\n",
    "files = [\n",
    "    tmp / \"A\" / \"LCFM_20200312_LAPAZ_image_01.txt\",\n",
    "    tmp / \"A\" / \"LCFM_20200312_LAPAZ_image_02.txt\",\n",
    "    tmp / \"B\" / \"OTHER_20210101_SITE_image_01.txt\",\n",
    "    tmp / \"B\" / \"OTHER_20210101_SITE_image_02.txt\",\n",
    "    tmp / \"B\" / \"C\" / \"MISC_20211111_TEST_doc_001.txt\",\n",
    "    tmp / \"B\" / \"C\" / \"MISC_20211111_TEST_doc_002.txt\",\n",
    "    tmp / \"D\" / \"EXTRA_FILE_01.txt\",\n",
    "    tmp / \"D\" / \"EXTRA_FILE_02.txt\",\n",
    "    tmp / \"E\" / \"sub\" / \"DEEP_202001_sample_01.txt\",\n",
    "    tmp / \"E\" / \"sub\" / \"DEEP_202001_sample_02.txt\",\n",
    "]\n",
    "for p in files:\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    p.write_text(\"test\\n\")\n",
    "paths = [str(p) for p in files]\n",
    "print(\"created files:\", len(paths))\n",
    "for p in paths:\n",
    "    print(\" -\", p)\n",
    "df = pl.DataFrame({\"path\": paths})\n",
    "df2 = ml.add_filename_features(df, sep=\"_\", prefix=None, include_parent=True, path_col=\"path\")\n",
    "print(\"Discovered columns:\", df2.columns)\n",
    "train, val, test = ml.split_data(\n",
    "    df2, train_val_test=(60, 20, 20), feature=\"path_parts\", path_parts=(-1,), path_col=\"path\", seed=42, return_type=\"polars\"\n",
    ")\n",
    "print(\"Split sizes:\", len(train), len(val), len(test))\n",
    "print(\"Train sample:\")\n",
    "print(train)\n",
    "# cleanup\n",
    "shutil.rmtree(tmp)\n",
    "print(\"cleaned up\", tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d39617",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "filoma (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
