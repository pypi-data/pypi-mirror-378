[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "termaitrik"
version = "1.7.2"
description = "Terminal AI assistant inspired by Warp AI, supporting Ollama and BYOK"
readme = "README.md"
license = "MIT"
license-files = ["LICENSE"]
requires-python = ">=3.10"
authors = [{name = "Trikketto"}]
maintainers = [{name = "Trikketto"}]
keywords = ["ai", "terminal", "ollama", "cli", "assistant"]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "Operating System :: OS Independent",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Utilities",
]
dependencies = [
    "fastapi>=0.111",
    "uvicorn>=0.30",
    "typer>=0.12",
    "rich>=13.7",
    "PyYAML>=6.0",
    "requests>=2.31",
    "llama-cpp-python",
]

# TODO?: Fix optional dependency installation for llama-cpp-python
#        llama-cpp-python install is big and fail-prone on some systems
#        so it would be nice to make it optional, and have it installed only when...
# [project.optional-dependencies]
# # Install with: pip install "termaitrik[llamacpp]" or
# # uvx --from "termaitrik[llamacpp]@latest" termai ...
# llamacpp = [
#     "llama-cpp-python",
# ]

[project.urls]
Homepage = "https://github.com/Trikketto/termai_project"
Repository = "https://github.com/Trikketto/termai_project"
Issues = "https://github.com/Trikketto/termai_project/issues"

[project.scripts]
termai = "termai.cli:app"

[tool.setuptools]
include-package-data = true

[tool.setuptools.package-data]
termai = [
    "scripts/*.sh",
]
